[["index.html", "Ciencia de Datos y Machine Learning BIENVENIDA Objetivo Alcances del curso Instructores Temario Duración y evaluación del curso Recursos y dinámica de clase", " Ciencia de Datos y Machine Learning BIENVENIDA Objetivo Capacitar y brindar acompañamiento al equipo de analítica de ASERTA en temas relacionados con Ciencia de Datos para la correcta implementación de proyectos y toma de decisiones basadas en la evidencia de datos internos y externos a la empresa para lograr un beneficio operativo y económico. Alcances del curso El participante conocerá los conceptos teóricos alrededor de esta ciencia y sabrá implementar correctamente un análisis exploratorio estadístico y gráfico que le permita conocer a mayor profundidad los datos a usar. Conocerá y sabrá implementar los modelos predictivos de Machine Learning más usados y de mayor impacto en la industria de seguros y fianzas. Finalmente, sabrá tomar decisiones sobre el correcto uso e implementación de los modelos para aumentar el beneficio comercial dentro de la institución. Instructores ACT. ARTURO BRINGAS LinkedIn: arturo-bringas Email: act.arturo.b@ciencias.unam.mx Actuario egresado de la Facultad de Ciencias con maestría en Ciencia de Datos por el ITAM. Se especializa en modelos predictivos y de clasificación de machine learning aplicado a seguros, marketing, deportes, e-commerce y movilidad internacional. Ha sido consultor Senior Data Scientist para empresas y organizaciones como GNP, El Universal, UNAM, la Organización de las Naciones Unidas Contra la Droga y el Delito (UNODC), Sinnia, entre otros. Actualmente es profesor de Ciencia de datos y Machine Learning en AMAT. Es jefe de estadística en el Departamento de Investigación Aplicada y Opinión de la UNAM, donde realiza estudios nacionales de impacto social. Es colaborador del Laboratorio Nacional de Observación de la Tierra (LANOT) y consultor senior de Grupo ALSEA. ACT. KARINA LIZETTE GAMBOA LinkedIn: KaLizzyGam Email: lizzygamboa@ciencias.unam.mx Actuaria egresada de la Facultad de Ciencias y candidata a Maestra en Ciencia de Datos por el ITAM. Experiencia en áreas de analítica predictiva e inteligencia del negocio. Lead y Senior Data Scientist en consultoría en diferentes sectores como tecnología, asegurador, financiero y bancario. Es experta en entendimiento de negocio para la correcta implementación de algoritmos de inteligencia y explotación de datos. Actualmente se desarrolla como Arquitecta de Soluciones Analíticas en Merama, startup mexicana clasificada como uno de los nuevos unicornios de Latinoamérica. Senior Data Science en CLOSTER y como profesora del diplomado de Metodología de la Investigación Social por la UNAM así como instructora de cursos de Ciencia de Datos en AMAT. Empresas anteriores: GNP, Actinver Banco y Casa de Bolsa, PlayCity Casinos, RakenDataGroup Consulting, entre otros. Temario Módulo 1: Introducción a R (22 hrs) Objetivo: A través de este módulo se adquirirán los conocimientos necesarios para la operación del software estadístico y la manipulación ágil de datos. Al finalizar, el participante desarrollará análisis exploratorios y reportes automatizados. Estructuras de almacenamiento de datos Almacenamiento Vectores Matrices Listas DataFrames Funciones y estructuras de control Librerías y funciones Operaciones vectoriales Condicionamiento Ciclos Guía de estilo Manipulación de estructuras de datos Importación de tablas Consultas y transformación de estructuras Iteraciones Manipulación de texto y datos temporales Análisis exploratorio y visualización de datos Guía de visualización Análisis Exploratorio de Datos (EDA) Análisis Gráfico Exploratorio de Datos (GEDA) Reportes con markdown Consultoría y aplicaciones con datos institucionales Módulo 2: Introducción a Ciencia de Datos (18 hrs) Objetivo: Este módulo presenta los conceptos teóricos clave para conocer los términos, objetivo y alcances de proyectos con enfoque en ciencia de datos. Se presenta el flujo de trabajo y organización que deberá seguir un equipo para obtener el mayor beneficio posible. Adicionalmente, se propone presentar el software git y github para implementar correctamente el trabajo en equipo que garantice la reproducibilidad y seguridad del desarrollo realizado. Introducción a ciencia de datos ¿Qué es la ciencia de datos? Objetivo de ciencia de datos Requisitos y aplicaciones Tipos de algoritmos Perfiles de un equipo de ciencia de datos Ciclo de vida de un proyecto Taller de scoping Concepto de Ciencia de Datos Machine learning Análisis supervisado Análisis no supervisado Sesgo y varianza Pre-procesamiento e ingeniería de datos Partición de datos Colaboración y reproducibilidad Git &amp; Github Ambiente de desarrollo Consultoría y aplicaciones con datos institucionales Módulo 3: Machine Learning: Supervisado (38 hrs) Objetivo: Este módulo está diseñado para adquirir los conocimientos técnicos para conocer e implementar los distintos modelos de aprendizaje supervisado que son aplicados en ciencia de datos a la industria de los seguros y fianzas. Modelos de aprendizaje Supervisado Regresión Lineal Regresión logística Regularización Ridge &amp; Lasso Elasticnet KNN Árbol de decisión Bagging Random Forest Boosting Stacking Toma de decisiones enfocadas a negocio Comparación de modelos Balance entre precisión y cobertura Cuantificación de sesgo e inequidad Cuantificación de ganancia comercial Diseño experimental Consultoría y aplicaciones con datos institucionales Módulo 4: Machine Learning: No Supervisado (12 hrs) Objetivo: Este módulo permite al participante conocer técnicas de clustering para clasificar clientes de acuerdo con la utilidad y riesgo para la empresa. Adicionalmente, se presentan aplicaciones de clustering enfocadas a la estratificación de acuerdo con el riesgo geográfico. Técnicas de reducción de dimensión Análisis de componentes principales Creación de índices Clustering Liga simple, compleja y promedio Dendogramas &amp; heatmaps Kmeans &amp; Kmedoids DBSCAN Consultoría y aplicaciones con datos institucionales Requisitos Computadora con al menos 4Gb Ram. Instalación de R con versión &gt;= 4.1.0 Instalación de Rstudio con versión &gt;= 1.4.17 Conocimientos generales de probabilidad, estadística y álgebra lineal Duración y evaluación del curso El programa tiene una duración de 90 hrs. Las clases serán impartidas los días lunes a viernes, de 7:30 am a 9:30 am Serán asignados ejercicios que el participante deberá resolver entre una semana y otra. Al final del curso se solicitará un proyecto final, el cual deberá ser entregado para ser acreedor a la constancia de participación. “La gota abre la piedra, no por su fuerza sino por su constancia” - Ovidio Recursos y dinámica de clase En esta clase estaremos usando: R (descargar) RStudio (descargar) Zoom Clases Pulgar arriba: Voy bien, estoy entendiendo! Pulgar abajo: Eso no quedó muy claro Mano arriba: Quiero participar/preguntar o Ya estoy listo para iniciar Google Drive Notas de clase Asistencias y rescates vía gpo whatsapp: https://chat.whatsapp.com/InAbwYRJ7njGbtz9V2xxrN FINALMENTE… se dejarán ejercicios que serán clave para el éxito del aprendizaje de los capítulos, por lo que se trabajará en equipo para lograr adquirir el mayor aprendizaje. "],["conceptos-de-ciencia-de-datos.html", "Capítulo 1 Conceptos de Ciencia de Datos 1.1 ¿Qué es Ciencia de Datos? 1.2 Objetivos 1.3 Requisitos 1.4 Aplicaciones 1.5 Tipos de algoritmos 1.6 Perfiles de un equipo 1.7 Flujo de trabajo en ML 1.8 Ciclo de un proyecto 1.9 Taller de Scoping", " Capítulo 1 Conceptos de Ciencia de Datos 1.1 ¿Qué es Ciencia de Datos? Definiendo conceptos: Estadística Disciplina que recolecta, organiza, analiza e interpreta datos. Lo hace a través de una población muestral generando estadística descriptiva y estadística inferencial. La estadística descriptiva, como su nombre lo indica, se encarga de describir datos y obtener conclusiones. Se utilizan números (media, mediana, moda, mínimo, máximo, etc) para analizar datos y llegar a conclusiones de acuerdo a ellos. La estadística inferencial argumenta o infiere sus resultados a partir de las muestras de una población. Se intenta conseguir información al utilizar un procedimiento ordenado en el manejo de los datos de la muestra. La estadística predictiva busca estimar valores y escenarios futuros más probables de ocurrir a partir de referencias históricas previas. Se suelen ocupar como apoyo características y factores áltamente asociados al fenómeno que se desea predecir. Business Intelligence: BI aprovecha el software y los servicios para transformar los datos en conocimientos prácticos que informan las decisiones empresariales estratégicas y tácticas de una organización. Las herramientas de BI acceden y analizan conjuntos de datos y presentan hallazgos analíticos en informes, resúmenes, tableros, gráficos, cuadros, -indicadores- o KPI’s y mapas para proporcionar a los usuarios inteligencia detallada sobre el estado del negocio. BI esta enfocado en analizar la historia pasada para tomar decisiones hacia el futuro. ¿Qué características tiene un KPI? Específicos Continuos y periódicos Objetivos Cuantificables Medibles Realistas Concisos Coherentes Relevantes Machine Learning: Machine learning –aprendizaje de máquina– es una rama de la inteligencia artificial que permite que las máquinas aprendan de los patrones existentes en los datos. Se usan métodos computacionales para aprender de datos con el fin de producir reglas para mejorar el desempeño en alguna tarea o toma de decisión. (Está enfocado en la programación de máquinas para aprender de los patrones existentes en datos principalmente estructurados y anticiparse al futuro) Deep Learning: El aprendizaje profundo es un subcampo del aprendizaje automático que se ocupa de los algoritmos inspirados en la estructura y función del cerebro llamados redes neuronales artificiales. En Deep Learning, un modelo de computadora aprende a realizar tareas de clasificación directamente a partir de imágenes, texto o sonido. Los modelos de aprendizaje profundo pueden lograr una precisión de vanguardia, a veces superando el rendimiento a nivel humano. Los modelos se entrenan mediante el uso de un gran conjunto de datos etiquetados y arquitecturas de redes neuronales que contienen muchas capas. (Está enfocado en la programación de máquinas para el reconocimiento de imágenes y audio (datos no estructurados)) Big data se refiere a los grandes y diversos conjuntos de información que crecen a un ritmo cada vez mayor. Abarca el volumen de información, la velocidad a la que se crea y recopila, y la variedad o alcance de los puntos de datos que se cubren. Los macrodatos a menudo provienen de la minería de datos y llegan en múltiples formatos. Es común que se confunda los conceptos de Big Data y Big Compute, como se mencionó, Big Data se refiere al procesamiento de conjuntos de datos que son más voluminosos y complejos que los tradicionales y Big Compute a herramientas y enfoques que utilizan una gran cantidad de recursos de CPU y memoria de forma coordinada para resolver problemas que usan algoritmos muy complejos. Curiosidad: Servidores en líquido para ser enfriados Curiosidad 2: Centro de datos en el océano Entonces, ¿qué NO es ciencia de datos? No es una tecnología No es una herramienta No es desarrollo de software No es Business Intelligence* No es Big Data* No es Inteligencia Artificial* No es (solo) machine learning No es (solo) deep learning No es (solo) visualización No es (solo) hacer modelos 1.2 Objetivos Los científicos de datos analizan qué preguntas necesitan respuesta y dónde encontrar los datos relacionados. Tienen conocimiento de negocio y habilidades analíticas, así como la capacidad de extraer, limpiar y presentar datos. Las empresas utilizan científicos de datos para obtener, administrar y analizar grandes cantidades de datos no estructurados. Luego, los resultados se sintetizan y comunican a las partes interesadas clave para impulsar la toma de decisiones estratégicas en la organización. Fuente: Blog post de Drew Conway Más sobre Conway: Forbes 2016 1.3 Requisitos Background científico: Conocimientos generales de probabilidad, estadística, álgebra lineal, cálculo, geometría analítica, programación, conocimientos computacionales… etc Datos relevantes y suficientes: Es indispensable saber si los datos con los que se trabajará son relevantes y suficientes, debemos evaluar qué preguntas podemos responder con los datos con los que contamos. Suficiencia: Los datos con los que trabajamos tienen que ser representativos de la población en general, necesitamos que las características representadas en la información sean suficientes para aproximar a la población objetivo. Relevancia: De igual manera los datos tienen que tener relevancia para la tarea que queremos resolver, por ejemplo, es probable que información sobre gusto en alimentos sea irrelevante para predecir número de hijos. Etiquetas: Se necesita la intervención humana para etiquetar, clasificar e introducir los datos en el algoritmo. Software: Existen distintos lenguajes de programación para realizar ciencia de datos 1.4 Aplicaciones Dependiendo de la industria en la que se quiera aplicar Machine Learning, podemos pensar en distintos enfoques, en la siguiente imagen se muestran algunos ejemplos: Podemos pensar en una infinidad de aplicaciones comerciales basadas en el análisis de datos. Con la intención de estructurar las posibles aplicaciones, se ofrece a continuación una categorización que, aunque no es suficiente para englobar todos los posibles casos de uso, sí es sorprendente la cantidad de aplicaciones que abarca. 1. Aplicaciones centradas en los clientes Incrementar beneficio al mejorar recomendaciones de productos Up-selling Cross-selling Reducir tasas de cancelación y mejorar tasas de retención Personalizar experiencia de usuario Mejorar el marketing dirigido Análisis de sentimientos Personalización de productos o servicios 2. Optimización de problemas Optimización de precios Ubicación de nuevas sucursales Maximización de ganancias mediante producción de materias primas Construcción de portafolios de inversión 3. Predicción de demanda Número futuro de clientes Número esperado de viajes en avión / camión / bicis Número de contagios por un virus (demanda médica / medicamentos / etc) Predicción de uso de recursos (luz / agua / gas) 4. Análisis de detección de fraudes Detección de robo de identidad Detección de transacciones ilícitas Detección de servicios fraudulentos Detección de zonas geográficas con actividades ilícitas 1.5 Tipos de algoritmos Los algoritmos de Machine Learning se dividen en tres categorías, siendo las dos primeras las más comunes: La diferencia entre el análisis supervisado y el no supervisado es la etiqueta, es decir, en el análisis supervisado tenemos una etiqueta “correcta” y el objetivo de los algoritmos es predecir esta etiqueta. 1.5.1 Aprendizaje supervisado En el aprendizaje supervisado, la idea principal es aprender bajo supervisión, donde la señal de supervisión se nombra como valor objetivo o etiqueta. Estos algoritmos cuentan con un aprendizaje previo basado en un sistema de etiquetas asociadas a unos datos que les permiten tomar decisiones o hacer predicciones. Conocemos la respuesta correcta de antemano. Esta respuesta correcta fue “etiquetada” por un humano (la mayoría de las veces, en algunas circunstancias puede ser generada por otro algoritmo). Debido a que conocemos la respuesta correcta, existen muchas métricas de desempeño del modelo para verificar que nuestro algoritmo está haciendo las cosas “bien”. Algunos ejemplos son: - Un detector de spam que etiqueta un e-mail como spam o no. - Predecir precios de casas - Clasificación de imagenes - Predecir el clima - ¿Quiénes son los clientes descontentos? Tipos de aprendizaje supervisado (Regresión vs clasificación) Existen dos tipos principales de aprendizaje supervisado, esto depende del tipo de la variable respuesta: Clasificación En el aprendizaje supervisado, los algoritmos de clasificación se usan cuando el resultado es una etiqueta discreta. Esto quiere decir que se utilizan cuando la respuesta se fundamenta en conjunto finito de resultados. Regresión El análisis de regresión es un subcampo del aprendizaje automático supervisado cuyo objetivo es establecer un método para la relación entre un cierto número de características y una variable objetivo continua. 1.5.2 Aprendizaje no supervisado En el aprendizaje no supervisado, carecemos de etiquetas. Por lo tanto, necesitamos encontrar nuestro camino sin ninguna supervisión ni guía. Esto simplemente significa que necesitamos descubrir ¿qué es qué? por nosotros mismos. Aquí no tenemos la respuesta correcta de antemano ¿cómo podemos saber que el algoritmo está bien o mal? Estadísticamente podemos verificar que el algoritmo está bien Siempre tenemos que verificar con el cliente si los resultados que estamos obteniendo tienen sentido de negocio. Por ejemplo, número de grupos y características Algunos ejemplos son: - Encontrar segmentos de clientes. - Reducir la complejidad de un problema - Selección de variables - Encontrar grupos - Reducción de dimensionalidad 1.5.3 Aprendizaje por refuerzo Su objetivo es que un algoritmo aprenda a partir de la propia experiencia. Esto es, que sea capaz de tomar la mejor decisión ante diferentes situaciones de acuerdo a un proceso de prueba y error en el que se recompensan las decisiones correctas. Algunos ejemplos son: - Optimización de campañas de marketing - Reconocimiento facial - Diagnósticos médicos - Clasificar secuencias de ADN Ejemplo: Mario Bros 1.6 Perfiles de un equipo La tecnología crece día con día y resulta imposible abarcar todos los conocimientos y especialidades, por lo que resulta indispensable tener un claro entendimiento de los diferentes roles o perfiles de profesionistas que lograrán colaborar en el alcance de objetivos de negocio basados en el análisis y explotación de datos. A continuación se presenta un esquema global sobre el crecimiento de un equipo con enfoque de ingeniería de inteligencia de decisiones basada en análisis de datos: 1) Ingeniero de datos Es fundamental tener la capacidad de obtener datos antes de que tenga sentido hablar sobre el análisis de datos. Si estás trabajando con conjuntos de datos pequeños, la ingeniería de datos consistirá básicamente en ingresar algunos números en una hoja de cálculo. Cuando se opera en una escala más grande, la ingeniería de datos se convierte en una disciplina sofisticada por derecho propio. Alguien del equipo deberá asumir la responsabilidad de lidiar con los complicados aspectos de ingeniería para poder entregar los datos con los que el resto del equipo pueda trabajar. 2) Decisor Antes de contratar a un científico de datos con un master o PhD, hay que asegurarse de que quien toma las decisiones entiende el arte y la ciencia de la toma de decisiones basada en datos. \\[\\text{Las capacidades de toma de decisiones deben estar establecidas, antes de que un equipo}\\] \\[\\text{pueda obtener valor de los datos}\\] Este individuo es responsable de identificar las decisiones que valen la pena tomar con los datos, plasmarlas en un modelo (desde el diseño de métricas, hasta las inyecciones sobre supuestos estadísticos) y determinar el nivel requerido de rigor analítico, basado en el impacto potencial en el negocio. 3) Analista En este punto, todos los que ya están trabajando contigo en el equipo están calificados para mirar los datos y sentirse inspirados, lo único que puede estar faltando es un poco de familiaridad con el software que sea adecuado para hacer el análisis. Si toda la fuerza laboral está empoderada para hacerlo, se tendrá un mucho mejor pulso de negocio que si nadie está mirando ningún dato en lo absoluto. Lo importante a recordar, es que no se debe llegar a conclusiones más allá de los datos. Eso requiere entrenamiento especializado. Al igual que con la foto de arriba, esto es todo lo que puedes decir al respecto: “Esto es lo que hay en mi conjunto de datos”. Por favor, no usarlo para concluir que el Monstruo de Lago Ness es real. 4) Analista experto ¡Entra la versión ultra rápida! Esta persona puede ver más datos más rápido. El juego aquí es velocidad, exploración, descubrimiento… ¡diversión!. Esta es la persona que ayuda a tu equipo a ver la mayor cantidad de datos posible para que el responsable de la toma de decisiones pueda tener una idea de lo que vale la pena obtener con más detalle. \\[\\text{El trabajo aquí es la velocidad, encontrando potenciales “insights” lo más rápido posible.}\\] Esto puede ser contrario a la intuición, pero no es conveniente asignar esta función a los mejores ingenieros que escriben un magnífico y sólido código de software. El trabajo aquí es velocidad, encontrando potenciales “insights” o revelaciones lo más rápido posible. \\[\\text{Aquellos que se obsesionan con la calidad del código pueden}\\] \\[\\text{encontrar difícil ser útiles en este rol.}\\] 5) Estadístico Ahora que tenemos a todas estas personas contentas explorando los datos, es mejor tener a alguien cerca para controlar tanta exaltación. Podría ser una buena idea tener a alguien cerca que pueda evitar que el equipo saque conclusiones infundadas. \\[\\text{La inspiración es barata, pero el rigor es caro.}\\] Los Estadísticos ayudan a quienes toman las decisiones a llegar a conclusiones seguras más allá de los datos. Por ejemplo, si el sistema de Machine Learning funcionó para un conjunto de datos, todo lo que se puede concluir es que funcionó en ese conjunto de datos. ¿Funcionará cuando se está ejecutando en producción con otros datos? ¿Debería ser lanzado a producción? Necesita algunas habilidades adicionales para lidiar con esas preguntas. Habilidades estadísticas. Si queremos tomar decisiones serias cuando no tenemos datos perfectos, vayamos más despacio y tomemos un enfoque cuidadoso. Los estadísticos ayudan a quienes toman las decisiones a llegar a conclusiones más seguras, más allá de los datos analizados. 6) Ingeniero de Machine Learning El mejor atributo de un ingeniero de Machine Learning / Inteligencia Artificial aplicada es diseñar, crear, evaluar y producir modelos para resolver problemas de la vida real. Lo que estás buscando es experiencia en transformar código para hacer que los algoritmos existentes acepten y revuelvan tus conjuntos de datos. Se busca una personalidad que tenga tolerancia frente al fracaso. Ejecuta los datos a través de un grupo de algoritmos lo más rápido posible y ve sí está funcionando. Una gran parte del trabajo es ir tanteando a ciegas, y se necesita un tipo especial de personalidad para disfrutar eso. \\[\\text{Los perfeccionistas tienden a tener problemas como ingenieros de ML.}\\] Como el problema de negocio no está en un libro de texto, no puede saberse de antemano qué funcionará, por lo que no puede esperarse obtener un resultado perfecto la primera vez. ¡Eso bien!, solo hay que intentar muchos enfoques lo más rápido posible e intentar encontrar una solución. Es importante que el ingeniero de Machine Learning tenga un profundo respeto por la parte del proceso donde el rigor es vital: la evaluación. ¿Funcionó realmente la solución con nuevos datos? 7) Científico de Datos Un científico de datos es alguien que es un experto en los tres roles anteriores. No todos usan esta definición: verás las solicitudes de empleo por ahí con personas que se autodenominan “científicos de datos” cuando sólo dominan realmente uno de los tres, así que vale la pena comprobarlo. Este rol está en la posición # 7 porque contratar a los verdaderos tres-en-uno es una opción costosa. Antes de contratar a un nuevo especialista 3 en 1, considera hacer crecer a tu equipo actual. 8) Gerente de Análisis / Líder de Ciencia de Datos El Gerente de Analítica es la gallina de los huevos de oro: son un híbrido entre el científico de datos y el que toma las decisiones. Su presencia en el equipo actúa como un multiplicador de fuerzas, lo que garantiza que tu equipo de ciencia de datos no quede en fuera de juego en lugar de agregar valor a tu negocio. Esta persona se queda despierta por la noche pensando preguntas como: “¿Cómo diseñamos las preguntas correctas? ¿Cómo tomamos decisiones? ¿Cómo podemos asignar mejor a nuestros expertos? ¿Qué vale la pena hacer? ¿Las habilidades y los datos coincidirán con los requerimientos? ¿Cómo aseguramos buenos datos de entrada? 9) Experto Cualitativo / Científico Social A veces, quien toma las decisiones es un brillante líder, gerente, motivador, influyente o navegante de la política organizacional, pero no siempre tiene experiencia en el arte y la ciencia de la toma de decisiones. El experto cualitativo está para complementar las habilidades del equipo técnico en matemáticas y programación. Esta persona generalmente tiene formación en ciencias sociales y datos: Los economistas de comportamiento, neuroeconomistas y psicólogos reciben la capacitación más especializada, pero la gente autodidacta también puede ser buena en esto. El trabajo consiste en ayudar al responsable de la toma de decisiones a aclarar ideas, examinar todos los ángulos y convertir las intuiciones ambiguas en instrucciones bien pensadas en un lenguaje que facilite la ejecución al resto del equipo. Por lo general, los científicos sociales están mejor equipados que los científicos de datos para traducir en métricas concretas, las intuiciones e intenciones de quienes toman las decisiones. Se aseguran de que el responsable de la toma de decisiones haya captado completamente la información disponible para poderla tomar. También son un asesor de confianza, un compañero de intercambio de ideas y una caja de resonancia para quien toma las decisiones. 10) Investigador Se trata de profesionistas de larga trayectoria tanto académica como práctica. Son profesionistas con PhD. Su gran experiencia y conocimientos los hacen ser capaces de construir nuevas herramientas hechas a la medida que no existen en el mercado. Este perfil es de gran beneficio cuando ya se cuenta con las posiciones anteriores. Si el investigador es el primer empleado, es probable que no se tenga el entorno adecuado para hacer un buen uso y aprovechamiento de sus conocimientos y habilidades. \\[\\text{&quot;Antes de construir ese bolígrafo espacial para viajar a la Luna, }\\] \\[\\text{comprueba primero si un lápiz puede hacer el trabajo.&quot;}\\] Es conveniente esperar hasta que el equipo se haya desarrollado lo suficiente como para haber averiguado para qué específicamente necesitan un investigador. Extra) Personal Adicional Además de los roles que vimos, estas son algunas de las personas que podrían para participar en un proyecto de inteligencia de decisiones: Experto en áreas específicas de negocio Ética Ingeniero de software Ingeniero de Confiabilidad Diseñador de Experiencia de Usuario Visualizador interactivo / diseñador gráfico. Especialista en recolección de datos Gerente de producto de datos Gerente de proyectos / programas Muchos proyectos no pueden prescindir de ellos. La única razón por la que no figuran en el top 10 es que la inteligencia de decisiones basadas en la explotación de datos no es su negocio principal. En su lugar, son genios en su propia área y han aprendido lo suficiente sobre datos y la toma de decisiones para ser muy útiles en el proyecto. Piensa en ellos como si tuvieran su propia carrera universitaria, pero con suficiente amor por la inteligencia de decisiones que eligieron estudiarla como una especialización. Fuente: Medium Google Data Career Path Google es una compañía bastante especializada en procesos de desarrollo de tecnología con grandes aplicaciones comerciales. Cada compañía puede armar su propio equipo de acuerdo con la estrategia que más se apegue a sus objetivos, no obstante, siempre vale la pena conocer los perfiles que Google define y sugiere. Fuente: Data Science On Google Cloud Platform Esta definición de roles es particularmente técnica, por lo que es importante añadir los perfiles de expertos de negocio. 1.7 Flujo de trabajo en ML Al conocer el camino antes de atravesarlo habrá mucho más probabilidad de que sea alcanzado de manera exitosa. Como un preciado extra, además podrá lograrse en una cantidad significativamente menor de tiempo a lo que llevaría avanzar sin un esquema de trabajo. En esta sección se muestra el flujo de trabajo general que todo científico de datos debe implementar para llevar a cabo un exitoso proyecto basado en análisis de datos. Existen múltiples propuestas sobre el flujo de trabajo a implementar, sin embargo, la mayoría son muy similares. La diferencia estas propuestas son aspectos triviales que no se ven reflejados de una manera importante en la estructura del flujo de trabajo. El diagrama anterior muestra los elementos que pueden encontrarse en todo proyecto de analítica. 1. Business Understanding: La ciencia y tecnología aplicada a un problema es peligrosa si no se cuenta con el conocimiento de la naturaleza del problema y los factores que los afectan. El entendimiento del negocio es vital para lograr resolver el problema y solo mediante el profundo entendimiento es que se logra encontrar nuevas aportaciones para mejorar la calidad de la solución. 2. Data Mining: Es indispensable contar con una fuente de datos que provea a todo el equipo la información necesaria para el desarrollo del proyecto. Recolectar datos de diversas fuentes y centralizarlos para el consumo de todos aquellos autorizados a consumirlos, es la primer tarea técnica a satisfacer. En esta etapa se deberán separar los datos que serán usados en las siguientes etapas para: Creación del modelo Pruebas de calidad Validación de resultados 3. Data Cleaning: Los datos suelen no estar listos para ser usados. Suelen existir datos faltantes o equivocados que en caso de usarse directamente provocarán resultados de baja calidad. Es indispensable limpiar estos datos para que los modelos tengan resultados con la mejor calidad posible. 4. Data Exploration: La exploración es necesaria para conocer el contenido, estructura, distribución y relación que existe entre los datos. Los modelos suelen tener distintos supuestos del comportamiento de la información para poder ser implementados. En la medida en que se conocen estos atributos, será posible proponer alternativas y soluciones adicionales que aporten valor. 5. Feature Engineering: La ingeniería de variables es el proceso en el que se manufacturan nuevas variables que aportan valor adicional al que ofrecen las variables originales. Esta etapa es posible realizarse con éxito cuando se conoce el negocio y se ha realizado una exploración de datos profunda. 6. Predictive Modeling Una vez que se ha creado el conjunto de datos que sirve de insumo para el análisis, se procede a la creación del modelo. En esta etapa se ponen a prueba múltiples modelos hasta elegir el que aporta la mejor solución de acuerdo con el objetivo de negocio. 7. Data Visualization Todos los modelos tienen un tiempo de vida finita. Con el paso del tiempo la calidad va disminuyendo debido a cambios en el comportamiento de la población o fenómenos involucrados, por lo que los resultados y la calidad del modelo deben ser monitoreados constantemente para conocer el momento en que dejan de ser útiles y debe darse mantenimiento al proyecto. En R, existen librerías que ayudan a llevar a cabo todo el proceso de principio a fin. En las siguientes sesiones se llevará a cabo la explicación de todo el proceso y su implementación. 1.8 Ciclo de un proyecto Identificación del problema Debemos conocer si el problema es significativo, si el problema se puede resolver con ciencia de datos, y si habrá un compromiso real del lado de cliente/usuario/partner para implementar la solución con todas sus implicaciones: recursos físicos y humanos. Scoping El objetivo es definir el alcance del proyecto y por lo tanto definir claramente los objetivos. Conocer las acciones que se llevarán a cabo para cada objetivo. Estas definirán las soluciones analíticas a hacer. Queremos saber si los datos con los que contamos son relevantes y suficientes. Hacer visible los posibles conflictos éticos que se pueden tener en esta fase. Debemos definir el cómo evaluaremos que el análisis de esos datos será balanceada entre eficiencia, efectividad y equidad. Adquisición de datos Adquisición, almacenamiento, entendimiento y preparación de los datos para después poder hacer analítica sober ellos. Asegurar que en la transferencia estamos cumpliendo con el manejo adecuado de datos sensibles y privados. EDA El objetivo en esta fase es conocer los datos con los que contamos y contexto de negocio explicado a través de los mismos. Identificamos datos faltantes, sugerimos cómo imputarlos. Altamente apoyado de visualización y procesos de adquisición y limpieza de datos. Formulación analítica Esta fase incluye empezar a formular nuestro problema como uno de ciencia de datos, el conocimiento adquirido en la fase de exploración nos permite conocer a mayor detalle del problema y por lo tanto de la solución adecuada. Modelado Proceso iterativo para desarrollar diferentes “experimentos”. Mismo algoritmo/método diferentes hiperparámetros (grid search). Diferentes algortimos. Selección de un muy pequeño conjunto de modelos tomando en cuenta un balance entre interpretabilidad, complejidad, desempeño, fairness. Correcta interpretación de los resultados de desempeño de cada modelo. Validación Es muy importante poner a prueba el/los modelo/modelos seleccionados en la fase anterior. Esta prueba es en campo con datos reales, le llamamos prueba piloto. Debemos medir el impacto causal que nuestro modelo tuvo en un ambiente real. Acciones a realizar Finalmente esta etapa corresponde a compartir con los tomadores de decisiones/stakeholders/creadores de política pública los resultados obtenidos y la recomendación de acciones a llevar a cabo -menú de opciones-. Las implicaciones éticas de esta fase consisten en hacer conciente el impacto social de nuestro trabajo. 1.9 Taller de Scoping El scoping es uno de los pasos más importante en los proyectos de ciencia de datos, es ideal realizarlo con ayuda del cliente, tiene como objetivo definir el alcance del proyecto, definir los objetivos, conocer las acciones que se llevaran acabo, conocer si los datos son relevantes y suficientes, proponer soluciones analíticas, entre otros puntos que se tocaran a continuación. 1.9.1 Data Maturity Framework Antes de iniciar con el scoping, queremos conocer si los interesados están listos para realizar un proyecto de ciencia de datos. Para ello, una opción es usar el Data Maturity Framework desarrollado en la Universidad de Chicago. El Data Maturity Framework nos sirve para ver dónde se encuentra la organización en el marco de madurez de datos y cómo mejorar su organización, tecnología y preparación de datos. Tiene tres áreas de contenido: Definición del problema Disponibilidad de datos y tecnología Preparación organizacional Esta dividido en tres partes: Un cuestionario y una encuesta para evaluar la preparación de la organización. Matriz de preparación de datos y tecnología Matriz de preparación organizacional 1.9.2 Scoping Para realizar el scoping podemos apoyarnos del siguiente documento. Ya que sabemos que la organización esta preparada para realizar un proyecto de ciencia de datos, podemos iniciar el scoping. El proceso a seguir es el siguiente: Definir objetivo(s) Considerado el paso más importante del proceso, los stakeholders iniciaran con un planteamiento del problema de manera muy general, nuestra responsabilidad será ir aterrizando ideas y definir el problema de manera más concreta, esta parte del scoping puede ocurrir en distintas iteraciones. Necesitamos hacer que el objetivo sea concreto, medible y optimizable. Cuando se van refinando objetivos, es común que se vaya priorizando por lo que tendremos tradeoffs que irán ligados a las acciones y al contexto del negocio. ¿Qué acciones o intervenciones existen que serán mejoradas a través de este proyecto? Debemos definir acciones concretas, si esto no ocurre es muy probable que la solución no sea implementada por lo que el proyecto no tendrá uso y no se estará haciendo ciencia de datos. La implementación del proyecto debería ayudar a tener mejor información para llevar acabo estas acciones, es decir, el proyecto mejorará la toma de decisiones basadas en la evidencia de los datos. Hacer una lista con las acciones ayuda a que el proyecto sea accionable, es posible que estas acciones no existan aún en la organización, por lo que el proyecto puede ayudar a generar nuevas acciones. Es muy común que la acción definida por el stakeholder sea de muy alto nivel, en ese caso podemos tomar 2 caminos en el scoping: Proponer en el scoping que el proyecto informe a esa acción general. Generar a partir de esa acción general acciones más pequeñas. ¿Qué datos tenemos y cuáles necesitamos? Primero observemos que no se había hablado de los datos hasta este punto, lo anterior porque debemos primero pensar en el problema, entenderlo y luego ver con qué datos contamos para resolverlo. Si hacemos esto primero seguramente acabaremos desarrollando productos de datos “muertos” y no accionables. En este paso se le dará uso al Data Maturity Framework, queremos conocer cómo se guardan los datos, con qué frecuencia, en qué formato, en qué estructura, qué granularidad tiene, desde cuándo tenemos historia de estos datos, si existe un sesgo en su recolección, con qué frecuencia recolectan nueva información, sobrescribe la ya existente? Uno de los objetivos consiste en identificar si la granularidad, frecuencia y horizonte de tiempo en los datos corresponde a la granularidad, frecuencia y horizonte de tiempo de las acciones. ¿Cuál es el análisis que necesitamos hacer? En esta sección del scoping queremos definir qué tipo de análisis necesitamos hacer con los datos con los que contamos para cumplir con los objetivos definidos y generar las acciones identificadas. El análisis puede incluir métodos y herramientas de diferentes disciplinas: ciencias computacionales, ciencia de datos, machine learning, estadística, ciencias sociales. Existen distintos tipos de análisis, los 4 más comunes son: Descripción: Centrado en entender eventos y comportamientos del pasado. Aunque puede confundirse con business intelligence, debido a que ya definimos objetivos y acciones vamos a desarrollar un producto de datos. Para este tipo de análisis podemos ocupar métodos de aprendizaje no supervisado: clustering. Detección: Más concentrado en los eventos que están sucediendo. Detección de anomalías. Predicción: Concentrado en el futuro, prediciendo futuros eventos o comportamientos. Cambio en comportamiento: Concentrado en entender las causas de cambios en comportamientos de personas eventos, organizaciones, vecindarios, etc. En esta fase tenemos que responder las siguientes preguntas: ¿Qué tipo de análisis necesitaremos? Puede ser más de uno. ¿Cómo vamos a validar el análisis? ¿Qué validaciones se pueden hacer con los datos existentes? ¿Cómo podemos diseñar una prueba en campo para validar el análisis antes de que pongamos el producto en producción. Identificar qué acciones se cubren con cada análisis, debemos tener todas las acciones cubiertas. Ejemplos Los siguientes ejemplos forman parte del trabajo de DSSG, en cada uno de estos planteamientos intentaremos responder las siguientes preguntas: ¿Cuál es el objetivo? ¿Cómo se mide el objetivo? ¿Qué se optimiza? ¿Se puede optimizar? ¿Cuáles son los tradeoffs? ¿Que implicaciones éticas identificas? Envenenamiento por plomo: Hace unos años, comenzamos a trabajar con el Departamento de Salud Pública de Chicago para prevenir el envenenamiento por plomo. El objetivo inicial era aumentar la eficacia de sus inspecciones de peligro de plomo. Una forma de lograr ese objetivo sería concentrarse en los hogares que tienen peligros de plomo. Aunque fue útil, este enfoque no lograría su objetivo real, que era evitar que los niños se intoxicaran con plomo. Encontrar un hogar con peligros de plomo y repararlo solo es beneficioso si existe una alta probabilidad de que un niño presente (actualmente o en el futuro) se exponga al plomo. La siguiente iteración del objetivo fue maximizar la cantidad de inspecciones que detectan peligros de plomo en hogares donde hay un niño en riesgo (antes de que el niño se exponga al plomo). Finalmente, llegamos al objetivo final: identificar qué niños corren un alto riesgo de intoxicación por plomo en el futuro y luego dirigir las intervenciones a los hogares de esos niños.. High School Graduation: Uno de los mayores desafíos que enfrentan las escuelas hoy en día es ayudar a sus estudiantes a graduarse (a tiempo). Las tasas de graduación en los EE. UU. Son ~65%. Todos están interesados en identificar a los estudiantes que corren el riesgo de no graduarse a tiempo. Al hablar inicialmente con la mayoría de los distritos escolares, comienzan con un objetivo muy limitado de predecir qué niños es poco probable que se gradúen a tiempo. El primer paso es volver al objetivo de aumentar las tasas de graduación y preguntar si hay un subconjunto específico de estudiantes en riesgo que quieran identificar. ¿Qué pasaría si pudiéramos identificar a los estudiantes que tienen solo un 5% de probabilidades de estar en riesgo frente a los estudiantes que tienen un 95% de probabilidades de no graduarse a tiempo sin apoyo adicional? Si el objetivo es simplemente aumentar las tasas de graduación, es (probablemente) más fácil intervenir e influir en el primer grupo, mientras que el segundo grupo puede ser más desafiante debido a los recursos que necesita. ¿El objetivo es maximizar la probabilidad promedio/media/mediana de graduarse para una clase/escuela o es el objetivo enfocarse en los niños con mayor riesgo y maximizar la probabilidad de graduación del 10% inferior de los estudiantes? ¿O el objetivo es crear más equidad y disminuir la diferencia en la probabilidad de graduación a tiempo entre el cuartil superior y el cuartil inferior? Todos estos son objetivos razonables, pero las escuelas deben comprender, evaluar y decidir qué objetivos les interesan. Esta conversación a menudo los hace pensar más en definir analíticamente cuáles son sus objetivos organizacionales, así como las compensaciones.. Inspecciones: Hemos trabajado en varios proyectos que involucraron inspecciones, como con la EPA (Agencia de Protección Ambiental) y el Departamento de Conservación Ambiental del Estado de Nueva York para ayudarlos a priorizar qué instalaciones inspeccionar para detectar infracciones de eliminación de desechos, con la ciudad de Cincinnati para ayudar a identificar las propiedades en riesgo de violaciones del código para prevenir el deterioro -el proceso a través del cual una ciudad que funcionaba anteriormente, o parte de ella, cae en deterioro y decrepitud-, y con el Grupo del Banco Mundial para ayudarlos a priorizar qué denuncias de fraude y colusión investigar. En la mayoría de los problemas de inspección/investigación, hay muchas más entidades (viviendas, edificios, instalaciones, negocios, contratos) para inspeccionar que los recursos disponibles necesarios para realizar esas inspecciones. El objetivo con el que comienzan la mayoría de estas organizaciones es dirigir sus inspecciones a las entidades que tienen más probabilidades de violar las regulaciones existentes. Ese es un buen comienzo, pero la mayoría de estas organizaciones nunca pueden inspeccionar todas las instalaciones/hogares que pueden no cumplir con las normas, por lo que el objetivo que realmente buscan es la disuasión: reducir la cantidad total de instalaciones que estarán en violación. Un proceso de inspección ideal resultaría entonces en la reducción del número real de violaciones (encontradas o no), lo cual puede no ser lo mismo que un proceso de inspección que tiene como objetivo ser eficiente y aumentar la tasa de aciertos (% de inspección que resulta en violaciones). Programación de la recolección de residuos: Recientemente comenzamos a trabajar con Sanergy, una empresa social con sede en Kenia. Implementan inodoros portátiles en asentamientos urbanos informales y uno de sus mayores costos es contratar personas para vaciar los inodoros. Hoy en día, todos los inodoros se vacían todos los días, aunque existe una variación en cuánto se usan y cuánto se llenan. Para que puedan crecer y mantener bajos los costos, necesitan un enfoque más adaptable que pueda optimizar el cronograma de vaciado de los inodoros. El objetivo en este caso es asegurarse de no vaciar demasiado el inodoro cuando no está lleno, pero tampoco dejar que permanezca lleno porque entonces no se puede usar. Esto se traduce en una formulación que presiona para vaciar el inodoro lo más cerca posible de estar lleno al 100% sin llegar al 100%. "],["introducción-a-r.html", "Capítulo 2 Introducción a R 2.1 ¿Cómo obtener R? 2.2 ¿Qué es RStudio? 2.3 R como lenguaje orientado a objetos 2.4 Estructuras de almacenamiento 2.5 Funciones básicas de R 2.6 Estructuras de control 2.7 Guía de estilo", " Capítulo 2 Introducción a R R (R Core Team) es un entorno y lenguaje de programación que permite el análisis estadístico de información y reportes gráficos. Es ampliamente usado en investigación por la comunidad estadística en campos como la biomedicina, minería de datos, finanzas, seguros, entre otros. Ha ganado mucha popularidad en los últimos años al ser un software libre que está en constante crecimiento por las aportaciones de otros usuarios y que permite la interacción con software estadísticos como STATA, SAS, SPSS, etc. R permite la incorporación de librerías y paqueterías con funcionalidades específicas, por lo que es un lenguaje de programación muy completo y fácil de usar. 2.1 ¿Cómo obtener R? R puede ser fácilmente descargado de forma gratuita desde el sitio oficial http://www.r-project.org/. R está disponible para las plataformas Windows, Mac y Linux. 2.2 ¿Qué es RStudio? RStudio es un Entorno de Desarrollo Integrado (IDE, por sus siglas en inglés) para R. Este permite y facilita el desarrollo y ejecución de sintaxis para código en R, incluye una consola y proporciona herramientas para la gestión del espacio de trabajo. RStudio está disponible para Windows, Mac y Linux o para navegadores conectados a RStudio Server o RStudio Server Pro. Algunas de las principales características de Rstudio que lo hacen una gran herramienta para trabajar en R, son: Auto completado de código Sangría inteligente Resaltado de sintaxis Facilidad para definir funciones Soporte integrado Documentación integrada Administración de directorios y proyectos Visor de datos Depurador interactivo para corregir errores Conexión con Rmarkwon y Sweave La siguiente imagen muestra la forma en la que está estructurado RStudio. El orden de las ventanas puede ser elegido por el usuario, así como las características de tipo de letra, tamaño y color de fondo, entre otras características. Figure 2.1: Páneles de trabajo de Rstudio 2.3 R como lenguaje orientado a objetos R es un lenguaje de programación orientado a objetos (POO). Un objeto es “cualquier cosa con significado para el problema que se trata de resolver”. Los objetos tienen características fundamentales que permiten identificarlos, conocerlos y entender su comportamiento. De acuerdo con (Schildt 2009), estas características son: Identidad: Esta es la propiedad que da nombre a cada uno de los objetos y que permite declararlos, distinguirlos de manera única, usarlos y llamarlos para la representación de su contenido. Comportamiento: Esta es la propiedad que determina las operaciones que puede realizar el objeto, es decir, permite conocer las capacidades y alcances de la funcionalidad de cada objeto. El comportamiento permite conocer la interacción que puede existir con otros objetos y los resultados que generarán. Estructura: El estado se refiere a un conjunto de características o atributos específicos del objeto dados en un momento determinado, y que pueden cambiar en un instante de tiempo. En la programación orientada a objetos, un programa recolecta muchos objetos para ser tratado como un conjunto dinámico de objetos interactuando entre sí. Los objetos están definidos por: Atributos: Son las propiedades o características de los datos contenidos en un objeto. Los valores asociados a un objeto en un momento determinado del tiempo determinan su estado. Métodos: Acceden a los atributos de los objetos y determinan el comportamiento de los datos contenidos. 2.4 Estructuras de almacenamiento En R existen varios tipos de objectos que permiten que el usuario pueda almacenar la información para realizar procedimientos estadísticos y gráficos. Los principales objetos en R son vectores, matrices, arreglos, marcos de datos y listas. A continuación se presentan las características de estos objetos y la forma para crearlos. 2.4.1 Operadores de asignación En R se pueden hacer asignación de varias formas, a continuación se presentan los operadores disponibles para tal fin. &lt;- este es el operador de asignación a izquierda, es el más usado y recomendado. -&gt; este es el operador de asignación a derecha, no es frecuente su uso. = el símbolo igual sirve para hacer asignaciones pero NO se recomienda usarlo. &lt;&lt;- este es un operador de asignación global y sólo debe ser usado por usuarios avanzados. Ejemplo Almacene los valores 5.3, 4.6 y 25 en los objetos a, b y age respectivamente, use diferentes símbolos de asignación. Para hacer lo solicitado se podría usar el siguiente código. a &lt;- 5.3 # Recomendado 4.6 -&gt; b # No es usual age = 25 # No recomendado Aunque una asignación se puede hacer de tres formas diferentes, se recomienda sólo usar el símbolo &lt;-. 2.4.2 Variables Las variables sirven para almacenar un valor que luego vamos a utilizar en algún procedimiento. Para hacer la asignación de un valor a alguna variable se utiliza el operador &lt;- entre el valor y el nombre de la variable. A continuación un ejemplo sencillo. x &lt;- 5 (2 * x) + 3 ## [1] 13 En el siguiente ejemplo se crea la variable país y se almacena el nombre Colombia, luego se averigua el número de caracteres de la variable país. pais &lt;- &quot;México&quot; nchar(pais) ## [1] 6 También existen variables lógicas y estas toman los valores verdadero (TRUE) o falso (FALSE) dependiendo del resultado lógico puesto a prueba. Ejemplo: y &lt;- 10 y == (5 + 3 + 2) ## [1] TRUE y != 5 + 5 ## [1] FALSE 2.4.3 Vectores Los vectores vectores son arreglos ordenados en los cuales se puede almacenar información de tipo numérico (variable cuantitativa), alfanumérico (variable cualitativa) o lógico (TRUE o FALSE), pero no mezclas de éstos. La función de R para crear un vector es c() y que significa concatenar; dentro de los paréntesis de esta función se ubica la información a almacenar. Una vez construido el vector se acostumbra a etiquetarlo con un nombre corto y representativo de la información que almacena, la asignación se hace por medio del operador &lt;- entre el nombre y el vector. A continuación se presenta un ejemplo de cómo crear tres vectores que contienen las respuestas de cinco personas a tres preguntas que se les realizaron. edad &lt;- c(15, 19, 13, NA, 20) deporte &lt;- c(TRUE, TRUE, NA, FALSE, TRUE) sexo &lt;- c(&quot;Hombre&quot;, &quot;Mujer&quot;, &quot;Hombre&quot;, &quot;Hombre&quot;, &quot;Mujer&quot;) El vector edad es un vector cuantitativo y contiene las edades de las 5 personas. En la cuarta posición del vector se colocó el símbolo NA que significa Not Available debido a que no se registró la edad para esa persona. Al hacer una asignación se acostumbra a dejar un espacio antes y después del operador &lt;- de asignación. El segundo vector es llamado deporte y es un vector lógico que almacena las respuestas a la pregunta de si la persona practica deporte, nuevamente aquí hay un NA para la tercera persona. El último vector sexo contiene la información del sexo de cada persona, como esta variable es cualitativa es necesario usar las comillas ” ” para encerrar las respuestas. ¡¡ RECORDAR !! Cuando se usa NA para representar una información Not Available no se deben usar comillas. Es posible usar comillas ‘sencillas’ o comillas “dobles” para ingresar valores de una variable cualitativa. Si se desea ver lo que está almacenado en cada uno de estos vectores, se debe escribir en la consola de R el nombre de uno de los objetos y luego se presiona la tecla enter o intro, al realizar esto lo que se obtiene se muestra a continuación. edad ## [1] 15 19 13 NA 20 deporte ## [1] TRUE TRUE NA FALSE TRUE sexo ## [1] &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Hombre&quot; &quot;Mujer&quot; 2.4.3.1 ¿Cómo extraer elementos de un vector? Para extraer un elemento almacenado dentro un vector se usan los corchetes [] y dentro de ellos la posición o posiciones que interesan. Ejemplo Si queremos extraer la edad de la tercera persona escribimos el nombre del vector y luego \\[3\\] para indicar la tercera posición de edad, a continuación el código. edad[3] ## [1] 13 Si queremos conocer el sexo de la segunda y quinta persona, escribimos el nombre del vector y luego, dentro de los corchetes, escribimos otro vector con las posiciones 2 y 5 que nos interesan así: \\(c(2, 5)\\), a continuación el código. sexo[c(2, 5)] ## [1] &quot;Mujer&quot; &quot;Mujer&quot; Si nos interesan las respuestas de la práctica de deporte, excepto la de la persona 3, usamos \\[-3\\] luego del nombre del vector para obtener todo, excepto la tercera posición. deporte[-3] ## [1] TRUE TRUE FALSE TRUE ¡¡ RECORDAR !! Si desea extraer varios posiciones de un vector NUNCA escriba esto: mi_vector[2, 5, 7]. Tiene que crear un vector con las posiciones y luego colocarlo dentro de los corchetes así: \\[mi\\_vector[c(2, 5, 7)]\\] 2.4.4 Matrices Las matrices son arreglos rectangulares de filas y columnas con información numérica, alfanumérica o lógica. Para construir una matriz se usa la función matrix( ). Por ejemplo, para crear una matriz de 4 filas y 5 columnas (de dimensión 4×5) con los primeros 20 números positivos se escribe el código siguiente en la consola. mimatriz &lt;- matrix(data = 1:20, nrow = 4, ncol = 5, byrow = FALSE) El argumento data de la función sirve para indicar los datos que se van a almacenar en la matriz, los argumentos nrow y ncol sirven para definir la dimensión de la matriz y por último el argumento byrow sirve para indicar si la información contenida en data se debe ingresar por filas o no. Para observar lo que quedó almacenado en el objeto mimatriz se escribe en la consola el nombre del objeto seguido de la tecla enter o intro. mimatriz ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 5 9 13 17 ## [2,] 2 6 10 14 18 ## [3,] 3 7 11 15 19 ## [4,] 4 8 12 16 20 2.4.4.1 ¿Cómo extraer elementos de una matriz? Al igual que en el caso de los vectores, para extraer elementos almacenados dentro de una matriz se usan los corchetes [ , ] y dentro, separado por una coma, el número de fila(s) y el número de columna(s) que nos interesan. Ejemplo Si queremos extraer el valor almacenado en la fila 3 y columna 4 usamos el siguiente código. mimatriz[3, 4] ## [1] 15 Si queremos recuperar toda la fila 2 usamos el siguiente código. mimatriz[2, ] # No se escribe nada luego de la coma ## [1] 2 6 10 14 18 Si queremos recuperar toda la columna 5 usamos el siguiente código. mimatriz[, 5] # No se escribe nada antes de la coma ## [1] 17 18 19 20 Si queremos recuperar la matriz original sin las columnas 2 y 4 usamos el siguiente código. mimatriz[, -c(2, 4)] # Las columnas como vector ## [,1] [,2] [,3] ## [1,] 1 9 17 ## [2,] 2 10 18 ## [3,] 3 11 19 ## [4,] 4 12 20 Si queremos recuperar la matriz original sin la fila 1 ni columna 3 usamos el siguiente código. mimatriz[-1, -3] # Signo de menos para eliminar ## [,1] [,2] [,3] [,4] ## [1,] 2 6 14 18 ## [2,] 3 7 15 19 ## [3,] 4 8 16 20 2.4.5 Arreglos Un arreglo es una matriz de varias dimensiones con información numérica, alfanumérica o lógica. Para construir una arreglo se usa la función array( ). Por ejemplo, para crear un arreglo de 3 × 4 × 2 con las primeras 24 letras minúsculas del alfabeto se escribe el siguiente código. miarray &lt;- array(data = letters[1:24], dim=c(3, 4, 2)) El argumento data de la función sirve para indicar los datos que se van a almacenar en el arreglo y el argumento dim sirve para indicar las dimensiones del arreglo. Para observar lo que quedó almacenado en el objeto miarray se escribe en la consola lo siguiente. miarray ## , , 1 ## ## [,1] [,2] [,3] [,4] ## [1,] &quot;a&quot; &quot;d&quot; &quot;g&quot; &quot;j&quot; ## [2,] &quot;b&quot; &quot;e&quot; &quot;h&quot; &quot;k&quot; ## [3,] &quot;c&quot; &quot;f&quot; &quot;i&quot; &quot;l&quot; ## ## , , 2 ## ## [,1] [,2] [,3] [,4] ## [1,] &quot;m&quot; &quot;p&quot; &quot;s&quot; &quot;v&quot; ## [2,] &quot;n&quot; &quot;q&quot; &quot;t&quot; &quot;w&quot; ## [3,] &quot;o&quot; &quot;r&quot; &quot;u&quot; &quot;x&quot; 2.4.5.1 ¿Cómo extraer elementos de un arreglo? Para recuperar elementos almacenados en un arreglo se usan también corchetes, y dentro de los corchetes, las coordenadas del objeto de interés. Ejemplo Si queremos extraer la letra almacenada en la fila 1 y columna 3 de la segunda capa de miarray usamos el siguiente código. miarray[1, 3, 2] # El orden es importante ## [1] &quot;s&quot; Si queremos extraer la segunda capa completa usamos el siguiente código. miarray[,, 2] # No se coloca nada en las primeras posiciones ## [,1] [,2] [,3] [,4] ## [1,] &quot;m&quot; &quot;p&quot; &quot;s&quot; &quot;v&quot; ## [2,] &quot;n&quot; &quot;q&quot; &quot;t&quot; &quot;w&quot; ## [3,] &quot;o&quot; &quot;r&quot; &quot;u&quot; &quot;x&quot; Si queremos extraer la tercera columna de todas las capas usamos el siguiente código. miarray[, 3,] # No se coloca nada en las primeras posiciones ## [,1] [,2] ## [1,] &quot;g&quot; &quot;s&quot; ## [2,] &quot;h&quot; &quot;t&quot; ## [3,] &quot;i&quot; &quot;u&quot; 2.4.6 Data Frames El marco de datos marco de datos o data frame es uno de los objetos más utilizados porque permite agrupar vectores con información de diferente tipo (numérica, alfanumérica o lógica) en un mismo objeto, la única restricción es que los vectores deben tener la misma longitud. Para crear un marco de datos se usa la función data.frame( ), como ejemplo vamos a crear un marco de datos con los vectores edad, deporte y sexo definidos anteriormente. mi_data_frame &lt;- data.frame(edad, deporte, sexo) Una vez creado el objeto mi_data_frame podemos ver el objeto escribiendo su nombre en la consola, a continuación se muestra lo que se obtiene. mi_data_frame ## edad deporte sexo ## 1 15 TRUE Hombre ## 2 19 TRUE Mujer ## 3 13 NA Hombre ## 4 NA FALSE Hombre ## 5 20 TRUE Mujer De la salida anterior vemos que el marco de datos tiene 3 variables (columnas) cuyos nombres coinciden con los nombres de los vectores creados anteriormente, los números consecutivos al lado izquierdo son sólo de referencia y permiten identificar la información para cada persona en el conjunto de datos. Ejercicios: Use funciones o procedimientos (varias líneas) de R para responder cada una de las siguientes preguntas. Construya un vector con 5 nombres de personas. Construya un vector con las edades de las 5 personas anteriores. Construya un marco de datos o data frame con las respuestas de 5 personas a las preguntas: ¿Cuál es su nombre? Sexo de la persona ¿Cuál es su edad en años? ¿En qué alcaldía vive? ¿En qué alcaldía trabaja? 2.4.7 Listas Las listas son otro tipo de objeto muy usado para almacenar objetos de diferente tipo. La instrucción para crear una lista es list( ). A continuación vamos a crear una lista que contiene tres objetos: un vector con 5 números aleatorios llamado mivector, una matriz de dimensión 6×2 con los primeros doce números enteros positivos llamada matriz2 y el tercer objeto será el marco de datos mi_data_frame creado en el apartado anterior. Las instrucciones para crear la lista requerida se muestran a continuación. set.seed(12345) mivector &lt;- runif(n=5) matriz2 &lt;- matrix(data=1:12, ncol=6) milista &lt;- list(E1=mivector, E2=matriz2, E3=mi_data_frame) La función set.seed de la línea número 1 sirve para fijar la semilla de tal manera que los números aleatorios generados en la segunda línea con la función runif sean siempre los mismos. En la última línea del código anterior se construye la lista, dentro de la función list se colocan los tres objetos mivector, matriz2 y mi_data_frame. Es posible colocarle un nombre especial a cada uno de los elementos de la lista, en este ejemplo se colocaron los nombres E1, E2 y E3 para cada uno de los tres elementos. Para observar lo que quedó almacenado en la lista se escribe milista en la consola y el resultado se muestra a continuación. milista ## $E1 ## [1] 0.7209039 0.8757732 0.7609823 0.8861246 0.4564810 ## ## $E2 ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 3 5 7 9 11 ## [2,] 2 4 6 8 10 12 ## ## $E3 ## edad deporte sexo ## 1 15 TRUE Hombre ## 2 19 TRUE Mujer ## 3 13 NA Hombre ## 4 NA FALSE Hombre ## 5 20 TRUE Mujer 2.4.7.1 ¿Cómo extraer elementos de una lista? Para recuperar los elementos almacenadas en una lista se usa el operador $, corchetes dobles [[]] o corchetes sencillos []. A continuación unos ejemplos para entender cómo extraer elementos de una lista. Ejemplos Si queremos la matriz almacenada con el nombre de E2 dentro del objeto milista se puede usar el siguiente código. milista$E2 ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 3 5 7 9 11 ## [2,] 2 4 6 8 10 12 Es posible indicar la posición del objeto en lugar del nombre, para eso se usan los corchetes dobles. milista[[2]] ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 3 5 7 9 11 ## [2,] 2 4 6 8 10 12 El resultado obtenido con milista$E2 y milista[[2]] es exactamente el mismo. Vamos ahora a solicitar la posición 2 pero usando corchetes sencillos. milista[2] ## $E2 ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 1 3 5 7 9 11 ## [2,] 2 4 6 8 10 12 La apariencia de este último resultado es similar, no igual, al encontrado al usar $ y [[]]. Para ver la diferencia vamos a pedir la clase a la que pertenecen los tres últimos objetos usando la función class. A continuación el código usado. class(milista$E2) ## [1] &quot;matrix&quot; &quot;array&quot; class(milista[[2]]) ## [1] &quot;matrix&quot; &quot;array&quot; class(milista[2]) ## [1] &quot;list&quot; De lo anterior se observa claramente que cuando usamos $ o [[]] el resultado es el objeto almacenado, una matriz. Cuando usamos [] el resultado es una lista cuyo contenido es el objeto almacenado. 2.4.8 Ejercicios Use funciones o procedimientos (varias líneas) de R para responder cada una de las siguientes preguntas. Construya un vector con la primeras 20 letras MAYÚSCULAS usando la función LETTERS. Construya una matriz de 10×10 con los primeros 100 números positivos pares. Construya una matriz identidad de dimensión 3×3. Recuerde que una matriz identidad tiene sólo unos en la diagonal principal y los demás elementos son cero. Construya una lista con los anteriores tres objetos creados. Construya un marco de datos o data frame con las respuestas de 5 personas de su trabajo a las preguntas: ¿Cuál es su nombre? ¿Cuál es su antigüedad en la empresa? ¿Cuál es su puesto? ¿Tiene usted algún producto contratado con la empresa? (Sí / No) ¿Cuál? ¿Cuál es el error al ejecutar el siguiente código? ¿A qué se debe? edad &lt;- c(15, 19, 13, NA, 20) deporte &lt;- c(TRUE, TRUE, NA, FALSE, TRUE) sexo &lt;- c(NA, &#39;Hombre&#39;, &#39;Hombre&#39;, NA, &#39;Mujer&#39;) matrix(edad, deporte, sexo) 2.5 Funciones básicas de R En este capítulo se presentará lo que es una función y se mostrarán varias funciones básicas que son útiles para realizar diversas tareas. 2.5.1 ¿Qué es una función de R? En la figura de abajo se muestra una ilustración de lo que es una función o máquina general. Hay unas entradas (inputs) que luego son procesadas dentro de la caja para generar unas salidas (outputs). Un ejemplo de una función o máquina muy común en nuestras casas es la licuadora. Si a una licuadora le ingresamos leche, fresas, azúcar y hielo, el resultado será un delicioso jugo de fresa. Las funciones en R se caracterizan por un nombre corto y que dé una idea de lo que hace la función. Los elementos que pueden ingresar (inputs) a la función se llaman parámetros o argumentos y se ubican dentro de paréntesis, el cuerpo de la función se ubica dentro de llaves y es ahí donde se procesan los inputs para convertirlos en outputs A continuación se muestra la estructura general para definir una función. nombre_de_funcion &lt;- function(parametro1, parametro2, ...) { tareas internas tareas internas tareas internas return(salida) } Cuando usamos una función sólo debemos escribir bien el nombre e ingresar correctamente los parámetros de la función, el cuerpo de la función ni lo vemos ni lo debemos modificar. A continuación se presenta un ejemplo de cómo usar la función mean para calcular un promedio. notas &lt;- c(4.0, 1.3, 3.8, 2.0) # Notas de un estudiante mean(notas) ## [1] 2.775 2.5.2 Operaciones básicas En R se pueden hacer diversas operaciones usando operadores binarios. Este tipo de operadores se denomina binarios porque actúan entre dos objetos, a continuación el listado. + operador binario para sumar. - operador binario para restar. * operador binario para multiplicar. / operador binario para dividir. ^ operador binario para potencia. %/% operador binario para obtener el cociente en una división (número entero). %% operador binario para obtener el residuo en una división. A continuación se presentan ejemplos de cómo usar las anteriores funciones. 6 + 4 # Para sumar dos números ## [1] 10 a &lt;- c(1, 3, 2) b &lt;- c(2, 0, 1) # a y b de la misma dimensión a + b # Para sumar los vectores a y b miembro a miembro ## [1] 3 3 3 a - b # Para restar dos vectores a y b miembro a miembro ## [1] -1 3 1 a * b # Para multiplicar ## [1] 2 0 2 a / b # Para dividir ## [1] 0.5 Inf 2.0 a ^ b # Para potencia ## [1] 1 1 2 7 %/% 3 # Para saber las veces que cabe 3 en 7 ## [1] 2 7 %% 3 # Para saber el residuo al dividir 7 entre 3 ## [1] 1 2.5.3 Pruebas lógicas En R se puede verificar si un objeto cumple una condición dada, a continuación el listado de las pruebas usuales. &lt; para saber si un número es menor que otro. &gt; para saber si un número es mayor que otro. == para saber si un número es igual que otro. &lt;= para saber si un número es menor o igual que otro. &gt;= para saber si un número es mayor o igual que otro. A continuación se presentan ejemplos de cómo usar las anteriores funciones. 5 &lt; 12 # ¿Será 5 menor que 12? ## [1] TRUE # Comparando objetos x &lt;- 5 y &lt;- 20 / 4 x == y # ¿Será x igual a y? ## [1] TRUE # Usando vectores a &lt;- c(1, 3, 2) b &lt;- c(2, 0, 1) a &gt; b # Comparación término a término ## [1] FALSE TRUE TRUE a == b # Comparación de igualdad término a término ## [1] FALSE FALSE FALSE 2.5.4 Operadores lógicos En R están disponibles los operadores lógicos negación, conjunción y disyunción. A continuación el listado de los operadores entre los elementos x e y. !x # Negación de x x &amp; y # Conjunción entre x e y x &amp;&amp; y x | y # Disyunción entre x e y x || y xor(x, y) A continuación se presentan ejemplos de cómo usar el símbolo de negación !. ans &lt;- c(TRUE, FALSE, TRUE) !ans # Negando las respuestas almacenadas en ans ## [1] FALSE TRUE FALSE x &lt;- c(5, 1.5, 2, 3, 2) !(x &lt; 2.5) # Negando los resultados de una prueba ## [1] TRUE FALSE FALSE TRUE FALSE A continuación se presentan ejemplos de cómo aplicar la conjunción &amp; y &amp;&amp;. x &lt;- c(5, 1.5, 2) # Se construyen dos vectores para la prueba y &lt;- c(4, 6, 3) x &lt; 4 # ¿Serán los elementos de x menores que 4? ## [1] FALSE TRUE TRUE y &gt; 5 # ¿Serán los elementos de y mayores que 5? ## [1] FALSE TRUE FALSE x &lt; 4 &amp; y &gt; 5 # Conjunción entre las pruebas anteriores. ## [1] FALSE TRUE FALSE x &lt; 4 &amp;&amp; y &gt; 5 # Conjunción vectorial ## [1] FALSE Note las diferencias entre los dos últimos ejemplos, cuando se usa &amp; se hace una prueba término a término y el resultado es un vector, cuando se usa &amp;&amp; se aplica la conjunción al vector de resultados obtenido con &amp;. 2.5.5 Funciones sobre vectores En R podemos destacar las siguientes funciones básicas sobre vectores numéricos. min: para obtener el mínimo de un vector. max: para obtener el máximo de un vector. length: para determinar la longitud de un vector. range: para obtener el rango de valores de un vector, entrega el mínimo y máximo. sum: entrega la suma de todos los elementos del vector. prod: multiplica todos los elementos del vector. which.min: nos entrega la posición en donde está el valor mínimo del vector. which.max: nos da la posición del valor máximo del vector. rev: invierte un vector. Ejemplo Construir en vector llamado myvec con los siguientes elementos: 5, 3, 2, 1, 2, 0, NA, 0, 9, 6. Luego aplicar todas las funciones anteriores para verificar el funcionamiento de las mismas. myvec &lt;- c(5, 3, 2, 1, 2, 0, NA, 0, 9, 6) myvec ## [1] 5 3 2 1 2 0 NA 0 9 6 min(myvec) # Oops, no aparece el mínimo que es Cero. ## [1] NA min(myvec, na.rm=TRUE) # Usamos na.rm = TRUE para remover el NA ## [1] 0 max(myvec, na.rm=T) # Para obtener el valor máximo ## [1] 9 range(myvec, na.rm=T) # Genera min y max simultáneamente ## [1] 0 9 sum(myvec, na.rm=T) # La suma de los valores internos ## [1] 28 prod(myvec, na.rm=T) # El productor de los valores internos ## [1] 0 which.min(myvec) # Posición del valor mínimo 0 en el vector ## [1] 6 which.max(myvec) # Posición del valor máximo 9 en el vector ## [1] 9 De las dos últimas líneas podemos destacar lo siguiente: NO es necesario usar na.rm = TRUE para remover el NA dentro de las funciones which.min ni which.max. El valor mínimo 0 aparece en las posicione 2.5.6 Función rep En R podemos crear repeticiones usando la función rep, la estructura de esta función es: rep(x, times=1, length.out=NA, each=1) Los argumentos de esta función son: x: vector con los elementos a repetir. times: número de veces que el vector x se debe repetir. length.out: longitud deseada para el vector resultante. each: número de veces que cada elemento de x se debe repetir. Ejemplo Construya las siguientes repeticiones usando la función rep, no lo haga ingresando número por número. 1 2 3 4 1 2 3 4 1 1 2 2 3 3 4 4 1 1 2 3 3 4 1 1 2 2 3 3 4 4 La clave para construir una repetición es, descubrir la semilla o elemento que se repite. Las instrucciones para obtener las repeticiones anteriores se muestra a continuación. rep(x=1:4, times=2) ## [1] 1 2 3 4 1 2 3 4 rep(x=1:4, times=c(2,2,2,2)) ## [1] 1 1 2 2 3 3 4 4 rep(x=1:4, times=c(2,1,2,1)) ## [1] 1 1 2 3 3 4 rep(x=1:4, each=2) ## [1] 1 1 2 2 3 3 4 4 2.5.7 Función seq En R podemos crear secuencias de números de una forma sencilla usando la función seq, la estructura de esta función es: seq(from=1, to=1, by, length.out) Los argumentos de esta función son: from: valor de inicio de la secuencia. to: valor de fin de la secuencia, no siempre se alcanza. by: incremento de la secuencia. length.out: longitud deseado de la secuencia. Ejemplo Construya las siguientes tres secuencias usando la función seq. Once valores igualmente espaciados desde 0 hasta 1. Una secuencia de dos en dos comenzando en 1. Una secuencia desde 1 con un salto de \\(\\pi\\) y sin pasar del número 9. El código necesario para obtener las secuencias se muestra a continuación. seq(from=0, to=1, length.out = 11) ## [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 seq(from=1, to=9, by=2) # concuerda con final ## [1] 1 3 5 7 9 seq(from=1, to=9, by=pi) # se mantiene por debajo del final ## [1] 1.000000 4.141593 7.283185 En R existe el operador binario : que sirve para construir secuencias de uno en uno fácilmente. Revise los siguientes ejemplos para entender el funcionamiento del operador :. 2:8 ## [1] 2 3 4 5 6 7 8 3:-5 ## [1] 3 2 1 0 -1 -2 -3 -4 -5 pi:6 # secuencia real ## [1] 3.141593 4.141593 5.141593 6:pi # secuencia entera ## [1] 6 5 4 2.5.8 EJERCICIOS Use funciones o procedimientos (varias líneas) de R para responder (al menos) a 15 de las siguientes preguntas. ¿Qué cantidad de dinero sobra al repartir $10,000 entre 3 personas? ¿Es el número 4,560 divisible por 3? Construya un vector con los números enteros del 2 al 87. ¿Cuáles de esos números son divisibles por 7? Construya dos vectores, el primero con los números enteros desde 7 hasta 3, el segundo vector con los primeros cinco números positivos divisibles por 5. Sea A la condición de ser par en el primer vector. Sea B la condición de ser mayor que 10 en el segundo vector. ¿En cuál de las 5 posiciones se cumple A y B simultáneamente? Construya un vector con los siguientes elementos: 1, -4, 5, 9, -4. Escriba un procedimiento para extraer las posiciones donde está el valor mínimo en el vector. Calcular \\(8!\\) Evaluar la siguiente suma \\(\\sum_{i=3}^{i=7}e^i\\) Evaluar el siguiente producto \\(\\prod_{i=1}^{i=10}\\log\\sqrt{i}\\) Construya un vector cualquiera e inviértalo, es decir, que el primer elemento quede de último, el segundo de penúltimo y así sucesivamente. Compare su resultado con el de la función rev. Crear el vector: \\(1, 2, 3, \\ldots, 19, 20\\). Crear el vector: \\(20, 19, \\ldots , 2, 1\\). Crear el vector: \\(1, -2, 3, -4, 5, -6, \\ldots, 19, -20\\). Crear el vector: \\(0.1^3, 0.2^1, 0.1^6, 0.2^4, . . . , 0.1^{36}, 0.2^{34}\\). Calcular lo siguiente: \\(\\sum_{i=10}^{100}(i^3+4i^2)\\) y \\(\\sum_{i=1}^{25}\\left( \\frac{2^i}{i} + \\frac{3^i}{i^2} \\right)\\). En R hay unas bases de datos incluidas, una de ellas es la base de datos llamada mtcars. Para conocer las variables que están en mtcars usted puede escribir en la consola ?mtcars o también help(mtcars). De la base mtcars obtenga bases de datos que cumplan las siguientes condiciones. Autos que tengan un rendimiento menor a 18 millas por galón de combustible. Autos que tengan 4 cilindros. Autos que pesen más de 2500 libras y tengan transmisión manual. 2.6 Estructuras de control En R se disponen de varias instrucciones de control para facilitar los procedimientos que un usuario debe realizar. A continuación se explican esas instrucciones de control. 2.6.1 Instrucción if Esta instrucción sirve para realizar un conjunto de operaciones si se cumple cierta condición. A continuación se muestra la estructura básica de uso. if (condicion) { operación 1 operación 2 ... operación final } Ejemplo Una secretaria recibe la información del salario básico semanal de un empleado y las horas trabajadas durante la semana por ese empleado. El salario básico es la remuneración por 40 horas de labor por semana, las horas extra son pagadas a 150 pesos. Escriba el procedimiento en R que debe usar la secretaria para calcular el salario semanal de un empleado que trabajó 45 horas y tiene salario básico de 5 mil pesos. El código para calcular el salario final del empleado es el siguiente: sal &lt;- 5000 # Salario básico por semana hlab &lt;- 45 # Horas laboradas por semana if(hlab &gt; 40) { hext &lt;- hlab - 40 salext &lt;- hext * 150 sal &lt;- sal + salext } sal # Salario semanal ## [1] 5750 2.6.2 Instrucción if else Esta instrucción sirve para realizar un conjunto de operaciones cuando NO se cumple cierta condición evaluada por un if. A continuación se muestra la estructura básica de uso. if (condicion) { operación 1 operación 2 ... operación final } else { operación 1 operación 2 ... operación final } Ejemplo sal &lt;- 5000 # Salario básico por semana hlab &lt;- 40 # Horas laboradas por semana if (hlab &gt; 40) { hext &lt;- hlab - 40 salext &lt;- hext * 150 sal &lt;- sal + salext } else { h_faltantes &lt;- 40 - hlab sueldo_sobrante &lt;- h_faltantes * sal/40 sal &lt;- sal - sueldo_sobrante } # Cálculo de salario por horas trabajadas sal ## [1] 5000 2.6.3 Instrucción ifelse Se recomienda usar la instrucción ifelse cuando hay una sola instrucción para el caso if y para el caso else. A continuación se muestra la estructura básica de uso. ifelse(condición, operación SI cumple, operación NO cumple) Ejemplo Suponga que usted recibe un vector de números enteros, escriba un procedimiento que diga si cada elemento del vector es par o impar. x &lt;- c(5, 3, 2, 8, -4, 1) ifelse(x %% 2 == 0, &#39;Es par&#39;, &#39;Es impar&#39;) ## [1] &quot;Es impar&quot; &quot;Es impar&quot; &quot;Es par&quot; &quot;Es par&quot; &quot;Es par&quot; &quot;Es impar&quot; 2.6.4 Instrucción else if En caso de querer actuar de forma distinta dependiendo de la condición, puede especificarse más de una condición de la siguiente manera: sal &lt;- 5000 # Salario básico por semana hlab &lt;- 20 # Horas laboradas por semana if (hlab &gt; 40) { hext &lt;- hlab - 40 salext &lt;- hext * 150 sal &lt;- sal + salext print(paste0(&quot;Pago semanal: $&quot;, sal)) } else if (hlab &lt; 16) { h_faltantes &lt;- 40 - hlab sueldo_sobrante &lt;- h_faltantes * sal/40 sal &lt;- sal - 1.05 * sueldo_sobrante print(&quot;despedido&quot;) print(paste0(&quot;liquidación: $&quot;, sal)) } else { h_faltantes &lt;- 40 - hlab sueldo_sobrante &lt;- h_faltantes * sal/40 sal &lt;- sal - sueldo_sobrante print(paste0(&quot;Pago con descuento: $&quot;, sal)) }# Cálculo de salario por horas trabajadas ## [1] &quot;Pago con descuento: $2500&quot; Otro caso: sal &lt;- 5000 # Salario básico por semana hlab &lt;- 10 # Horas laboradas por semana if (hlab &gt; 40) { hext &lt;- hlab - 40 salext &lt;- hext * 150 sal &lt;- sal + salext print(paste0(&quot;Pago semanal: $&quot;, sal)) } else if (hlab &lt; 16) { h_faltantes &lt;- 40 - hlab sueldo_sobrante &lt;- h_faltantes * sal/40 sal &lt;- sal - 1.05 * sueldo_sobrante print(&quot;¡Empleado despedido! :O&quot;) print(paste0(&quot;liquidación: $&quot;, sal)) } else { h_faltantes &lt;- 40 - hlab sueldo_sobrante &lt;- h_faltantes * sal/40 sal &lt;- sal - sueldo_sobrante print(paste0(&quot;Pago con descuento: $&quot;, sal)) }# Cálculo de salario por horas trabajadas ## [1] &quot;¡Empleado despedido! :O&quot; ## [1] &quot;liquidación: $1062.5&quot; 2.6.5 Instrucción for La instrucción for es muy útil para repetir un procedimiento cierta cantidad de veces. A continuación se muestra la estructura básica de uso. for (i in secuencia) { operación 1 operación 2 ... operación final } Ejemplo Escriba un procedimiento para crear 10 muestras de tamaño 100 de una distribución uniforme entre uno y tres. Para cada una de las muestra, se debe contar el número de elementos de la muestra que fueron mayores o iguales a 2.5. nrep &lt;- 10 # Número de repeticiones n &lt;- 100 # Tamaño de la muestra conteo &lt;- numeric(nrep) # Vector para almacenar el conteo for (i in 1:nrep) { x &lt;- runif(n=n, min=1, max=3) conteo[i] &lt;- sum(x &gt;= 2.5) } conteo # Para obtener el conteo ## [1] 24 37 28 26 30 18 29 23 19 19 2.6.6 Instrucción while La instrucción while es muy útil para repetir un procedimiento siempre que se cumple una condición. A continuación se muestra la estructura básica de uso. while (condición) { operación 1 operación 2 ... operación final } Ejemplo Suponga que se lanza una moneda en la cual el resultado es cara o cruz. Escribir un procedimiento que simule lanzamientos hasta que el número de caras obtenidas sea 5. El procedimiento debe entregar el historial de lanzamientos. Para simular el lanzamiento de una moneda se puede usar la función sample y definiendo el vector resultados con size=1 para simular un lanzamiento, a continuación el código y tres pruebas ilustrativas. resultados &lt;- c(&#39;Cara&#39;, &#39;Cruz&#39;) sample(x=resultados, size=1) # Prueba 1 ## [1] &quot;Cruz&quot; Una vez seamos capaces de simular un lanzamiento podemos escribir el procedimiento para generar tantos lanzamientos hasta que se cumpla la condición. El código mostrado abajo permite hacer lo solicitado. num.lanza &lt;- 0 # Contador de lanzamientos num.caras &lt;- 0 # Contados de caras obtenidas historial &lt;- NULL # Vector vacío para almacenar while (num.caras &lt; 5) { res &lt;- sample(x=resultados, size=1) num.lanza &lt;- num.lanza + 1 historial[num.lanza] &lt;- res if (res == &#39;Cara&#39;) { num.caras &lt;- num.caras + 1 } } historial ## [1] &quot;Cruz&quot; &quot;Cruz&quot; &quot;Cruz&quot; &quot;Cruz&quot; &quot;Cara&quot; &quot;Cara&quot; &quot;Cruz&quot; &quot;Cruz&quot; &quot;Cara&quot; &quot;Cara&quot; ## [11] &quot;Cara&quot; num.lanza ## [1] 11 La instrucción for se usa cuando sabemos el número de veces que se debe repetir el procedimiento, mientras que la instrucción while se usa cuando debemos repetir un procedimiento cuando se cumpla una condición. 2.6.7 Instrucción repeat La instrucción while es muy útil para repetir un procedimiento siempre que se cumple una condición. A continuación se muestra la estructura básica de uso. repeat { operación 1 operación 2 ... operación final if (condición) break } Ejemplo Escribir un procedimiento para ir aumentando de uno en uno el valor de x hasta que x sea igual a siete El procedimiento debe imprimir por pantalla la secuencia de valores de x. x &lt;- 3 # Valor de inicio repeat { print(x) x &lt;- x + 1 if (x == 8) { break } } ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 La instrucción break sirve para salir de un procedimiento iterativo. 2.7 Guía de estilo Así como en el español existen reglas ortográficas, la escritura de códigos en R también tiene unas reglas que se recomienda seguir para evitar confusiones. Tener una buena guía de estilo es importante para que el código creado por usted sea fácilmente entendido por sus lectores. No existe una única y mejor guía de estilo para escritura en R, sin embargo aquí vamos a mostrar unas sugerencias basadas en la guía llamada The tidyverse style guidee. 2.7.1 Nombres de los archivos Se sugiere que el nombre usado para nombrar un archivo tenga sentido y que termine con extensión “.R”. A continuación dos ejemplos de como nombrar bien y mal un archivo. Bien: \"2020-analisis_exploratorio.R Mal: ju89HR56_74.R 2.7.2 Nombres de los objetos Se recomienda usar los símbolos _ dentro de los nombres de objetos. Para las variables es preferible usar letras minúsculas (pesomaiz o peso_maiz) o utilizar la notación camello iniciando en minúscula (pesoMaiz). Para las funciones se recomienda usar la notación camello iniciando todas la palabras en mayúscula (PlotRes). Para los nombres de las constantes se recomienda que inicien con la letra k (kPrecioBus). 2.7.3 Longitud de una línea de código Se recomienda que cada línea tenga como máximo 80 caracteres. Si una línea es muy larga se debe cortar siempre por una coma. 2.7.4 Espacios Use espacios alrededor de todos los operadores binarios (=, +, -, &lt;-, etc.). Los espacios alrededor del símbolo = son opcionales cuando se usan para ingresar valores dentro de una función. Así como en español, nunca coloque espacio antes de una coma, pero siempre use espacio luego de una coma. A continuación ejemplos de buenas y malas prácticas. tab &lt;- table(df[df$days &lt; 0, 2]) # Bien tot &lt;- sum(x[, 1]) # Bien tot &lt;- sum(x[1, ]) # Bien tab &lt;- table(df[df$days&lt;0, 2]) # Faltan espacios alrededor &#39;&lt;&#39; tab &lt;- table(df[df$days &lt; 0,2]) # Falta espacio luego de coma tab &lt;- table(df[df$days &lt; 0 , 2]) # Sobra espacio antes de coma tab&lt;- table(df[df$days &lt; 0, 2]) # Falta espacio antes de &#39;&lt;-&#39; tab&lt;-table(df[df$days &lt; 0, 2]) # Falta espacio alrededor de &#39;&lt;-&#39; tot &lt;- sum(x[,1]) # Falta espacio luego de coma tot &lt;- sum(x[1,]) # Falta espacio luego de coma Otra buena práctica es colocar espacio antes de un paréntesis excepto cuando se llama una función. if (debug) # Correcto if(debug) # Funciona pero no se recomienda colMeans (x) # Funciona pero no se recomienda Espacios extras pueden ser usados si con esto se mejora la apariencia del código, ver el ejemplo siguiente. plot(x = x.coord, y = data.mat[, MakeColName(metric, ptiles[1], &quot;roiOpt&quot;)], ylim = ylim, xlab = &quot;dates&quot;, ylab = metric, main = (paste(metric, &quot; for 3 samples &quot;, sep = &quot;&quot;))) No coloque espacios alrededor del código que esté dentro de paréntesis ( ) o corchetes [ ], la única excepción es luego de una coma, ver el ejemplo siguiente. if (condicion) # Correcto x[1, ] # Correcto if ( condicion ) # Sobran espacios alrededor de condición x[1,] # Se necesita espacio luego de coma Los signos de agrupación llaves { } se utilizan para agrupar bloques de código y se recomienda que nunca una llave abierta { esté sola en una línea; una llave cerrada } si debe ir sola en su propia línea. Se pueden omitir las llaves cuando el bloque de instrucciones esté formado por una sola línea pero esa línea de código NO debe ir en la misma línea de la condición. A continuación dos ejemplos de lo que se recomienda. if (is.null(ylim)) { # Correcto ylim &lt;- c(0, 0.06) } if (is.null(ylim)) # Correcto ylim &lt;- c(0, 0.06) if (is.null(ylim)) ylim &lt;- c(0, 0.06) # Aceptable if (is.null(ylim)) # No se recomienda { ylim &lt;- c(0, 0.06) } if (is.null(ylim)) {ylim &lt;- c(0, 0.06)} # Frente a la llave { no debe ir nada # la llave de cierre } debe ir sola La sentencia else debe ir siempre entre llaves } {, ver el siguiente ejemplo. if (condition) { one or more lines } else { # Correcto one or more lines } if (condition) { one or more lines } else { # Incorrecto one or more lines } if (condition) one line else # Incorrecto one line 2.7.5 Asignación Para realizar asignaciones se recomienda usar el símbolo &lt;-, el símbolo de igualdad = no se recomienda usarlo para asignaciones. x &lt;- 5 # Correcto x = 5 # No recomendado Para una explicación más detallada sobre el símbolo de asignación se recomienda visitar este enlace. 2.7.6 Punto y coma No se recomienda colocar varias instrucciones separadas por ; en la misma línea, aunque funciona dificulta la revisión del código. n &lt;- 100; y &lt;- rnorm(n, mean=5); hist(y) # No se recomienda n &lt;- 100 # Correcto y &lt;- rnorm(n, mean=5) hist(y) A pesar de la anterior advertencia es posible que en este libro usemos el ; en algunas ocasiones, si lo hacemos es para ahorrar espacio en la presentación del código. "],["tidyverse.html", "Capítulo 3 Tidyverse 3.1 Lectura de archivos 3.2 Consultas de datos 3.3 Orden y estructura 3.4 Manipulación de texto 3.5 Manipulación de tiempo 3.6 Iteraciones", " Capítulo 3 Tidyverse La compañía Rstudio ha desarrollado un conjunto de librerías que revolucionó la programación en R. Este conjunto de librerías permite al usuario mayor orden, legibilidad e intuición a la hora de escribir y leer código. El conjunto de librerías lleva por nombre: TIDYVERSE. En este capítulo se estudiarán las distintas librerías que componen este conjunto. Cada una de las librerías puede usarse de modo independiente. En caso de que el usuario lo prefiera, puede disponer de todas las librerías al mandar ejecutar la función: library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() 3.1 Lectura de archivos Usualmente, no creamos los datos desde la sesión de R, sino que a través de un archivo externo o una base de datos se realiza la lectura de datos. Los más comunes son: 3.1.1 Archivos csv A la hora de importar conjuntos de datos en R, uno de los formatos más habituales en los que hallamos información es en archivos separados por comas (comma separated values), cuya extensión suele ser .csv. En ellos encontramos múltiples líneas que recogen la tabla de interés, y en las cuales los valores aparecen, de manera consecutiva, separados por el carácter ,. Para importar este tipo de archivos en nuestra sesión de R, se utiliza la función read_csv(). Para acceder a su documentación utilizamos el comando ?read_csv. El único argumento que debemos de pasar a esta función de manera obligatoria, es file, el nombre o la ruta completa del archivo que pretendemos importar. library(readr) read_csv( file, col_names = TRUE, col_types = NULL, locale = default_locale(), na = c(&quot;&quot;, &quot;NA&quot;), quoted_na = TRUE, quote = &quot;\\&quot;&quot;, comment = &quot;&quot;) La paquetería readr fue desarrollada recientemente para lidiar con la lectura de archivos grandes rápidamente. El paquete proporciona reemplazos para funciones como read.table(), read.csv() entre otras. Esta paquetería proporciona funciones que suelen ser mucho más rápidas que las funciones base que proporciona R. Ventajas de readr: Por lo general, son mucho más rápidos (~ 10x) que sus funciones equivalentes. Producen tibbles: No convierten vectores de caracteres en factores. No usan nombres de filas ni modifican los nombres de columnas. Reproducibilidad No convierte, automáticamente, las columnas con cadenas de caracteres a factores, como sí hacen por defecto las otras funciones base de R. Reconoce ocho clases diferentes de datos (enteros, lógicos, etc.), dejando el resto como cadenas de caracteres. Veamos un ejemplo: La base de datos llamada AmesHousing contiene un conjunto de datos con información de la Oficina del Tasador de Ames utilizada para calcular los valores tasados para las propiedades residenciales individuales vendidas en Ames, Iowa, de 2006 a 2010. FUENTES: Ames, Oficina del Tasador de Iowa. Pueden descargar los datos para la clase aquí base &lt;- read.csv(&quot;data/ames.csv&quot;) head(base, 2) ## MS_SubClass MS_Zoning Lot_Frontage ## 1 One_Story_1946_and_Newer_All_Styles Residential_Low_Density 141 ## 2 One_Story_1946_and_Newer_All_Styles Residential_High_Density 80 ## Lot_Area Street Alley Lot_Shape Land_Contour Utilities ## 1 31770 Pave No_Alley_Access Slightly_Irregular Lvl AllPub ## 2 11622 Pave No_Alley_Access Regular Lvl AllPub ## Lot_Config Land_Slope Neighborhood Condition_1 Condition_2 Bldg_Type ## 1 Corner Gtl North_Ames Norm Norm OneFam ## 2 Inside Gtl North_Ames Feedr Norm OneFam ## House_Style Overall_Cond Year_Built Year_Remod_Add Roof_Style Roof_Matl ## 1 One_Story Average 1960 1960 Hip CompShg ## 2 One_Story Above_Average 1961 1961 Gable CompShg ## Exterior_1st Exterior_2nd Mas_Vnr_Type Mas_Vnr_Area Exter_Cond Foundation ## 1 BrkFace Plywood Stone 112 Typical CBlock ## 2 VinylSd VinylSd None 0 Typical CBlock ## Bsmt_Cond Bsmt_Exposure BsmtFin_Type_1 BsmtFin_SF_1 BsmtFin_Type_2 ## 1 Good Gd BLQ 2 Unf ## 2 Typical No Rec 6 LwQ ## BsmtFin_SF_2 Bsmt_Unf_SF Total_Bsmt_SF Heating Heating_QC Central_Air ## 1 0 441 1080 GasA Fair Y ## 2 144 270 882 GasA Typical Y ## Electrical First_Flr_SF Second_Flr_SF Gr_Liv_Area Bsmt_Full_Bath ## 1 SBrkr 1656 0 1656 1 ## 2 SBrkr 896 0 896 0 ## Bsmt_Half_Bath Full_Bath Half_Bath Bedroom_AbvGr Kitchen_AbvGr TotRms_AbvGrd ## 1 0 1 0 3 1 7 ## 2 0 1 0 2 1 5 ## Functional Fireplaces Garage_Type Garage_Finish Garage_Cars Garage_Area ## 1 Typ 2 Attchd Fin 2 528 ## 2 Typ 0 Attchd Unf 1 730 ## Garage_Cond Paved_Drive Wood_Deck_SF Open_Porch_SF Enclosed_Porch ## 1 Typical Partial_Pavement 210 62 0 ## 2 Typical Paved 140 0 0 ## Three_season_porch Screen_Porch Pool_Area Pool_QC Fence ## 1 0 0 0 No_Pool No_Fence ## 2 0 120 0 No_Pool Minimum_Privacy ## Misc_Feature Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition Sale_Price ## 1 None 0 5 2010 WD Normal 215000 ## 2 None 0 6 2010 WD Normal 105000 ## Longitude Latitude ## 1 -93.61975 42.05403 ## 2 -93.61976 42.05301 tidy &lt;- read_csv(&quot;data/ames.csv&quot;) ## Rows: 2930 Columns: 74 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (40): MS_SubClass, MS_Zoning, Street, Alley, Lot_Shape, Land_Contour, Ut... ## dbl (34): Lot_Frontage, Lot_Area, Year_Built, Year_Remod_Add, Mas_Vnr_Area, ... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. head(tidy, 2) ## # A tibble: 2 × 74 ## MS_SubC…¹ MS_Zo…² Lot_F…³ Lot_A…⁴ Street Alley Lot_S…⁵ Land_…⁶ Utili…⁷ Lot_C…⁸ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 One_Stor… Reside… 141 31770 Pave No_A… Slight… Lvl AllPub Corner ## 2 One_Stor… Reside… 80 11622 Pave No_A… Regular Lvl AllPub Inside ## # … with 64 more variables: Land_Slope &lt;chr&gt;, Neighborhood &lt;chr&gt;, ## # Condition_1 &lt;chr&gt;, Condition_2 &lt;chr&gt;, Bldg_Type &lt;chr&gt;, House_Style &lt;chr&gt;, ## # Overall_Cond &lt;chr&gt;, Year_Built &lt;dbl&gt;, Year_Remod_Add &lt;dbl&gt;, ## # Roof_Style &lt;chr&gt;, Roof_Matl &lt;chr&gt;, Exterior_1st &lt;chr&gt;, Exterior_2nd &lt;chr&gt;, ## # Mas_Vnr_Type &lt;chr&gt;, Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;chr&gt;, Foundation &lt;chr&gt;, ## # Bsmt_Cond &lt;chr&gt;, Bsmt_Exposure &lt;chr&gt;, BsmtFin_Type_1 &lt;chr&gt;, ## # BsmtFin_SF_1 &lt;dbl&gt;, BsmtFin_Type_2 &lt;chr&gt;, BsmtFin_SF_2 &lt;dbl&gt;, … ¿Y si el archivo que necesitamos leer esta en excel? 3.1.2 Archivos txt Uno de los archivos más comunes es el .txt. La librería readr también cuenta con funciones que permiten leer fácilmente los datos contenidos en formato tabular. ames_txt &lt;- read_delim(&quot;data/ames.txt&quot;, delim = &quot;;&quot;, col_names = TRUE) ## Rows: 2930 Columns: 74 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;;&quot; ## chr (40): MS_SubClass, MS_Zoning, Street, Alley, Lot_Shape, Land_Contour, Ut... ## dbl (34): Lot_Frontage, Lot_Area, Year_Built, Year_Remod_Add, Mas_Vnr_Area, ... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. head(ames_txt, 2) ## # A tibble: 2 × 74 ## MS_SubC…¹ MS_Zo…² Lot_F…³ Lot_A…⁴ Street Alley Lot_S…⁵ Land_…⁶ Utili…⁷ Lot_C…⁸ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 One_Stor… Reside… 141 31770 Pave No_A… Slight… Lvl AllPub Corner ## 2 One_Stor… Reside… 80 11622 Pave No_A… Regular Lvl AllPub Inside ## # … with 64 more variables: Land_Slope &lt;chr&gt;, Neighborhood &lt;chr&gt;, ## # Condition_1 &lt;chr&gt;, Condition_2 &lt;chr&gt;, Bldg_Type &lt;chr&gt;, House_Style &lt;chr&gt;, ## # Overall_Cond &lt;chr&gt;, Year_Built &lt;dbl&gt;, Year_Remod_Add &lt;dbl&gt;, ## # Roof_Style &lt;chr&gt;, Roof_Matl &lt;chr&gt;, Exterior_1st &lt;chr&gt;, Exterior_2nd &lt;chr&gt;, ## # Mas_Vnr_Type &lt;chr&gt;, Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;chr&gt;, Foundation &lt;chr&gt;, ## # Bsmt_Cond &lt;chr&gt;, Bsmt_Exposure &lt;chr&gt;, BsmtFin_Type_1 &lt;chr&gt;, ## # BsmtFin_SF_1 &lt;dbl&gt;, BsmtFin_Type_2 &lt;chr&gt;, BsmtFin_SF_2 &lt;dbl&gt;, … La función read_delim() funciona para leer archivos con diferentes delimitadores posibles, es decir, es posible especificar si las columnas están separadas por espacios, comas, punto y coma, tabulador o algún otro delimitador (““,”,“,”;“,”, “@”). Adicionalmente, se puede especificar si el archivo contiene encabezado, si existen renglones a saltar, codificación, tipo de variable y muchas más opciones. Todos estos detalles pueden consultarse en la documentación de ayuda. 3.1.3 Archivos xls y xlsx La paquetería readxl facilita la obtención de datos tabulares de archivos de Excel. Admite tanto el formato .xls heredado como el formato .xlsx moderno basado en XML. Esta paquetería pone a disposición las siguientes funciones: read_xlsx() lee un archivo con extensión xlsx. read_xlsx( path, sheet = NULL, range = NULL, col_names = TRUE, col_types = NULL, na = &quot;&quot;, trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000, n_max), progress = readxl_progress(), .name_repair = &quot;unique&quot; ) read_xls() lee un archivo con extensión xls. read_xls( path, sheet = NULL, range = NULL, col_names = TRUE, col_types = NULL, na = &quot;&quot;, trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000, n_max), progress = readxl_progress(), .name_repair = &quot;unique&quot; ) read_excel() determina si el archivo es de tipo xls o xlsx para después llamar a una de las funciones mencionadas anteriormente. read_excel( path, sheet = NULL, range = NULL, col_names = TRUE, col_types = NULL, na = &quot;&quot;, trim_ws = TRUE, skip = 0, n_max = Inf, guess_max = min(1000, n_max), progress = readxl_progress(), .name_repair = &quot;unique&quot; ) EJERCICIO: Leer archivo excel de la carpeta del curso 3.1.4 Archivos json Se utiliza la función fromJSON de la paquetería jsonlite library(jsonlite) ## ## Attaching package: &#39;jsonlite&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## flatten base_json &lt;- jsonlite::fromJSON(&quot;data/ames.json&quot;) head(base_json, 2) ## MS_SubClass MS_Zoning Lot_Frontage ## 1 One_Story_1946_and_Newer_All_Styles Residential_Low_Density 141 ## 2 One_Story_1946_and_Newer_All_Styles Residential_High_Density 80 ## Lot_Area Street Alley Lot_Shape Land_Contour Utilities ## 1 31770 Pave No_Alley_Access Slightly_Irregular Lvl AllPub ## 2 11622 Pave No_Alley_Access Regular Lvl AllPub ## Lot_Config Land_Slope Neighborhood Condition_1 Condition_2 Bldg_Type ## 1 Corner Gtl North_Ames Norm Norm OneFam ## 2 Inside Gtl North_Ames Feedr Norm OneFam ## House_Style Overall_Cond Year_Built Year_Remod_Add Roof_Style Roof_Matl ## 1 One_Story Average 1960 1960 Hip CompShg ## 2 One_Story Above_Average 1961 1961 Gable CompShg ## Exterior_1st Exterior_2nd Mas_Vnr_Type Mas_Vnr_Area Exter_Cond Foundation ## 1 BrkFace Plywood Stone 112 Typical CBlock ## 2 VinylSd VinylSd None 0 Typical CBlock ## Bsmt_Cond Bsmt_Exposure BsmtFin_Type_1 BsmtFin_SF_1 BsmtFin_Type_2 ## 1 Good Gd BLQ 2 Unf ## 2 Typical No Rec 6 LwQ ## BsmtFin_SF_2 Bsmt_Unf_SF Total_Bsmt_SF Heating Heating_QC Central_Air ## 1 0 441 1080 GasA Fair Y ## 2 144 270 882 GasA Typical Y ## Electrical First_Flr_SF Second_Flr_SF Gr_Liv_Area Bsmt_Full_Bath ## 1 SBrkr 1656 0 1656 1 ## 2 SBrkr 896 0 896 0 ## Bsmt_Half_Bath Full_Bath Half_Bath Bedroom_AbvGr Kitchen_AbvGr TotRms_AbvGrd ## 1 0 1 0 3 1 7 ## 2 0 1 0 2 1 5 ## Functional Fireplaces Garage_Type Garage_Finish Garage_Cars Garage_Area ## 1 Typ 2 Attchd Fin 2 528 ## 2 Typ 0 Attchd Unf 1 730 ## Garage_Cond Paved_Drive Wood_Deck_SF Open_Porch_SF Enclosed_Porch ## 1 Typical Partial_Pavement 210 62 0 ## 2 Typical Paved 140 0 0 ## Three_season_porch Screen_Porch Pool_Area Pool_QC Fence ## 1 0 0 0 No_Pool No_Fence ## 2 0 120 0 No_Pool Minimum_Privacy ## Misc_Feature Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition Sale_Price ## 1 None 0 5 2010 WD Normal 215000 ## 2 None 0 6 2010 WD Normal 105000 ## Longitude Latitude ## 1 -93.6198 42.054 ## 2 -93.6198 42.053 3.1.5 Archivos rds Un tipo de archivo que resulta de particular interés, es el .RDS. Este archivo comprime cualquier objeto o resultado que sea usado o producido en R. Uno puede almacenar el objeto de interés de la siguiente manera: saveRDS(base_json, &quot;data/ames.rds&quot;) Puede observarse que en el explorador de archivos se encuentra ahora el nuevo archivo con extensión .rds, el cual puede ser posteriormente incorporado a una sesión de R para seguir trabajando con él. base_rds &lt;- readRDS(&quot;data/ames.rds&quot;) Algunas de las grandes ventajas que tiene almacenar los archivos en formato rds, son las siguientes: No es necesario volver a ejecutar procesos largos cuando ya se ha logrado realizar una vez. El tiempo de lectura de la información es considerablemente más rápido. 3.1.6 Bases de Datos En muchos de los casos la información estará dentro de un Sistema Manejador de Bases de Datos, existen bibliotecas que nos permiten establecer las conexiones con ellas, algunos ejemplos son: ODBC DBI JDBC Un ejemplo con un SMBD como Oracle: 3.1.7 Oracle Database Referencias Configuración de conexión: Se necesitan seis configuraciones para realizar una conexión: Controlador : consulte la sección Controladores para obtener más información Url : una ruta de red al servidor de la base de datos. Base de datos : el nombre de la base de datos. Usuario : el ID de red del usuario o la cuenta local del servidor Contraseña : la contraseña de la cuenta Puerto : debe establecerse en 1526 o 1521 Para establecer la conexión con la base de datos: library(DBI) library(RJDBC) jdbcDriver = JDBC(driverClass = &quot;oracle.jdbc.OracleDriver&quot;,&quot;c:/Drivers/Oracle/ojdbc8.jar&quot;) con &lt;- dbConnect( jdbcDriver, url = &quot;jdbc:oracle:thin:@//Hostname:Port/Service_Name&quot; user = rstudioapi::askForPassword(&quot;Database user&quot;), password = rstudioapi::askForPassword(&quot;Database password&quot;), dbname = &quot;Data Base Name&quot; ) sql_translation.JDBCConnection &lt;- dbplyr:::sql_translation.Oracle sql_select.JDBCConnection &lt;- dbplyr:::sql_query_select.Oracle sql_subquery.JDBCConnection &lt;- dbplyr:::sql_query_wrap.Oracle dbExistsTable(jdbcConnection, &quot;nombre_tabla&quot;) # Probar si hay conexión con la tabla Información sobre la base de datos: El paquete odbc le brinda herramientas para explorar objetos y columnas en la base de datos. # Top level objects odbcListObjects(con) # Tables in a schema odbcListObjects(con, catalog = &quot;mydb&quot;, schema = &quot;dbo&quot;) # Columns in a table odbcListColumns(con, catalog = &quot;mydb&quot;, schema = &quot;dbo&quot;, table = &quot;cars&quot;) # Database structure odbcListObjectTypes(con) Consultas con SQL: Para consultas interactivas, utilice dbGetQuery() para enviar una consulta y obtener los resultados. Para obtener los resultados por separado, utilice dbSendQuery() y dbFetch(). El argumento n en dbFetch() se puede utilizar para obtener resultados parciales. # Return the results for an arbitrary query dbGetQuery(con, &quot;SELECT speed, dist FROM cars&quot;) # Fetch the first 100 records query &lt;- dbSendQuery(con, &quot;SELECT speed, dist FROM cars&quot;) dbFetch(query, n = 10) dbClearResult(query) Puedes usar los ejemplos anteriores para probar con diferentes consultas y bases de datos. Tengamos un ejemplo de manera local: remotes::install_version(&quot;RSQLite&quot;) library(dplyr) library(dbplyr) library(RSQLite) con &lt;- src_memdb() copy_to(con, storms, overwrite = T) copy_to(con, mtcars, overwrite = T) tbl_storms &lt;- tbl(con, &quot;storms&quot;) tbl_storms ## # Source: table&lt;storms&gt; [?? x 13] ## # Database: sqlite 3.39.1 [:memory:] ## name year month day hour lat long status categ…¹ wind press…² ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Amy 1975 6 27 0 27.5 -79 tropical dep… -1 25 1013 ## 2 Amy 1975 6 27 6 28.5 -79 tropical dep… -1 25 1013 ## 3 Amy 1975 6 27 12 29.5 -79 tropical dep… -1 25 1013 ## 4 Amy 1975 6 27 18 30.5 -79 tropical dep… -1 25 1013 ## 5 Amy 1975 6 28 0 31.5 -78.8 tropical dep… -1 25 1012 ## 6 Amy 1975 6 28 6 32.4 -78.7 tropical dep… -1 25 1012 ## 7 Amy 1975 6 28 12 33.3 -78 tropical dep… -1 25 1011 ## 8 Amy 1975 6 28 18 34 -77 tropical dep… -1 30 1006 ## 9 Amy 1975 6 29 0 34.4 -75.8 tropical sto… 0 35 1004 ## 10 Amy 1975 6 29 6 34 -74.8 tropical sto… 0 40 1002 ## # … with more rows, 2 more variables: tropicalstorm_force_diameter &lt;int&gt;, ## # hurricane_force_diameter &lt;int&gt;, and abbreviated variable names ¹​category, ## # ²​pressure tbl_mtcars &lt;- tbl(con, &quot;mtcars&quot;) tbl_mtcars ## # Source: table&lt;mtcars&gt; [?? x 11] ## # Database: sqlite 3.39.1 [:memory:] ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.46 20.2 1 0 3 1 ## 7 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 ## 8 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 9 22.8 4 141. 95 3.92 3.15 22.9 1 0 4 2 ## 10 19.2 6 168. 123 3.92 3.44 18.3 1 0 4 4 ## # … with more rows Existe otra metodología de conexión, la cual puede encontrarse en la siguiente documentación 3.2 Consultas de datos Ahora que ya se ha estudiado la manera de cargar datos, aprenderemos como manipularlos con dplyr. El paquete dplyr proporciona un conjunto de funciones muy útiles para manipular data-frames y así reducir el número de repeticiones, la probabilidad de cometer errores y el número de caracteres que hay que escribir. Como valor extra, podemos encontrar que la gramática de dplyr es más fácil de entender. Revisaremos algunas de sus funciones más usadas (verbos), así como el uso de pipes (%&gt;%) para combinarlas. select() filter() arrange() mutate() summarise() join() group_by() Primero tenemos que instalar y cargar la paquetería (parte de tidyverse): # install.packages(&quot;dplyr&quot;) library(dplyr) library(readr) Usaremos el dataset AmesHousing que se proporcionó en el capítulo anterior (el alumno puede hacer el ejercicio con datos propios) ames_housing &lt;- read_csv(&quot;data/ames.csv&quot;) glimpse(ames_housing) ## Rows: 2,930 ## Columns: 74 ## $ MS_SubClass &lt;chr&gt; &quot;One_Story_1946_and_Newer_All_Styles&quot;, &quot;One_Story_1… ## $ MS_Zoning &lt;chr&gt; &quot;Residential_Low_Density&quot;, &quot;Residential_High_Densit… ## $ Lot_Frontage &lt;dbl&gt; 141, 80, 81, 93, 74, 78, 41, 43, 39, 60, 75, 0, 63,… ## $ Lot_Area &lt;dbl&gt; 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005… ## $ Street &lt;chr&gt; &quot;Pave&quot;, &quot;Pave&quot;, &quot;Pave&quot;, &quot;Pave&quot;, &quot;Pave&quot;, &quot;Pave&quot;, &quot;Pa… ## $ Alley &lt;chr&gt; &quot;No_Alley_Access&quot;, &quot;No_Alley_Access&quot;, &quot;No_Alley_Acc… ## $ Lot_Shape &lt;chr&gt; &quot;Slightly_Irregular&quot;, &quot;Regular&quot;, &quot;Slightly_Irregula… ## $ Land_Contour &lt;chr&gt; &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;Lvl&quot;, &quot;H… ## $ Utilities &lt;chr&gt; &quot;AllPub&quot;, &quot;AllPub&quot;, &quot;AllPub&quot;, &quot;AllPub&quot;, &quot;AllPub&quot;, &quot;… ## $ Lot_Config &lt;chr&gt; &quot;Corner&quot;, &quot;Inside&quot;, &quot;Corner&quot;, &quot;Corner&quot;, &quot;Inside&quot;, &quot;… ## $ Land_Slope &lt;chr&gt; &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;Gtl&quot;, &quot;G… ## $ Neighborhood &lt;chr&gt; &quot;North_Ames&quot;, &quot;North_Ames&quot;, &quot;North_Ames&quot;, &quot;North_Am… ## $ Condition_1 &lt;chr&gt; &quot;Norm&quot;, &quot;Feedr&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;N… ## $ Condition_2 &lt;chr&gt; &quot;Norm&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;Norm&quot;, &quot;No… ## $ Bldg_Type &lt;chr&gt; &quot;OneFam&quot;, &quot;OneFam&quot;, &quot;OneFam&quot;, &quot;OneFam&quot;, &quot;OneFam&quot;, &quot;… ## $ House_Style &lt;chr&gt; &quot;One_Story&quot;, &quot;One_Story&quot;, &quot;One_Story&quot;, &quot;One_Story&quot;,… ## $ Overall_Cond &lt;chr&gt; &quot;Average&quot;, &quot;Above_Average&quot;, &quot;Above_Average&quot;, &quot;Avera… ## $ Year_Built &lt;dbl&gt; 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 199… ## $ Year_Remod_Add &lt;dbl&gt; 1960, 1961, 1958, 1968, 1998, 1998, 2001, 1992, 199… ## $ Roof_Style &lt;chr&gt; &quot;Hip&quot;, &quot;Gable&quot;, &quot;Hip&quot;, &quot;Hip&quot;, &quot;Gable&quot;, &quot;Gable&quot;, &quot;Ga… ## $ Roof_Matl &lt;chr&gt; &quot;CompShg&quot;, &quot;CompShg&quot;, &quot;CompShg&quot;, &quot;CompShg&quot;, &quot;CompSh… ## $ Exterior_1st &lt;chr&gt; &quot;BrkFace&quot;, &quot;VinylSd&quot;, &quot;Wd Sdng&quot;, &quot;BrkFace&quot;, &quot;VinylS… ## $ Exterior_2nd &lt;chr&gt; &quot;Plywood&quot;, &quot;VinylSd&quot;, &quot;Wd Sdng&quot;, &quot;BrkFace&quot;, &quot;VinylS… ## $ Mas_Vnr_Type &lt;chr&gt; &quot;Stone&quot;, &quot;None&quot;, &quot;BrkFace&quot;, &quot;None&quot;, &quot;None&quot;, &quot;BrkFac… ## $ Mas_Vnr_Area &lt;dbl&gt; 112, 0, 108, 0, 0, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6… ## $ Exter_Cond &lt;chr&gt; &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typica… ## $ Foundation &lt;chr&gt; &quot;CBlock&quot;, &quot;CBlock&quot;, &quot;CBlock&quot;, &quot;CBlock&quot;, &quot;PConc&quot;, &quot;P… ## $ Bsmt_Cond &lt;chr&gt; &quot;Good&quot;, &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typical&quot;,… ## $ Bsmt_Exposure &lt;chr&gt; &quot;Gd&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Mn&quot;, &quot;No&quot;, &quot;No… ## $ BsmtFin_Type_1 &lt;chr&gt; &quot;BLQ&quot;, &quot;Rec&quot;, &quot;ALQ&quot;, &quot;ALQ&quot;, &quot;GLQ&quot;, &quot;GLQ&quot;, &quot;GLQ&quot;, &quot;A… ## $ BsmtFin_SF_1 &lt;dbl&gt; 2, 6, 1, 1, 3, 3, 3, 1, 3, 7, 7, 1, 7, 3, 3, 1, 3, … ## $ BsmtFin_Type_2 &lt;chr&gt; &quot;Unf&quot;, &quot;LwQ&quot;, &quot;Unf&quot;, &quot;Unf&quot;, &quot;Unf&quot;, &quot;Unf&quot;, &quot;Unf&quot;, &quot;U… ## $ BsmtFin_SF_2 &lt;dbl&gt; 0, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1120, 0… ## $ Bsmt_Unf_SF &lt;dbl&gt; 441, 270, 406, 1045, 137, 324, 722, 1017, 415, 994,… ## $ Total_Bsmt_SF &lt;dbl&gt; 1080, 882, 1329, 2110, 928, 926, 1338, 1280, 1595, … ## $ Heating &lt;chr&gt; &quot;GasA&quot;, &quot;GasA&quot;, &quot;GasA&quot;, &quot;GasA&quot;, &quot;GasA&quot;, &quot;GasA&quot;, &quot;Ga… ## $ Heating_QC &lt;chr&gt; &quot;Fair&quot;, &quot;Typical&quot;, &quot;Typical&quot;, &quot;Excellent&quot;, &quot;Good&quot;, … ## $ Central_Air &lt;chr&gt; &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;Y&quot;, &quot;… ## $ Electrical &lt;chr&gt; &quot;SBrkr&quot;, &quot;SBrkr&quot;, &quot;SBrkr&quot;, &quot;SBrkr&quot;, &quot;SBrkr&quot;, &quot;SBrkr… ## $ First_Flr_SF &lt;dbl&gt; 1656, 896, 1329, 2110, 928, 926, 1338, 1280, 1616, … ## $ Second_Flr_SF &lt;dbl&gt; 0, 0, 0, 0, 701, 678, 0, 0, 0, 776, 892, 0, 676, 0,… ## $ Gr_Liv_Area &lt;dbl&gt; 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616… ## $ Bsmt_Full_Bath &lt;dbl&gt; 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, … ## $ Bsmt_Half_Bath &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ Full_Bath &lt;dbl&gt; 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, … ## $ Half_Bath &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, … ## $ Bedroom_AbvGr &lt;dbl&gt; 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 2, 1, 4, 4, … ## $ Kitchen_AbvGr &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, … ## $ TotRms_AbvGrd &lt;dbl&gt; 7, 5, 6, 8, 6, 7, 6, 5, 5, 7, 7, 6, 7, 5, 4, 12, 8,… ## $ Functional &lt;chr&gt; &quot;Typ&quot;, &quot;Typ&quot;, &quot;Typ&quot;, &quot;Typ&quot;, &quot;Typ&quot;, &quot;Typ&quot;, &quot;Typ&quot;, &quot;T… ## $ Fireplaces &lt;dbl&gt; 2, 0, 0, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, … ## $ Garage_Type &lt;chr&gt; &quot;Attchd&quot;, &quot;Attchd&quot;, &quot;Attchd&quot;, &quot;Attchd&quot;, &quot;Attchd&quot;, &quot;… ## $ Garage_Finish &lt;chr&gt; &quot;Fin&quot;, &quot;Unf&quot;, &quot;Unf&quot;, &quot;Fin&quot;, &quot;Fin&quot;, &quot;Fin&quot;, &quot;Fin&quot;, &quot;R… ## $ Garage_Cars &lt;dbl&gt; 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, … ## $ Garage_Area &lt;dbl&gt; 528, 730, 312, 522, 482, 470, 582, 506, 608, 442, 4… ## $ Garage_Cond &lt;chr&gt; &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typical&quot;, &quot;Typica… ## $ Paved_Drive &lt;chr&gt; &quot;Partial_Pavement&quot;, &quot;Paved&quot;, &quot;Paved&quot;, &quot;Paved&quot;, &quot;Pav… ## $ Wood_Deck_SF &lt;dbl&gt; 210, 140, 393, 0, 212, 360, 0, 0, 237, 140, 157, 48… ## $ Open_Porch_SF &lt;dbl&gt; 62, 0, 36, 0, 34, 36, 0, 82, 152, 60, 84, 21, 75, 0… ## $ Enclosed_Porch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 170, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Three_season_porch &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ Screen_Porch &lt;dbl&gt; 0, 120, 0, 0, 0, 0, 0, 144, 0, 0, 0, 0, 0, 0, 140, … ## $ Pool_Area &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ Pool_QC &lt;chr&gt; &quot;No_Pool&quot;, &quot;No_Pool&quot;, &quot;No_Pool&quot;, &quot;No_Pool&quot;, &quot;No_Poo… ## $ Fence &lt;chr&gt; &quot;No_Fence&quot;, &quot;Minimum_Privacy&quot;, &quot;No_Fence&quot;, &quot;No_Fenc… ## $ Misc_Feature &lt;chr&gt; &quot;None&quot;, &quot;None&quot;, &quot;Gar2&quot;, &quot;None&quot;, &quot;None&quot;, &quot;None&quot;, &quot;No… ## $ Misc_Val &lt;dbl&gt; 0, 0, 12500, 0, 0, 0, 0, 0, 0, 0, 0, 500, 0, 0, 0, … ## $ Mo_Sold &lt;dbl&gt; 5, 6, 6, 4, 3, 6, 4, 1, 3, 6, 4, 3, 5, 2, 6, 6, 6, … ## $ Year_Sold &lt;dbl&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 201… ## $ Sale_Type &lt;chr&gt; &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;WD&quot;, &quot;WD… ## $ Sale_Condition &lt;chr&gt; &quot;Normal&quot;, &quot;Normal&quot;, &quot;Normal&quot;, &quot;Normal&quot;, &quot;Normal&quot;, &quot;… ## $ Sale_Price &lt;dbl&gt; 215000, 105000, 172000, 244000, 189900, 195500, 213… ## $ Longitude &lt;dbl&gt; -93.61975, -93.61976, -93.61939, -93.61732, -93.638… ## $ Latitude &lt;dbl&gt; 42.05403, 42.05301, 42.05266, 42.05125, 42.06090, 4… 3.2.1 Seleccionar columnas Observamos que nuestros datos tienen 2,930 observaciones y 74 variables, con select() podemos seleccionar las variables que se indiquen. ames_housing %&gt;% select(Lot_Area, Neighborhood, Year_Sold, Sale_Price) ## # A tibble: 2,930 × 4 ## Lot_Area Neighborhood Year_Sold Sale_Price ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 31770 North_Ames 2010 215000 ## 2 11622 North_Ames 2010 105000 ## 3 14267 North_Ames 2010 172000 ## 4 11160 North_Ames 2010 244000 ## 5 13830 Gilbert 2010 189900 ## 6 9978 Gilbert 2010 195500 ## 7 4920 Stone_Brook 2010 213500 ## 8 5005 Stone_Brook 2010 191500 ## 9 5389 Stone_Brook 2010 236500 ## 10 7500 Gilbert 2010 189000 ## # … with 2,920 more rows ¡¡ RECORDAR !! El operador pipe (%&gt;%) se usa para conectar un elemento con una función o acción a realizar. En este caso solo se indica que en los datos de ames se seleccionan 4 variables. Con select() y contains() podemos seleccionar variables con alguna cadena de texto. ames_housing %&gt;% select(contains(&quot;Area&quot;)) ## # A tibble: 2,930 × 5 ## Lot_Area Mas_Vnr_Area Gr_Liv_Area Garage_Area Pool_Area ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 31770 112 1656 528 0 ## 2 11622 0 896 730 0 ## 3 14267 108 1329 312 0 ## 4 11160 0 2110 522 0 ## 5 13830 0 1629 482 0 ## 6 9978 20 1604 470 0 ## 7 4920 0 1338 582 0 ## 8 5005 0 1280 506 0 ## 9 5389 0 1616 608 0 ## 10 7500 0 1804 442 0 ## # … with 2,920 more rows De igual manera, con select(), ends_with y start_with() podemos seleccionar que inicien o terminen con alguna cadena de texto. ames_housing %&gt;% select(starts_with(&quot;Garage&quot;)) ## # A tibble: 2,930 × 5 ## Garage_Type Garage_Finish Garage_Cars Garage_Area Garage_Cond ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Attchd Fin 2 528 Typical ## 2 Attchd Unf 1 730 Typical ## 3 Attchd Unf 1 312 Typical ## 4 Attchd Fin 2 522 Typical ## 5 Attchd Fin 2 482 Typical ## 6 Attchd Fin 2 470 Typical ## 7 Attchd Fin 2 582 Typical ## 8 Attchd RFn 2 506 Typical ## 9 Attchd RFn 2 608 Typical ## 10 Attchd Fin 2 442 Typical ## # … with 2,920 more rows Funciones útiles para select(): contains(): Selecciona variables cuyo nombre contiene la cadena de texto. ends_with(): Selecciona variables cuyo nombre termina con la cadena de caracteres. everything(): Selecciona todas las columnas. matches(): Selecciona las variables cuyos nombres coinciden con una expresión regular. num_range(): Selecciona las variables por posición. start_with(): Selecciona variables cuyos nombres empiezan con la cadena de caracteres. any_of: Selecciona cualquiera de estas variables, en caso de existir EJERCICIO: Crear con datos propios una consulta de columnas usando como variable auxiliar cada una de las listadas anteriormente. Será suficiente con realizar un ejemplo de cada una. 3.2.2 Filtrar observaciones La función filter() nos permite filtrar filas según una condición, primero notemos que la variable Sale_Condition tiene distintas categorías. table(ames_housing$Sale_Condition) ## ## Abnorml AdjLand Alloca Family Normal Partial ## 190 12 24 46 2413 245 ¡¡ SPOILER !! En un modelo predictivo de Machine Learning, no es correcto agregar columnas cuyo valor es conocido hasta el momento de la observación. Es decir, no deben agregarse variables que no se conozca su valor al momento de la predicción, como es el caso de condición de venta. Ahora usaremos la función filter para quedarnos solo con las observaciones con condición de venta “normal”. ames_housing %&gt;% filter(Sale_Condition == &quot;Normal&quot;) ## # A tibble: 2,413 × 74 ## MS_Sub…¹ MS_Zo…² Lot_F…³ Lot_A…⁴ Street Alley Lot_S…⁵ Land_…⁶ Utili…⁷ Lot_C…⁸ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 One_Sto… Reside… 141 31770 Pave No_A… Slight… Lvl AllPub Corner ## 2 One_Sto… Reside… 80 11622 Pave No_A… Regular Lvl AllPub Inside ## 3 One_Sto… Reside… 81 14267 Pave No_A… Slight… Lvl AllPub Corner ## 4 One_Sto… Reside… 93 11160 Pave No_A… Regular Lvl AllPub Corner ## 5 Two_Sto… Reside… 74 13830 Pave No_A… Slight… Lvl AllPub Inside ## 6 Two_Sto… Reside… 78 9978 Pave No_A… Slight… Lvl AllPub Inside ## 7 One_Sto… Reside… 41 4920 Pave No_A… Regular Lvl AllPub Inside ## 8 One_Sto… Reside… 43 5005 Pave No_A… Slight… HLS AllPub Inside ## 9 One_Sto… Reside… 39 5389 Pave No_A… Slight… Lvl AllPub Inside ## 10 Two_Sto… Reside… 60 7500 Pave No_A… Regular Lvl AllPub Inside ## # … with 2,403 more rows, 64 more variables: Land_Slope &lt;chr&gt;, ## # Neighborhood &lt;chr&gt;, Condition_1 &lt;chr&gt;, Condition_2 &lt;chr&gt;, Bldg_Type &lt;chr&gt;, ## # House_Style &lt;chr&gt;, Overall_Cond &lt;chr&gt;, Year_Built &lt;dbl&gt;, ## # Year_Remod_Add &lt;dbl&gt;, Roof_Style &lt;chr&gt;, Roof_Matl &lt;chr&gt;, ## # Exterior_1st &lt;chr&gt;, Exterior_2nd &lt;chr&gt;, Mas_Vnr_Type &lt;chr&gt;, ## # Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;chr&gt;, Foundation &lt;chr&gt;, Bsmt_Cond &lt;chr&gt;, ## # Bsmt_Exposure &lt;chr&gt;, BsmtFin_Type_1 &lt;chr&gt;, BsmtFin_SF_1 &lt;dbl&gt;, … También se puede usar para filtrar variables numéricas: ames_housing %&gt;% filter(Lot_Area &gt; 1000 &amp; Sale_Price &gt;= 150000) ## # A tibble: 1,677 × 74 ## MS_Sub…¹ MS_Zo…² Lot_F…³ Lot_A…⁴ Street Alley Lot_S…⁵ Land_…⁶ Utili…⁷ Lot_C…⁸ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 One_Sto… Reside… 141 31770 Pave No_A… Slight… Lvl AllPub Corner ## 2 One_Sto… Reside… 81 14267 Pave No_A… Slight… Lvl AllPub Corner ## 3 One_Sto… Reside… 93 11160 Pave No_A… Regular Lvl AllPub Corner ## 4 Two_Sto… Reside… 74 13830 Pave No_A… Slight… Lvl AllPub Inside ## 5 Two_Sto… Reside… 78 9978 Pave No_A… Slight… Lvl AllPub Inside ## 6 One_Sto… Reside… 41 4920 Pave No_A… Regular Lvl AllPub Inside ## 7 One_Sto… Reside… 43 5005 Pave No_A… Slight… HLS AllPub Inside ## 8 One_Sto… Reside… 39 5389 Pave No_A… Slight… Lvl AllPub Inside ## 9 Two_Sto… Reside… 60 7500 Pave No_A… Regular Lvl AllPub Inside ## 10 Two_Sto… Reside… 75 10000 Pave No_A… Slight… Lvl AllPub Corner ## # … with 1,667 more rows, 64 more variables: Land_Slope &lt;chr&gt;, ## # Neighborhood &lt;chr&gt;, Condition_1 &lt;chr&gt;, Condition_2 &lt;chr&gt;, Bldg_Type &lt;chr&gt;, ## # House_Style &lt;chr&gt;, Overall_Cond &lt;chr&gt;, Year_Built &lt;dbl&gt;, ## # Year_Remod_Add &lt;dbl&gt;, Roof_Style &lt;chr&gt;, Roof_Matl &lt;chr&gt;, ## # Exterior_1st &lt;chr&gt;, Exterior_2nd &lt;chr&gt;, Mas_Vnr_Type &lt;chr&gt;, ## # Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;chr&gt;, Foundation &lt;chr&gt;, Bsmt_Cond &lt;chr&gt;, ## # Bsmt_Exposure &lt;chr&gt;, BsmtFin_Type_1 &lt;chr&gt;, BsmtFin_SF_1 &lt;dbl&gt;, … Notemos que en el ejemplo anterior se usa &amp;, que ayuda a filtrar por dos condiciones. También puede usarse | para filtrar por alguna de las dos condiciones. ames_housing %&gt;% filter(Lot_Area &lt; 1000 | Sale_Price &lt;= 150000) ## # A tibble: 1,271 × 74 ## MS_Sub…¹ MS_Zo…² Lot_F…³ Lot_A…⁴ Street Alley Lot_S…⁵ Land_…⁶ Utili…⁷ Lot_C…⁸ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 One_Sto… Reside… 80 11622 Pave No_A… Regular Lvl AllPub Inside ## 2 One_Sto… Reside… 140 19138 Pave No_A… Regular Lvl AllPub Corner ## 3 One_Sto… Reside… 0 11241 Pave No_A… Slight… Lvl AllPub CulDSac ## 4 One_Sto… Reside… 0 12537 Pave No_A… Slight… Lvl AllPub CulDSac ## 5 One_Sto… Reside… 65 8450 Pave No_A… Regular Lvl AllPub Inside ## 6 One_Sto… Reside… 70 8400 Pave No_A… Regular Lvl AllPub Corner ## 7 One_Sto… Reside… 70 10500 Pave No_A… Regular Lvl AllPub FR2 ## 8 Two_Sto… Reside… 21 1680 Pave No_A… Regular Lvl AllPub Inside ## 9 Two_Sto… Reside… 21 1680 Pave No_A… Regular Lvl AllPub Inside ## 10 Two_Sto… Reside… 21 1680 Pave No_A… Regular Lvl AllPub Inside ## # … with 1,261 more rows, 64 more variables: Land_Slope &lt;chr&gt;, ## # Neighborhood &lt;chr&gt;, Condition_1 &lt;chr&gt;, Condition_2 &lt;chr&gt;, Bldg_Type &lt;chr&gt;, ## # House_Style &lt;chr&gt;, Overall_Cond &lt;chr&gt;, Year_Built &lt;dbl&gt;, ## # Year_Remod_Add &lt;dbl&gt;, Roof_Style &lt;chr&gt;, Roof_Matl &lt;chr&gt;, ## # Exterior_1st &lt;chr&gt;, Exterior_2nd &lt;chr&gt;, Mas_Vnr_Type &lt;chr&gt;, ## # Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;chr&gt;, Foundation &lt;chr&gt;, Bsmt_Cond &lt;chr&gt;, ## # Bsmt_Exposure &lt;chr&gt;, BsmtFin_Type_1 &lt;chr&gt;, BsmtFin_SF_1 &lt;dbl&gt;, … Las condiciones pueden ser expresiones lógicas construidas mediante los operadores relacionales y lógicos: &lt; : Menor que &gt; : Mayor que == : Igual que &lt;= : Menor o igual que &gt;= : Mayor o igual que != : Diferente que %in% : Pertenece al conjunto is.na : Es NA !is.na : No es NA EJERCICIO: Practicar la función de filtro de observaciones usando los operadores auxiliares. Concatenar el resultado de seleccionar columnas y posteriormente filtrar columnas. 3.2.3 Ordenar registros La función arrange() se utiliza para ordenar las filas de un data frame de acuerdo a una o varias variables. Este ordenamiento puede ser ascendente o descendente. Por defecto arrange() ordena las filas por orden ascendente: ames_housing %&gt;% arrange(Sale_Price) ## # A tibble: 2,930 × 74 ## MS_Sub…¹ MS_Zo…² Lot_F…³ Lot_A…⁴ Street Alley Lot_S…⁵ Land_…⁶ Utili…⁷ Lot_C…⁸ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 One_Sto… Reside… 68 9656 Pave No_A… Regular Lvl AllPub Inside ## 2 One_Sto… A_agr 80 14584 Pave No_A… Regular Low AllPub Inside ## 3 One_Sto… C_all 60 7879 Pave No_A… Regular Lvl AllPub Inside ## 4 One_Sto… Reside… 60 8088 Pave Grav… Regular Lvl AllPub Inside ## 5 One_Sto… C_all 50 9000 Pave No_A… Regular Lvl AllPub Inside ## 6 One_and… Reside… 50 5925 Pave No_A… Regular Lvl AllPub Inside ## 7 One_Sto… Reside… 50 5000 Pave No_A… Regular Low AllPub Inside ## 8 Two_Sto… C_all 50 8500 Pave Paved Regular Lvl AllPub Inside ## 9 One_Sto… C_all 72 9392 Pave No_A… Regular Lvl AllPub Corner ## 10 One_Sto… Reside… 50 5925 Pave No_A… Regular Lvl AllPub Corner ## # … with 2,920 more rows, 64 more variables: Land_Slope &lt;chr&gt;, ## # Neighborhood &lt;chr&gt;, Condition_1 &lt;chr&gt;, Condition_2 &lt;chr&gt;, Bldg_Type &lt;chr&gt;, ## # House_Style &lt;chr&gt;, Overall_Cond &lt;chr&gt;, Year_Built &lt;dbl&gt;, ## # Year_Remod_Add &lt;dbl&gt;, Roof_Style &lt;chr&gt;, Roof_Matl &lt;chr&gt;, ## # Exterior_1st &lt;chr&gt;, Exterior_2nd &lt;chr&gt;, Mas_Vnr_Type &lt;chr&gt;, ## # Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;chr&gt;, Foundation &lt;chr&gt;, Bsmt_Cond &lt;chr&gt;, ## # Bsmt_Exposure &lt;chr&gt;, BsmtFin_Type_1 &lt;chr&gt;, BsmtFin_SF_1 &lt;dbl&gt;, … Si las queremos ordenar de forma ascendente, lo haremos del siguiente modo: ames_housing %&gt;% arrange(desc(Sale_Price)) ## # A tibble: 2,930 × 74 ## MS_Sub…¹ MS_Zo…² Lot_F…³ Lot_A…⁴ Street Alley Lot_S…⁵ Land_…⁶ Utili…⁷ Lot_C…⁸ ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Two_Sto… Reside… 104 21535 Pave No_A… Slight… Lvl AllPub Corner ## 2 Two_Sto… Reside… 160 15623 Pave No_A… Slight… Lvl AllPub Corner ## 3 Two_Sto… Reside… 118 35760 Pave No_A… Slight… Lvl AllPub CulDSac ## 4 One_Sto… Reside… 106 12720 Pave No_A… Regular HLS AllPub Inside ## 5 One_Sto… Reside… 100 12919 Pave No_A… Slight… Lvl AllPub Inside ## 6 One_Sto… Reside… 105 13693 Pave No_A… Regular Lvl AllPub Inside ## 7 One_Sto… Reside… 52 51974 Pave No_A… Slight… Lvl AllPub CulDSac ## 8 Two_Sto… Reside… 114 17242 Pave No_A… Slight… Lvl AllPub Inside ## 9 Two_Sto… Reside… 107 13891 Pave No_A… Regular Lvl AllPub Inside ## 10 Two_Sto… Reside… 85 16056 Pave No_A… Slight… Lvl AllPub Inside ## # … with 2,920 more rows, 64 more variables: Land_Slope &lt;chr&gt;, ## # Neighborhood &lt;chr&gt;, Condition_1 &lt;chr&gt;, Condition_2 &lt;chr&gt;, Bldg_Type &lt;chr&gt;, ## # House_Style &lt;chr&gt;, Overall_Cond &lt;chr&gt;, Year_Built &lt;dbl&gt;, ## # Year_Remod_Add &lt;dbl&gt;, Roof_Style &lt;chr&gt;, Roof_Matl &lt;chr&gt;, ## # Exterior_1st &lt;chr&gt;, Exterior_2nd &lt;chr&gt;, Mas_Vnr_Type &lt;chr&gt;, ## # Mas_Vnr_Area &lt;dbl&gt;, Exter_Cond &lt;chr&gt;, Foundation &lt;chr&gt;, Bsmt_Cond &lt;chr&gt;, ## # Bsmt_Exposure &lt;chr&gt;, BsmtFin_Type_1 &lt;chr&gt;, BsmtFin_SF_1 &lt;dbl&gt;, … Si se desea usar dos o más columnas para realizar el ordenamiento, deben separarse por comas cada una de las características ames_housing %&gt;% arrange(Sale_Condition, desc(Sale_Price), Lot_Area) %&gt;% select(Sale_Condition, Sale_Price, Lot_Area) ## # A tibble: 2,930 × 3 ## Sale_Condition Sale_Price Lot_Area ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Abnorml 745000 15623 ## 2 Abnorml 552000 14836 ## 3 Abnorml 475000 11778 ## 4 Abnorml 390000 13418 ## 5 Abnorml 328900 5119 ## 6 Abnorml 310000 14541 ## 7 Abnorml 290000 9950 ## 8 Abnorml 287000 15498 ## 9 Abnorml 258000 12090 ## 10 Abnorml 257000 10994 ## # … with 2,920 more rows Notemos que en el ejemplo anterior usamos dos pipes (%&gt;%), como habíamos mencionado se pueden usar los necesarios para combinar funciones. 3.2.4 Agregar / Modificar Con la función mutate() podemos computar transformaciones de variables en un data frame. A menudo, tendremos la necesidad de crear nuevas variables que se calculan a partir de variables existentes. La función mutate() proporciona una interfaz clara para realizar este tipo de operaciones. Por ejemplo, haremos el cálculo de la antigüedad del inmueble a partir de las variables Year_Sold y Year_Remod_Add: ejemplo_mutate &lt;- ames_housing %&gt;% select(Year_Sold, Year_Remod_Add) %&gt;% mutate(Antique = Year_Sold - Year_Remod_Add) ejemplo_mutate ## # A tibble: 2,930 × 3 ## Year_Sold Year_Remod_Add Antique ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2010 1960 50 ## 2 2010 1961 49 ## 3 2010 1958 52 ## 4 2010 1968 42 ## 5 2010 1998 12 ## 6 2010 1998 12 ## 7 2010 2001 9 ## 8 2010 1992 18 ## 9 2010 1996 14 ## 10 2010 1999 11 ## # … with 2,920 more rows El ejemplo anterior crea una nueva variable. Ahora se presenta otro ejemplo en donde se modifica una variable ya creada. ejemplo_mutate %&gt;% mutate(Antique = Antique * 12) ## # A tibble: 2,930 × 3 ## Year_Sold Year_Remod_Add Antique ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2010 1960 600 ## 2 2010 1961 588 ## 3 2010 1958 624 ## 4 2010 1968 504 ## 5 2010 1998 144 ## 6 2010 1998 144 ## 7 2010 2001 108 ## 8 2010 1992 216 ## 9 2010 1996 168 ## 10 2010 1999 132 ## # … with 2,920 more rows En este segundo ejemplo, se modifica el número de años de antigüedad y se multiplica por un factor de 12 para modificar el tiempo en una escala de meses. 3.2.5 Resumen estadístico La función summarise() se comporta de forma análoga a la función mutate(), excepto que en lugar de añadir nuevas columnas crea un nuevo data frame. Podemos usar el ejemplo anterior y calcular la media de la variable creada Antique: ames_housing %&gt;% select(Year_Sold, Year_Remod_Add) %&gt;% mutate(Antique = Year_Sold - Year_Remod_Add) %&gt;% summarise(Mean_Antique = mean(Antique)) ## # A tibble: 1 × 1 ## Mean_Antique ## &lt;dbl&gt; ## 1 23.5 Solo fue necesario agregar un pipe, especificar el nombre de la variable creada y la operación a realizar. A continuación se muestran funciones que trabajando conjuntamente con la función summarise() facilitarán nuestro trabajo diario. Las primeras pertenecen al paquete base y las otras son del paquete dplyr. Todas ellas toman como argumento un vector y devuelven un único resultado: min(), max() : Valores max y min. mean() : Media. median() : Mediana. sum() : Suma de los valores. var(), sd() : Varianza y desviación estándar. first() : Primer valor en un vector. last() : El último valor en un vector n() : El número de valores en un vector. n_distinct() : El número de valores distintos en un vector. nth() : Extrae el valor que ocupa la posición n en un vector. Mas adelante veremos como combinar esta función con la función group_by() para calcular estadísticos agrupados por alguna característica de interés. EJERCICIO: Realizar una consulta usando summarise() y cada una de las funciones estadísticas listadas anteriormente. 3.2.6 Agrupamiento La función group_by() agrupa un conjunto de filas de acuerdo con los valores de una o más columnas o expresiones. Usaremos el ejemplo anterior. Primero creamos nuestra nueva variable Antique, después agrupamos por vecindario y al final calculamos la media de la variable Antique. Gracias al agrupamiento, nos regresara una media por cada grupo creado, es decir, nos regresara el promedio de la antigüedad por vecindario. ames_housing %&gt;% mutate(Antique = Year_Sold - Year_Remod_Add) %&gt;% group_by(Neighborhood) %&gt;% summarise(Mean_Antique = round(mean(Antique), 0)) ## # A tibble: 28 × 2 ## Neighborhood Mean_Antique ## &lt;chr&gt; &lt;dbl&gt; ## 1 Bloomington_Heights 2 ## 2 Blueste 25 ## 3 Briardale 35 ## 4 Brookside 39 ## 5 Clear_Creek 28 ## 6 College_Creek 8 ## 7 Crawford 29 ## 8 Edwards 33 ## 9 Gilbert 9 ## 10 Green_Hills 14 ## # … with 18 more rows 3.2.7 Cruces de tablas Una operación fundamental por agregar al flujo de trabajo es el cruce de tablas, las cuales pueden proceder de la misma o de distinta fuente. Comúnmente este proceso se realiza para enriquecer y unificar la información proveniente de distintas tablas. Para lograr esta tarea es indispensable que exista una variable llave en ambos conjuntos de datos que sirva como puente o identificador de cada caso o renglón. Si se cuenta con la columna llave entonces será posible cruzar las tablas y lograr su enriquecimiento. En el siguiente ejemplo se muestra el uso de la variable llave a través de la columna “ID”. Se puede apreciar que en la tabla final se cuenta con información de la variable “Weight” para los elementos que existen en las tablas “A” y “B”. La función que hace posible el complemento de la información es llamada left_join(). El primer argumento de la función corresponde al conjunto de datos que se desea complementar, mientras que en el segundo argumento se ingresa el conjunto de datos con la información que enriquecerá al primer conjunto. Es necesario especificar en el argumento “by” el nombre de la columna llave. conjuntoX &lt;- tibble(&quot;Llave&quot; = LETTERS[1:8], &quot;C1&quot; = 1:8) conjuntoY &lt;- tibble( &quot;Llave&quot; = sample(LETTERS[11:3], size = 9, replace = T), &quot;Ex1&quot; = letters[2:10], &quot;Ex2&quot; = 1002:1010,&quot;Ex3&quot; = paste0(letters[12:20], 2:10) ) conjuntoX ## # A tibble: 8 × 2 ## Llave C1 ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 C 3 ## 4 D 4 ## 5 E 5 ## 6 F 6 ## 7 G 7 ## 8 H 8 conjuntoY ## # A tibble: 9 × 4 ## Llave Ex1 Ex2 Ex3 ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 F b 1002 l2 ## 2 I c 1003 m3 ## 3 K d 1004 n4 ## 4 H e 1005 o5 ## 5 F f 1006 p6 ## 6 J g 1007 q7 ## 7 C h 1008 r8 ## 8 J i 1009 s9 ## 9 I j 1010 t10 left_join(x = conjuntoX, y = conjuntoY, by = &quot;Llave&quot;) ## # A tibble: 9 × 5 ## Llave C1 Ex1 Ex2 Ex3 ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 A 1 &lt;NA&gt; NA &lt;NA&gt; ## 2 B 2 &lt;NA&gt; NA &lt;NA&gt; ## 3 C 3 h 1008 r8 ## 4 D 4 &lt;NA&gt; NA &lt;NA&gt; ## 5 E 5 &lt;NA&gt; NA &lt;NA&gt; ## 6 F 6 b 1002 l2 ## 7 F 6 f 1006 p6 ## 8 G 7 &lt;NA&gt; NA &lt;NA&gt; ## 9 H 8 e 1005 o5 Es posible que no todas las observaciones de un conjunto de datos estén en el otro conjunto. Cuando esto sucede, un aviso aparece indicando que los factores o categorías de la variable llave son diferentes. En caso de no encontrarse uno o más de los valores, el resultado para esos casos será NA (no disponible, por su traducción del inglés “Not Available”), y aparecerá siempre que no se cuente con información en un registro, como se muestra en el ejemplo anterior. Existen diferentes maneras de conjuntar datos. La primera, como en el ejemplo mostrado anteriormente, se hace por lo izquierda y quiere decir que, al primer conjunto de datos es al que se le agregará la información del segundo conjunto. Esto se realizará exclusivamente para aquellos registros de la segunda tabla que existan también en la primera, los cuales se identifican mediante la llave definida. Otra manera de realizar la conjunción de los datos es por la derecha. Funciona de manera análoga a la primera, con la diferencia de que son los datos del primer conjunto los que se agregan al segundo. De igual manera, esto sólo ocurre para los elemento del primer conjunto que se encuentran en el segundo y que son identificables a través de una llave. La función en R que permite realizar la conjunción por la derecha lleva por nombre right_join(). right_join(x = conjuntoX, y = conjuntoY, by = &quot;Llave&quot;) ## # A tibble: 9 × 5 ## Llave C1 Ex1 Ex2 Ex3 ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 C 3 h 1008 r8 ## 2 F 6 b 1002 l2 ## 3 F 6 f 1006 p6 ## 4 H 8 e 1005 o5 ## 5 I NA c 1003 m3 ## 6 K NA d 1004 n4 ## 7 J NA g 1007 q7 ## 8 J NA i 1009 s9 ## 9 I NA j 1010 t10 Una tercer forma de unir los datos es a través de la función full_join(), la cual es una combinación de las dos anteriores. Agrega todos los elementos llave tanto del primer conjunto como del segundo y posteriormente realiza el cruce de información de ambos conjuntos. full_join(x = conjuntoX, y = conjuntoY, by = &quot;Llave&quot;) ## # A tibble: 14 × 5 ## Llave C1 Ex1 Ex2 Ex3 ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 A 1 &lt;NA&gt; NA &lt;NA&gt; ## 2 B 2 &lt;NA&gt; NA &lt;NA&gt; ## 3 C 3 h 1008 r8 ## 4 D 4 &lt;NA&gt; NA &lt;NA&gt; ## 5 E 5 &lt;NA&gt; NA &lt;NA&gt; ## 6 F 6 b 1002 l2 ## 7 F 6 f 1006 p6 ## 8 G 7 &lt;NA&gt; NA &lt;NA&gt; ## 9 H 8 e 1005 o5 ## 10 I NA c 1003 m3 ## 11 K NA d 1004 n4 ## 12 J NA g 1007 q7 ## 13 J NA i 1009 s9 ## 14 I NA j 1010 t10 Estos 3 primeros métodos pueden resumirse en la siguiente imagen: Adicionalmente, existen otras funciones que ayudan con gestionar las operaciones entre conjuntos de datos. Tal es el caso de la función inner_join(), la cuál no es otra cosa que el filtro de aquellos elementos que se tengan en común en ambas tablas y la combinación de un join. Internamente, la función primero filtra el ID de aquellos elementos que tienen presencia en ambas tablas y finalmente hace el cruce de los datos. inner_join(x = conjuntoX, y = conjuntoY, by = &quot;Llave&quot;) ## # A tibble: 4 × 5 ## Llave C1 Ex1 Ex2 Ex3 ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 C 3 h 1008 r8 ## 2 F 6 b 1002 l2 ## 3 F 6 f 1006 p6 ## 4 H 8 e 1005 o5 Existen otras dos operaciones interesantes que agilizan la extracción de subconjuntos de tablas sin cruzar información. Se trata de las funciones semi_join() y anti_join(), las cuales funcionan de la siguiente manera: La función semi_join() detecta y filtra los elementos del primer conjunto que se encuentran en un segundo conjunto, mientras que la función anti_join() es su complemento, pues regresa los elementos del primer conjunto que no se encuentran en el segundo. En ambos casos, la información contenida en el segundo conjunto no es trasmitida al resultado. A continuación se presenta un ejemplo: semi_join(x = conjuntoX, y = conjuntoY, by = &quot;Llave&quot;) ## # A tibble: 3 × 2 ## Llave C1 ## &lt;chr&gt; &lt;int&gt; ## 1 C 3 ## 2 F 6 ## 3 H 8 Ahora revisemos el caso de la función anti_join() anti_join(x = conjuntoX, y = conjuntoY, by = &quot;Llave&quot;) ## # A tibble: 5 × 2 ## Llave C1 ## &lt;chr&gt; &lt;int&gt; ## 1 A 1 ## 2 B 2 ## 3 D 4 ## 4 E 5 ## 5 G 7 WARNING: llaves duplicadas La mayoría de los ejemplos anteriores suponen que las llaves son únicas en cada conjunto de datos, sin embargo, esto no es cierto en una gran cantidad de ocasiones. Existen dos casos importantes por analizar: Llaves duplicadas en 1 conjunto de datos Llaves duplicadas en ambos conjuntos El caso más sencillo es cuando solo uno de los conjuntos contiene llaves duplicadas. En este caso se creará un renglón por cada duplicado. En el segundo caso, por cada elemento duplicado en el primer conjunto habrá como resultado un elemento por cada duplicado en el segundo conjunto. A continuación se ejemplifica este escenario. 3.3 Orden y estructura Un conjunto de datos puede ser representado de muchas maneras distintas y contener en todos los casos la misma información. Sin embargo, no todos los modos en que se presenta la información resulta óptimo para su procesamiento y análisis. Los conjuntos de datos ordenados serán más fáciles de trabajar y analizar. Algunas de las características principales que presentan los conjuntos de datos ordenados son las siguientes: Cada variable debe tener su propia columna. Cada observación debe tener su propio renglón. Cada valor debe tener su propia celda. La figura anterior muestra la estructura de orden que debe tener un conjunto de datos. A pesar de que pueda parecer intuitivo y sencillo, en la práctica es considerable el número de conjuntos de datos desordenados. La limpieza y ordenamiento debe ser trabajado de forma impecable a fin de que puedan realizarse buenas prácticas. El tiempo de limpieza y ordenamiento varía mucho dependiendo de la dimensión del conjunto de datos. Algunos de los principales problemas que pueden tener los conjuntos de datos no ordenados son: Una variable puede estar dispersa en múltiples columnas Una observación puede estar esparcida en múltiples renglones La paquetería tidyr cuenta con funciones para resolver dichos problemas. Entre las principales funciones que tiene la paquetería, se encuentran pivot_longer(), pivot_wider(), separate() y unite(), mismas que se analizarán a continuación. 3.3.1 Pivote horizontal La función pivot_wider() resulta muy útil a la hora de organizar los datos. Su función consiste en dispersar una variable clave en múltiples columnas. Lo primero que se debe hacer para poder hacer uso de dicha función es instalar y cargar la librería. El siguiente conjunto de datos contiene el número de localidades rurales y urbanas por municipio de la Ciudad de México. Como es posible observar, algunos municipios aparecen más de una vez en el marco de datos, esto se debe a que cada municipio puede tener ambos ámbitos, rural y urbano. Para hacer que el conjunto de datos sea ordenado, es necesario que cada observación aparezca una sola vez por renglón y cada una de las categorías (rural y urbano) de la variable “Ámbito” deberá ocupar el lugar de una columna. El siguiente código muestra cómo convertir los datos no ordenados en un conjunto ordenado. library(tidyr) Resumen &lt;- readRDS(&quot;data/loc_mun_cdmx.rds&quot;) Resumen %&gt;% pivot_wider( names_from = Ambito, values_from = Total_localidades ) ## # A tibble: 16 × 3 ## NOM_MUN Rural Urbano ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Álvaro Obregón 3 1 ## 2 La Magdalena Contreras 8 1 ## 3 Cuajimalpa de Morelos 14 2 ## 4 Tláhuac 31 5 ## 5 Xochimilco 78 1 ## 6 Tlalpan 95 4 ## 7 Milpa Alta 187 10 ## 8 Azcapotzalco NA 1 ## 9 Benito Juárez NA 1 ## 10 Coyoacán NA 1 ## 11 Cuauhtémoc NA 1 ## 12 Gustavo A. Madero NA 1 ## 13 Iztacalco NA 1 ## 14 Iztapalapa NA 1 ## 15 Miguel Hidalgo NA 1 ## 16 Venustiano Carranza NA 1 En la tabla actual existe ahora un y solo un registro por cada observación (nombre de municipio en este caso). El valor que le corresponde a cada una de las columnas creadas es la frecuencia absoluta de localidades que tienen la característica “Rural” y “Urbano” respectivamente. Pero… ¿qué pasa cuando no existen todos los valores en ambas columnas? Si no se especifica la manera de llenar los datos faltantes, estos contendrán NAs. Siempre se puede elegir el caracter o número con el cual se imputan los datos faltantes. fish_encounters %&gt;% pivot_wider(names_from = station, values_from = seen) ## # A tibble: 19 × 12 ## fish Release I80_1 Lisbon Rstr Base_TD BCE BCW BCE2 BCW2 MAE MAW ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 4842 1 1 1 1 1 1 1 1 1 1 1 ## 2 4843 1 1 1 1 1 1 1 1 1 1 1 ## 3 4844 1 1 1 1 1 1 1 1 1 1 1 ## 4 4845 1 1 1 1 1 NA NA NA NA NA NA ## 5 4847 1 1 1 NA NA NA NA NA NA NA NA ## 6 4848 1 1 1 1 NA NA NA NA NA NA NA ## 7 4849 1 1 NA NA NA NA NA NA NA NA NA ## 8 4850 1 1 NA 1 1 1 1 NA NA NA NA ## 9 4851 1 1 NA NA NA NA NA NA NA NA NA ## 10 4854 1 1 NA NA NA NA NA NA NA NA NA ## 11 4855 1 1 1 1 1 NA NA NA NA NA NA ## 12 4857 1 1 1 1 1 1 1 1 1 NA NA ## 13 4858 1 1 1 1 1 1 1 1 1 1 1 ## 14 4859 1 1 1 1 1 NA NA NA NA NA NA ## 15 4861 1 1 1 1 1 1 1 1 1 1 1 ## 16 4862 1 1 1 1 1 1 1 1 1 NA NA ## 17 4863 1 1 NA NA NA NA NA NA NA NA NA ## 18 4864 1 1 NA NA NA NA NA NA NA NA NA ## 19 4865 1 1 1 NA NA NA NA NA NA NA NA fish_encounters %&gt;% pivot_wider(names_from = station, values_from = seen, values_fill = 0) ## # A tibble: 19 × 12 ## fish Release I80_1 Lisbon Rstr Base_TD BCE BCW BCE2 BCW2 MAE MAW ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 4842 1 1 1 1 1 1 1 1 1 1 1 ## 2 4843 1 1 1 1 1 1 1 1 1 1 1 ## 3 4844 1 1 1 1 1 1 1 1 1 1 1 ## 4 4845 1 1 1 1 1 0 0 0 0 0 0 ## 5 4847 1 1 1 0 0 0 0 0 0 0 0 ## 6 4848 1 1 1 1 0 0 0 0 0 0 0 ## 7 4849 1 1 0 0 0 0 0 0 0 0 0 ## 8 4850 1 1 0 1 1 1 1 0 0 0 0 ## 9 4851 1 1 0 0 0 0 0 0 0 0 0 ## 10 4854 1 1 0 0 0 0 0 0 0 0 0 ## 11 4855 1 1 1 1 1 0 0 0 0 0 0 ## 12 4857 1 1 1 1 1 1 1 1 1 0 0 ## 13 4858 1 1 1 1 1 1 1 1 1 1 1 ## 14 4859 1 1 1 1 1 0 0 0 0 0 0 ## 15 4861 1 1 1 1 1 1 1 1 1 1 1 ## 16 4862 1 1 1 1 1 1 1 1 1 0 0 ## 17 4863 1 1 0 0 0 0 0 0 0 0 0 ## 18 4864 1 1 0 0 0 0 0 0 0 0 0 ## 19 4865 1 1 1 0 0 0 0 0 0 0 0 En caso de que existan múltiples columnas que se desean dispersar mediante el pivote de una columna con múltiples categorías, es posible especificar tal re estructuración a través del siguiente código. us_rent_income %&gt;% arrange(NAME) ## # A tibble: 104 × 5 ## GEOID NAME variable estimate moe ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Alabama income 24476 136 ## 2 01 Alabama rent 747 3 ## 3 02 Alaska income 32940 508 ## 4 02 Alaska rent 1200 13 ## 5 04 Arizona income 27517 148 ## 6 04 Arizona rent 972 4 ## 7 05 Arkansas income 23789 165 ## 8 05 Arkansas rent 709 5 ## 9 06 California income 29454 109 ## 10 06 California rent 1358 3 ## # … with 94 more rows us_rent_income %&gt;% pivot_wider(names_from = variable, values_from = c(estimate, moe)) ## # A tibble: 52 × 6 ## GEOID NAME estimate_income estimate_rent moe_income moe_rent ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 01 Alabama 24476 747 136 3 ## 2 02 Alaska 32940 1200 508 13 ## 3 04 Arizona 27517 972 148 4 ## 4 05 Arkansas 23789 709 165 5 ## 5 06 California 29454 1358 109 3 ## 6 08 Colorado 32401 1125 109 5 ## 7 09 Connecticut 35326 1123 195 5 ## 8 10 Delaware 31560 1076 247 10 ## 9 11 District of Columbia 43198 1424 681 17 ## 10 12 Florida 25952 1077 70 3 ## # … with 42 more rows Adicionalmente, se puede especificar una función de agregación que operara antes de acomodar los datos en las respectivas columnas indicadas. Un ejemplo de funciones agregadas en la re estructuración de tabla se muestra a continuación, donde se muestra la media de los valores en las categorías tension y breaks. warpbreaks &lt;- warpbreaks[c(&quot;wool&quot;, &quot;tension&quot;, &quot;breaks&quot;)] %&gt;% as_tibble() warpbreaks ## # A tibble: 54 × 3 ## wool tension breaks ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 A L 26 ## 2 A L 30 ## 3 A L 54 ## 4 A L 25 ## 5 A L 70 ## 6 A L 52 ## 7 A L 51 ## 8 A L 26 ## 9 A L 67 ## 10 A M 18 ## # … with 44 more rows warpbreaks %&gt;% pivot_wider( names_from = wool, values_from = breaks, values_fn = mean ) ## # A tibble: 3 × 3 ## tension A B ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 L 44.6 28.2 ## 2 M 24 28.8 ## 3 H 24.6 18.8 3.3.2 Pivote vertical pivot_longer() es podría ser la función inversa de la anterior, se necesita comúnmente para ordenar los conjuntos de datos capturados en crudo, ya que a menudo no son capturados acorde a las mejores estructuras para facilitar el análisis. El conjunto de datos relig_income almacena recuentos basados en una encuesta que (entre otras cosas) preguntó a las personas sobre su religión e ingresos anuales: relig_income ## # A tibble: 18 × 11 ## religion `&lt;$10k` $10-2…¹ $20-3…² $30-4…³ $40-5…⁴ $50-7…⁵ $75-1…⁶ $100-…⁷ ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Agnostic 27 34 60 81 76 137 122 109 ## 2 Atheist 12 27 37 52 35 70 73 59 ## 3 Buddhist 27 21 30 34 33 58 62 39 ## 4 Catholic 418 617 732 670 638 1116 949 792 ## 5 Don’t know/r… 15 14 15 11 10 35 21 17 ## 6 Evangelical … 575 869 1064 982 881 1486 949 723 ## 7 Hindu 1 9 7 9 11 34 47 48 ## 8 Historically… 228 244 236 238 197 223 131 81 ## 9 Jehovah&#39;s Wi… 20 27 24 24 21 30 15 11 ## 10 Jewish 19 19 25 25 30 95 69 87 ## 11 Mainline Prot 289 495 619 655 651 1107 939 753 ## 12 Mormon 29 40 48 51 56 112 85 49 ## 13 Muslim 6 7 9 10 9 23 16 8 ## 14 Orthodox 13 17 23 32 32 47 38 42 ## 15 Other Christ… 9 7 11 13 13 14 18 14 ## 16 Other Faiths 20 33 40 46 49 63 46 40 ## 17 Other World … 5 2 3 4 2 7 3 4 ## 18 Unaffiliated 217 299 374 365 341 528 407 321 ## # … with 2 more variables: `&gt;150k` &lt;dbl&gt;, `Don&#39;t know/refused` &lt;dbl&gt;, and ## # abbreviated variable names ¹​`$10-20k`, ²​`$20-30k`, ³​`$30-40k`, ⁴​`$40-50k`, ## # ⁵​`$50-75k`, ⁶​`$75-100k`, ⁷​`$100-150k` ¿Crees que ésta es la mejor estructura para la tabla? ¿Cómo imaginas que podría modificarse? Este conjunto de datos contiene tres variables: religión, almacenada en las filas income repartidos entre los nombres de columna count almacenado en los valores de las celdas. Para ordenarlo usamos pivot_longer(): relig_income %&gt;% pivot_longer(cols = -religion, names_to = &quot;income&quot;, values_to = &quot;count&quot;) ## # A tibble: 180 × 3 ## religion income count ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Agnostic &lt;$10k 27 ## 2 Agnostic $10-20k 34 ## 3 Agnostic $20-30k 60 ## 4 Agnostic $30-40k 81 ## 5 Agnostic $40-50k 76 ## 6 Agnostic $50-75k 137 ## 7 Agnostic $75-100k 122 ## 8 Agnostic $100-150k 109 ## 9 Agnostic &gt;150k 84 ## 10 Agnostic Don&#39;t know/refused 96 ## # … with 170 more rows El primer argumento es el conjunto de datos para remodelar, relig_income. El segundo argumento describe qué columnas necesitan ser reformadas. En este caso, es cada columna aparte de religion. El names_to da el nombre de la variable que se creará a partir de los datos almacenados en los nombres de columna, es decir, ingresos. Los values_to dan el nombre de la variable que se creará a partir de los datos almacenados en el valor de la celda, es decir, count. Ni la columna names_to ni la values_to existen en relig_income, por lo que las proporcionamos como cadenas de caracteres entre comillas. 3.3.3 Unión de columnas Es común que en los conjuntos de datos exista información esparcida en distintas columnas que sería deseable (en muy pocas ocasiones) tenerlas en una sola columna. Algunos ejemplos de esta situación deseable son las fechas y claves geoestadísticas. La función unite() sirve para concatenar el contenido de columnas mediante un separador elegible. Se usará la variable de la clave geoestadística de localidades del país como ejemplo. El formato para las claves geoestadísticas para estado, municipio y localidad son claves alfanuméricas que contienen 2, 3 y 4 caracteres respectivamente. Es indispensable que al trabajar con claves geoestadísticas, las claves estén en su formato original. A continuación se hará la homologación de las claves para usar la función unite(). library(magrittr) library(readxl) library(stringr) Datos &lt;- read_excel(&quot;data/Margin CONAPO.xlsx&quot;, sheet = &quot;Margin CONAPO&quot;) Datos ## # A tibble: 107,458 × 21 ## ENT NOM_ENT MUN NOM_MUN LOC NOM_LOC POB_TOT VPH ANAL10 SPRIM10 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Aguascalient… 1 Aguasc… 1 Aguasc… 722250 184123 2.26 10.9 ## 2 1 Aguascalient… 1 Aguasc… 96 Agua A… 37 11 17.9 48.1 ## 3 1 Aguascalient… 1 Aguasc… 104 Ardill… 14 3 0 20 ## 4 1 Aguascalient… 1 Aguasc… 106 Arella… 1382 255 5.60 24.7 ## 5 1 Aguascalient… 1 Aguasc… 112 Bajío … 55 11 14.3 38.1 ## 6 1 Aguascalient… 1 Aguasc… 114 Reside… 757 202 0 1.63 ## 7 1 Aguascalient… 1 Aguasc… 120 Buenav… 935 217 10.7 29.5 ## 8 1 Aguascalient… 1 Aguasc… 121 Cabeci… 184 44 4.55 32.6 ## 9 1 Aguascalient… 1 Aguasc… 125 Cañada… 395 82 8.86 23.9 ## 10 1 Aguascalient… 1 Aguasc… 126 Cañada… 509 123 4.75 19.6 ## # … with 107,448 more rows, and 11 more variables: SEXC10 &lt;dbl&gt;, SEE10 &lt;dbl&gt;, ## # SAGUAE10 &lt;dbl&gt;, PROM_OCC10 &lt;dbl&gt;, PISOTIE10 &lt;dbl&gt;, SREFRI10 &lt;dbl&gt;, ## # IM_2010 &lt;dbl&gt;, GM_2010 &lt;chr&gt;, IMC0A100 &lt;dbl&gt;, LUG_NAL &lt;dbl&gt;, LUG_EDO &lt;dbl&gt; Como puede apreciarse en la tabla anterior, las claves de los campos Ent, Mun y Loc aparecen como numéricos. La estructura deseada para estos campos es de tipo alfanumérico y de longitud 2, 3 y 4 respectivamente. Para lograr esta estructura de datos, es necesario concatenar tantos ceros como sean necesarios antes del valor actual hasta lograr la longitud deseada. Datos2 &lt;- Datos %&gt;% select(ENT, MUN, LOC) Datos2$ENT %&lt;&gt;% str_pad(width = 2, side = &quot;left&quot;, pad = &quot;0&quot;) Datos2$MUN %&lt;&gt;% str_pad(width = 3, side = &quot;left&quot;, pad = &quot;0&quot;) Datos2$LOC %&lt;&gt;% str_pad(width = 4, side = &quot;left&quot;, pad = &quot;0&quot;) Datos2 %&gt;% head(5) ## # A tibble: 5 × 3 ## ENT MUN LOC ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 01 001 0001 ## 2 01 001 0096 ## 3 01 001 0104 ## 4 01 001 0106 ## 5 01 001 0112 Datos2 %&gt;% unite(&quot;CVE_GEO&quot;, c(&quot;ENT&quot;,&quot;MUN&quot;,&quot;LOC&quot;), sep=&quot;&quot;, remove = F) %&gt;% head(5) ## # A tibble: 5 × 4 ## CVE_GEO ENT MUN LOC ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 010010001 01 001 0001 ## 2 010010096 01 001 0096 ## 3 010010104 01 001 0104 ## 4 010010106 01 001 0106 ## 5 010010112 01 001 0112 Datos2 %&gt;% unite(&quot;CVE_GEO&quot;, c(&quot;ENT&quot;,&quot;MUN&quot;,&quot;LOC&quot;), sep=&quot;/&quot;,remove = T) %&gt;% head(5) ## # A tibble: 5 × 1 ## CVE_GEO ## &lt;chr&gt; ## 1 01/001/0001 ## 2 01/001/0096 ## 3 01/001/0104 ## 4 01/001/0106 ## 5 01/001/0112 En el código anterior se carga la librería magrittr para poder hacer uso del operador pipe doble “%&lt;&gt;%”, que permite al igual que el operador pipe simple “%&gt;%”, usar como argumento al primer elemento y mandarlo hacia la función definida, además de guardar el resultado final de la cadena de pipes en el argumento original que fue usado como insumo para la función. Es importante tener en cuenta que el dato será reescrito y no se podrá tener acceso a su información almacenada antes de ser usado el operador. Es opción del programador poder eliminar las variables originales que crearon la nueva variable o mantenerlas en el conjunto de datos. Esta opción está disponible en el parámetro remove de la función unite(). 3.3.4 Separador de columnas Los procesos que se han visto hasta ahora han tenido cada uno una función inversa, este es también el caso de la función unite que tiene por objetivo unir dos o más columnas en una. La función separate() separará una columna en dos o más dependiendo de la longitud que tenga y de las especificaciones de separación. Datos_unite1 &lt;- Datos2 %&gt;% unite(&quot;CVE_GEO&quot;, c(&quot;ENT&quot;,&quot;MUN&quot;,&quot;LOC&quot;), sep = &quot;&quot;, remove = T) Datos_unite1 %&gt;% head(5) ## # A tibble: 5 × 1 ## CVE_GEO ## &lt;chr&gt; ## 1 010010001 ## 2 010010096 ## 3 010010104 ## 4 010010106 ## 5 010010112 Datos_unite1 %&gt;% separate(&quot;CVE_GEO&quot;, c(&quot;EDO&quot;,&quot;MUNI&quot;,&quot;LOC&quot;), sep = c(2, 5), remove=F) %&gt;% head(5) ## # A tibble: 5 × 4 ## CVE_GEO EDO MUNI LOC ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 010010001 01 001 0001 ## 2 010010096 01 001 0096 ## 3 010010104 01 001 0104 ## 4 010010106 01 001 0106 ## 5 010010112 01 001 0112 Ya sea que se le especifique el número de caracteres que debe de contar para hacer un corte o que se le indique qué caracter debe identificar para hacer la separación, la función separate() puede dividir la columna indicada y crear nuevas a partir de la original. 3.4 Manipulación de texto Anteriormente se mencionaron algunas paqueterías que están incluidas dentro del conjunto Tidyverse. La paquetería stringr no forma parte del núcleo de Tidyverse, no obstante, sí pertenece a dicho conjunto y es ampliamente usada junto a las paqueterías nucleares debido a la facilidad que tiene para trabajar con cadenas, textos y expresiones regulares en general. Las expresiones regulares, también conocidas como regex o regexp, son patrones de texto repetidos en los datos y que son usados para operar con otras cadenas de texto. El resultado de dichas operaciones es obtener o resumir información, además de manipular y ordenar los conjuntos de datos. Entre las principales operaciones se encuentran los conteos, concatenaciones, separaciones, búsquedas, extracciones, imputaciones y sustituciones. 3.4.1 Caracteres especiales Debido a que la paquetería stringr trabaja principalmente con cadenas de texto, es importante tener en cuenta que los objetos de caracteres se definen a través de comillas, ya sea simples o dobles. La única diferencia está en el caso en que se pretendan usar comillas como parte del texto. En estos casos, la comilla simple es preferible para ser la que defina el texto. library(stringr) Cadena1 &lt;- &quot;Se definen cadenas a través de comillas dobles&quot; print(Cadena1) ## [1] &quot;Se definen cadenas a través de comillas dobles&quot; Cadena2 &lt;- &#39;También es posible con comillas simples y el resultado es el mismo&#39; print(Cadena2) ## [1] &quot;También es posible con comillas simples y el resultado es el mismo&quot; Cadena3 &lt;- &#39;Se pueden implementar &quot;comillas&quot; dentro de la cadena&#39; print(Cadena3) ## [1] &quot;Se pueden implementar \\&quot;comillas\\&quot; dentro de la cadena&quot; Cadena4 &lt;- &#39;Esta es otra forma de incluir \\&quot;comillas\\&quot; dentro de un texto&#39; print(Cadena4) ## [1] &quot;Esta es otra forma de incluir \\&quot;comillas\\&quot; dentro de un texto&quot; Como es posible apreciar en los ejemplos anteriores, la cadena 3 y 4 no se imprimen exactamente como se definieron. Podría parecer que existe un error, ya que aparecen diagonales antes de los caracteres deseados. Para resolver este problema, únicamente es necesario mandar llamar a la función cat() . Esta función sirve como intérprete de los caracteres que se definen en una cadena. La función cat() sirve como sustituto de la función print() (cuya función es imprimir de forma literal lo que existe dentro de las comillas), con la diferencia de que cat() interpreta las salidas de caracteres especiales en el texto y concatena las salidas finales con el separador específico que se indique. Por default, el separador es un espacio vacío, sin embargo, es posible modificarlo. A continuación se ejemplifica su uso. cat(Cadena3) ## Se pueden implementar &quot;comillas&quot; dentro de la cadena cat(Cadena4) ## Esta es otra forma de incluir &quot;comillas&quot; dentro de un texto A través del operador diagonal invertida “\\” también es posible definir comillas de manera literal. En caso de querer escribir textualmente una diagonal invertida, se necesitará escribir entre comillas dos diagonales invertidas “\\\\”. Existen otros caracteres espaciales que ayudan a mejorar el formato de las cadenas. Algunos de los caracteres más comunes son “\\n” (nueva línea) y “\\t” (tabulador). Todas las funciones que se presentarán a continuación, son posibles encontrarlas con otro nombre dentro de la paquetería básica. La ventaja que tienen las funciones de la paquetería stringr es que, los nombres son más intuitivos y comienzan con el mismo prefijo “str_”, haciendo que al escribir las primeras tres letras, la función de autocompletar de RStudio muestre una lista con sugerencias de los nombres de las posibles funciones a usarse. 3.4.2 Tamaño de cadena Es común que al procesar los conjuntos de datos, se requiera contar el número de caracteres que tiene una cadena. La paquetería básica cuenta con la función nchar() para realizar esta tarea. Con la ayuda de la paquetería stringr, es posible realizar esta misma tarea a través de la función str_length() str_length(&quot;Esta es una cadena de 35 caracteres&quot;) ## [1] 35 str_length(c(&quot;Un&quot;,&quot;vector&quot;,&quot;con&quot;,&quot;diferente&quot;,&quot;cantidad&quot;,&quot;de&quot;,&quot;carecteres&quot;,&quot;por&quot;,&quot;cadena&quot;)) ## [1] 2 6 3 9 8 2 10 3 6 Puede usarse la función tanto para objetos de cadenas individuales como para vectores. Existen muchos conjuntos de datos que durante su manipulación podemos encontrar claves alfanuméricas, que pueden ser necesarias unir información relevante o para crear claves de identificación única, por ejemplo poder unir el nombre completo de las personas dentro de una base de datos. Uniendo Nombre + Segundo Nombre + Primer Apellido + Segundo Apellido. Por otro lado de esto puede extraerse información sobre la CURP o en algunos otros ejemplos la unión de un ID + una matricula de carrera + el año pueden ser el registro para un estudiante o podrías querer replicar mensajes para alertas que dependan de una variable. 3.4.3 Concatenar Concatenar cadenas es una de las prácticas constantes en el manejo de conjuntos de datos. La función de la paquetería básica que se encarga de dicha tarea es la función paste(). A través de la paquetería stringr se logrará el concatenado mediante la función str_c(). Existe la opción de definir el caracter que hará la combinación de las cadenas mediante el argumento “sep”, que por default no deja ni un espacio entre las cadenas a combinar. Varios ejemplos se mostrarán a continuación. str_c(&quot;Concatenado&quot;, &quot;de&quot;,&quot;varias&quot;, &quot;cadenas&quot;, &quot;sin&quot;,&quot;espacios&quot;) ## [1] &quot;Concatenadodevariascadenassinespacios&quot; str_c(&quot;Concatenado&quot;,&quot;con&quot;,&quot;espacios&quot;, sep=&quot; &quot;) ## [1] &quot;Concatenado con espacios&quot; str_c(&quot;separando&quot;,&quot;mediante&quot;,&quot;otro&quot;,&quot;caracter&quot;,&quot;definido&quot;, sep=&quot;-&quot;) ## [1] &quot;separando-mediante-otro-caracter-definido&quot; str_c(&quot;Valores&quot;,str_c(&quot;09&quot;,&quot;006&quot;),&quot;anidados también se pueden concatenar&quot;,sep=&quot; &quot;) ## [1] &quot;Valores 09006 anidados también se pueden concatenar&quot; Es posible, al igual que con la función paste(), colapsar todas las cadenas de un vector en una sola cadena mediante el mismo parámetro: “collapse”. El caracter que divide a los elementos del vector debe ser especificado entre comillas, de lo contrario el valor por default será ” “. str_c(c(&quot;Colapsamiento&quot;, &quot;de&quot;,&quot;un&quot;,&quot;vector&quot;,&quot;de&quot;, &quot;cadenas&quot;, &quot;en&quot;,&quot;una&quot;, &quot;sola&quot;,&quot;cadena&quot;), collapse = &quot; &quot;) ## [1] &quot;Colapsamiento de un vector de cadenas en una sola cadena&quot; str_c(c(&quot;Colapsamiento&quot;, &quot;de&quot;,&quot;un&quot;,&quot;vector&quot;,&quot;de&quot;, &quot;cadenas&quot;, &quot;separado&quot;,&quot;por&quot;,&quot;signos&quot;), collapse = &quot;+&quot;) ## [1] &quot;Colapsamiento+de+un+vector+de+cadenas+separado+por+signos&quot; 3.4.4 Extraer y reemplazar Cuando únicamente interesa un subconjunto de alguna cadena para continuar con el manejo de la información, suele recurrirse a la expresión regular substr() de la paquetería básica para extraer este subconjunto de interés. Con stringr, la función para usar esta expresión regular es str_sub(). Esta función recibe como parámetros el texto desde el cuál se desea extraer el subconjunto, el índice que marque el inicio de la subcadena y el índice del final de la subcadena. str_sub(&quot;subcadenas&quot;, start = 4, end = 9) ## [1] &quot;cadena&quot; x &lt;- &quot;00000090060002&quot; str_sub(x, start = str_length(x) - 8, str_length(x)) ## [1] &quot;090060002&quot; str_sub(x, start = -9) ## [1] &quot;090060002&quot; Con la misma función str_sub() es posible sustituir parcial o totalmente la cadena “X” que sea introducida como argumento. Ésto se logra asignando a la subcadena seleccionada el valor que se usará para sustituir. En los siguientes ejemplos se muestra cómo modificar la cadena “substring” y la cadena “090060002”. En el primer caso, a partir de la cadena de caracteres “substring” se procede a generar una nueva cadena al sustituir las letras 4 a la 9, reemplazando así la subcadena “string” por “cadena”, dando lugar a “subcadena”. En el segundo ejemplo, es la clave correspondiente a los dígitos 3 a 5 los que cambian para dar lugar a otra clave numérica. y &lt;- &quot;substring&quot; str_sub(y, start = 4, end = 9) &lt;- &quot;cadena&quot;; y ## [1] &quot;subcadena&quot; x &lt;- &quot;090060002&quot; str_sub(x, start = str_length(x)-6,str_length(x)-4) &lt;- &quot;555&quot;; x ## [1] &quot;095550002&quot; Lo anterior es ampliamente usado en el proceso de limpieza de los datos. A veces es posible encontrar errores ortográficos o los llamados errores “de dedo” (hacen referencia a errores accidentales al escribir) que se dan a la hora de capturar la información. Cuando una gran cantidad de datos presentan el mismo error, es buena idea recurrir a esta función. 3.4.5 Expresiones regulares En el estudio de las expresiones regulares se puede encontrar de manera sobresaliente la aplicación de los patrones coincidentes, los cuáles sirven para describir y descubrir coincidencias de interés en conjuntos específicos a partir de cadenas de caracteres. Con el fin de comprender y visualizar de manera práctica el uso de los patrones coincidentes con las expresiones regulares, se hará uso de la función str_view(), que permite distinguir los elementos coincidentes de un vector con un patrón de caracteres descrito. La paquetería stringr cuenta con tres conjuntos predefinidos de oraciones y palabras que sirven para ejemplificar el uso de las expresiones regulares. Estos conjuntos llevan el nombre de sentences, words y fruit, su contenido es de sentencias, palabras y nombres de frutas. En los tres casos, estos conjuntos han sido escritos en inglés. Los conjuntos sirven bien para ejemplificar el uso de las siguientes funciones y de las expresiones regulares. head(sentences, 10) ## [1] &quot;The birch canoe slid on the smooth planks.&quot; ## [2] &quot;Glue the sheet to the dark blue background.&quot; ## [3] &quot;It&#39;s easy to tell the depth of a well.&quot; ## [4] &quot;These days a chicken leg is a rare dish.&quot; ## [5] &quot;Rice is often served in round bowls.&quot; ## [6] &quot;The juice of lemons makes fine punch.&quot; ## [7] &quot;The box was thrown beside the parked truck.&quot; ## [8] &quot;The hogs were fed chopped corn and garbage.&quot; ## [9] &quot;Four hours of steady work faced us.&quot; ## [10] &quot;Large size in stockings is hard to sell.&quot; head(words, 20) ## [1] &quot;a&quot; &quot;able&quot; &quot;about&quot; &quot;absolute&quot; &quot;accept&quot; &quot;account&quot; ## [7] &quot;achieve&quot; &quot;across&quot; &quot;act&quot; &quot;active&quot; &quot;actual&quot; &quot;add&quot; ## [13] &quot;address&quot; &quot;admit&quot; &quot;advertise&quot; &quot;affect&quot; &quot;afford&quot; &quot;after&quot; ## [19] &quot;afternoon&quot; &quot;again&quot; head(fruit, 20) ## [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; &quot;banana&quot; &quot;bell pepper&quot; ## [6] &quot;bilberry&quot; &quot;blackberry&quot; &quot;blackcurrant&quot; &quot;blood orange&quot; &quot;blueberry&quot; ## [11] &quot;boysenberry&quot; &quot;breadfruit&quot; &quot;canary melon&quot; &quot;cantaloupe&quot; &quot;cherimoya&quot; ## [16] &quot;cherry&quot; &quot;chili pepper&quot; &quot;clementine&quot; &quot;cloudberry&quot; &quot;coconut&quot; Para realizar una coincidencia de patrones, es necesario ingresar como argumento el vector de cadenas de caracteres en donde se desea hacer la búsqueda. Como segundo argumento, se ingresa el patrón con el cuál se desea buscar las coincidencias. Para que únicamente se muestren las coincidencias exitosas se debe agregar el argumento match = TRUE. str_view(sentences,&quot;great&quot;, match = TRUE) str_view(sentences,&quot;this&quot;, match = TRUE) Como es posible apreciarse en los dos ejemplos anteriores, la función str_view() filtra los casos coincidentes con los patrones “great” y “this”. Esta coincidencia no necesariamente es perfecta. Basta con que un subconjunto de la sentencia coincida con el patrón definido para que la función str_view() reconozca como coincidencia válida a toda la cadena. En caso de no contar con todos los caracteres del patrón deseado o de querer ver todas las combinaciones que tengan un patrón adyacente común, es posible ingresar un “comodín” a través del caracter punto “.”, el cuál coincidirá con cualquier caracter. Este caracter especial puede usarse al principio, al final o de manera intermedia dentro del patrón. str_view(sentences,&quot;up.&quot;, match = TRUE) Como se puede observar, esta es una manera de detectar subconjuntos de particular interés. Si \\ es usado para escapar un caracter especial, ¿cómo hacemos para hacer match con el caracter \\ literalmente? Necesita ser escapado, creando la expresión regular \\\\. Para crear la expresión regular, se necesita usar un string, el cual también requiere ser escapado. Esto significa que para hacer match con  se necesita escribir “\\\\\\\\” cuatro diagonales invertidas para hacer match con una sola diagonal invertida \\. Los primeros 2 diagonales son para crear la expresión regular, la tercera es para escapar el caracter especial siguiente, el cual corresponde a la cuarta diagonal. Anclajes Como se mencionó anteriormente, por default, la coincidencia de patrones se efectuará sobre cualquier subconjunto de la cadena de caracteres. Es posible definir el caracter inicial y/o el caracter final con el cuál se buscará la coincidencia de patrones. Esto se logra al hacer uso de los siguientes caracteres especiales. ^ Para hacer coincidir el inicio de la cadena $ Para hacer coincidir el final de la cadena str_view(words,&quot;^y&quot;, match = TRUE) str_view(words,&quot;x$&quot;, match = TRUE) En caso de desear hacer coincidir todo el contenido de la cadena, deben usarse ambos caracteres especiales para definir el inicio y el final del patrón coincidente como se muestra a continuación. vector &lt;- c(&quot;nulo aprendizaje&quot;, &quot;poco aprendizaje&quot;,&quot;aprendizaje moderado&quot;,&quot;aprendizaje&quot;, &quot;aprendizaje total&quot;) str_view(vector,&quot;^aprendizaje$&quot;) Wickham menciona que, además del caracter especial punto “.”, existen otros cuatro que resultan muy útiles para mostrar patrones particulares. \\d Hace coincidir cualquier dígito. \\s Hace coincidir cualquier espacio en blanco (espacio, tabulador, salto de línea). [abc] Hace coincidir a, b ó c. [^abc] Coincide con cualquier cosa excepto a, b ó c. Al momento de definir cualquiera de estos 4 patrones coincidentes será necesario usar doble diagonal invertida. Por ejemplo, “\\\\d” será el patrón para encontrar la coincidencia con cualquier dígito. cadena &lt;- &quot;El año 2022 será un año de mucho crecimiento.&quot; str_view(cadena,&quot;\\\\d&quot;, match = T) Wickham menciona que, “es posible usar alternancias para elegir entre uno o más patrones alternativos. Por ejemplo, abc|d..f coincidirá con”abc” o con “deaf”. Haciendo notar que la prioridad para el operador “|” es baja, por lo que abc|xyz coincide con abc o xyz, no con abcyz o abxyz. Al igual que en las matemáticas, si existe ambigüedad en la prioridad de las operaciones, usar paréntesis lo hará todo más claro.” str_view(c(&quot;tamaño&quot;,&quot;tasa&quot;,&quot;tata&quot;,&quot;taza&quot;,&quot;tapa&quot;),&quot;ta(s|z)a&quot;) Repeticiones El siguiente paso en complejidad para las expresiones regulares es, controlar el número de veces que aparece un patrón coincidente. ?: Se repite 0 o 1. +: Se repite 1 o más veces. *: Se repite 0 a más veces. x &lt;- &quot;1888 es el año más largo en números romanos: MDCCCLXXXVIII&quot; str_view(x,&quot;XX?&quot;) str_view(x,&quot;XX+&quot;) str_view(x,&quot;C[LX]+&quot;) Es posible especificar el número de repeticiones que se desea hacer coincidir un patrón. Ya sea de manera exacta o dentro de un intervalo. Esta repetición en el patrón se define de la siguiente manera. {n}: exactamente n veces {n,}: n o más veces {,m}: a lo más m veces {n,m}: entre n y m veces str_view(x,&quot;X{3}&quot;) str_view(x,&quot;X{1,2}&quot;) Match múltiple / nulo Es interesante el siguiente ejemplo. ¿Qué es lo que sucede? str_view(x,&quot;M*&quot;) Recordemos que los operadores * o ? busca un patrón que puede o no encontrarse dentro de la cadena de interés. En el caso anterior, la letra “M” puede o no encontrarse en la cadena “x”. En el ejemplo anterior, en cada posible caracter existe el hallazgo o no hallazgo de la letra “M”, de forma que el primer match que hace se encuentra al principio de la cadena. Una limitante de la función str_view() es que únicamente resalta la primer coincidencia encontrada con el patrón regular, sin embargo, la función str_view_all() se encarga de resaltar todas las coincidencias en la cadena, como se muestra a continuación. str_view_all(x,&quot;M*&quot;) Herramientas Una vez que se han visto los aspectos básicos de las expresiones regulares, es posible utilizar los patrones coincidentes y combinarlos para aplicarlos en problemas reales. Algunas de las aplicaciones más comunes son: Determinar cuáles cadenas coinciden con un patrón. Encontrar la posición de las coincidencias. Extraer el contenido de las coincidencias. Reemplazar coincidencias con nuevos valores. Dividir una cadena basándose en una coincidencia. A continuación se analizarán las funciones que permitirán realizar las acciones anteriores. 3.4.6 Detectar coincidencias Para determinar las cadenas de caracteres dentro de un vector que coinciden con un patrón, es posible utilizar la función str_detect(). La función regresará un vector booleano una vez que se introduzcan como argumentos el vector con cadenas y el patrón con el que se desea hacer la coincidencia. Aplicando esta función a un marco de muestreo es posible apreciar si los elementos coinciden o no con algún patrón indicado. En el siguiente ejemplo se puede apreciar cuáles frutas tienen entre sus letras una “a” o una “u”. str_detect(fruit, &quot;[au]&quot;) ## [1] TRUE TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE FALSE TRUE ## [13] TRUE TRUE TRUE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE ## [25] TRUE TRUE TRUE TRUE FALSE TRUE FALSE FALSE FALSE TRUE TRUE TRUE ## [37] FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE FALSE TRUE ## [49] TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE ## [61] TRUE TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE FALSE ## [73] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE A continuación se puede apreciar una aplicación de la función str_detect(). Se usará el vector booleano para seleccionar el subconjunto del objeto fruit que tiene entre su nombre una letra “l” o una letra “o”. fruit[str_detect(fruit, &quot;[lo]&quot;)] ## [1] &quot;apple&quot; &quot;apricot&quot; &quot;avocado&quot; ## [4] &quot;bell pepper&quot; &quot;bilberry&quot; &quot;blackberry&quot; ## [7] &quot;blackcurrant&quot; &quot;blood orange&quot; &quot;blueberry&quot; ## [10] &quot;boysenberry&quot; &quot;canary melon&quot; &quot;cantaloupe&quot; ## [13] &quot;cherimoya&quot; &quot;chili pepper&quot; &quot;clementine&quot; ## [16] &quot;cloudberry&quot; &quot;coconut&quot; &quot;damson&quot; ## [19] &quot;dragonfruit&quot; &quot;eggplant&quot; &quot;elderberry&quot; ## [22] &quot;feijoa&quot; &quot;goji berry&quot; &quot;gooseberry&quot; ## [25] &quot;honeydew&quot; &quot;huckleberry&quot; &quot;jambul&quot; ## [28] &quot;lemon&quot; &quot;lime&quot; &quot;loquat&quot; ## [31] &quot;lychee&quot; &quot;mango&quot; &quot;mulberry&quot; ## [34] &quot;olive&quot; &quot;orange&quot; &quot;pamelo&quot; ## [37] &quot;passionfruit&quot; &quot;persimmon&quot; &quot;physalis&quot; ## [40] &quot;pineapple&quot; &quot;plum&quot; &quot;pomegranate&quot; ## [43] &quot;pomelo&quot; &quot;purple mangosteen&quot; &quot;rock melon&quot; ## [46] &quot;salal berry&quot; &quot;tamarillo&quot; &quot;ugli fruit&quot; ## [49] &quot;watermelon&quot; De esta manera se va filtrando un marco muestral para quedarse únicamente con los elementos que coincidan con un patrón coincidente. 3.4.7 Contabilizar coincidencias Una variación de la función anterior, es la función str_count(). Esta función en lugar de devolver un vector lógico, devuelve un vector de conteos que corresponde al número de veces que detectó una coincidencia para cada cadena dentro de un vector. La manera de usarse es análoga a la función str_detect(). str_count(fruit, &quot;[aeiou]&quot;) ## [1] 2 3 4 3 3 2 2 3 5 3 3 4 4 5 4 1 4 4 3 3 2 3 2 2 2 4 3 2 3 4 1 3 4 2 4 3 3 3 ## [39] 3 2 3 4 3 2 2 3 2 4 2 2 4 1 3 3 3 3 5 2 2 3 2 4 1 5 3 6 3 3 3 2 3 3 3 3 3 2 ## [77] 4 4 4 4 En el ejemplo anterior se puede apreciar el número de vocales que existen dentro de cada una de los nombres de las frutas. Una de las aplicaciones más comunes para esta función, se encuentra en los estudios de análisis de textos. A continuación, se puede apreciar el promedio de vocales que son usadas dentro de los nombres de frutas en el objeto fruit. mean(str_count(fruit, &quot;[aeiou]&quot;)) ## [1] 3.0125 Otro ejemplo más complejo de esta función y sus aplicaciones es el siguiente: tabla &lt;- tibble( &quot;Vocal&quot; = c(&quot;a&quot;,&quot;e&quot;,&quot;i&quot;,&quot;o&quot;,&quot;u&quot;), &quot;Conteos&quot; = c(sum(str_count(fruit, &quot;a&quot;)),sum(str_count(fruit, &quot;e&quot;)), sum(str_count(fruit, &quot;i&quot;)),sum(str_count(fruit, &quot;o&quot;)), sum(str_count(fruit, &quot;u&quot;)))) %&gt;% mutate(Porcentaje = Conteos/sum(Conteos)) tabla ## # A tibble: 5 × 3 ## Vocal Conteos Porcentaje ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 a 65 0.270 ## 2 e 72 0.299 ## 3 i 34 0.141 ## 4 o 36 0.149 ## 5 u 34 0.141 De esta manera es posible visualizar los conteos totales que tuvo cada vocal. Se calculó el porcentaje de aparición que tiene cada vocal con respecto al total de vocales en el conjunto. Un dato curioso que es posible concluir con este ejemplo, es que, las vocales “a” y “e” aparecen casi dos veces más que el resto de las vocales en el conjunto fruit. El anterior es un ejemplo sencillo que tiene por objetivo ilustrar el aprovechamiento de las funciones, sin embargo, una aplicación más robusta podría permitir que a través de los tweets emitidos a candidatos políticos, se realice un análisis de sentimientos, en el cual cada tweet sea asociado a uno o más sentimientos tales como: alegría, enojo, miedo, tristeza, aversión, etc. Posteriormente, de manera análoga a los conteos de vocales con porcentajes, se podría analizar la distribución de los sentimientos asociados a las opiniones de cada uno de los candidatos políticos. Adicionalmente, se podría realizar un análisis en donde se muestren las palabras que más se repiten al expresarse de un candidato. 3.4.8 Extraer coincidencias Cuando se desea identificar y extraer un subgrupo particular de elementos que cumplan con cierta condición definida a través de un patrón coincidente, la función str_extract() es la mejor opción para realizar esta tarea. Si se desea extraer el subconjunto de sentencias conjuntivas o disyuntivas es necesario definir el patrón coincidente con el cuál se compararán las sentencias para ser extraídas. patron &lt;- &quot;( and )|( or )&quot; Por su traducción en inglés, “and” y “or” son los conectores “y” y “o” respectivamente. Primero se filtrarán las oraciones que cumplen con la condición de que las conjunciones “and” u “or” se encuentren dentro y posteriormente se extraerán los elementos coincidentes. coincidencias &lt;- str_subset(sentences, patron) head(coincidencias,10) ## [1] &quot;The hogs were fed chopped corn and garbage.&quot; ## [2] &quot;Kick the ball straight and follow through.&quot; ## [3] &quot;Smoky fires lack flame and heat.&quot; ## [4] &quot;The fish twisted and turned on the bent hook.&quot; ## [5] &quot;Press the pants and sew a button on the vest.&quot; ## [6] &quot;The colt reared and threw the tall rider.&quot; ## [7] &quot;It snowed, rained, and hailed the same morning.&quot; ## [8] &quot;The wrist was badly strained and hung limp.&quot; ## [9] &quot;Hop over the fence and plunge in.&quot; ## [10] &quot;Cars and busses stalled in snow drifts.&quot; Apenas 123 sentencias cumplen con la condición. Éstas representan el 17.08% del total. Para extraer los elementos coincidentes, la función str_extract() se usa de la siguiente manera: str_extract(coincidencias, patron) ## [1] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [10] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [19] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [28] &quot; and &quot; &quot; or &quot; &quot; or &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [37] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; or &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [46] &quot; or &quot; &quot; and &quot; &quot; or &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [55] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [64] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [73] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [82] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; or &quot; &quot; and &quot; &quot; and &quot; &quot; or &quot; ## [91] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [100] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; or &quot; &quot; and &quot; &quot; and &quot; ## [109] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; ## [118] &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; &quot; and &quot; Con el código anterior se logra extraer el patrón coincidente de cada una de las sentencias, sin embargo, sólo se logra extraer la primer coincidencia de cada cadena en donde hubo al menos una coincidencia. Para extender este resultado a todos los patrones coincidentes dentro de la sentencia, se debe agregar el sufijo “_all” a la función. La función str_extract_all() extraerá todas las coincidencias y las agrupará en un objeto cuya estructura será la de una “lista”. Con la función head() se logrará visualizar los 5 primeros elementos de la lista que guarda el resultado generado por la función str_extract_all(). head(str_extract_all(coincidencias,patron), 5) ## [[1]] ## [1] &quot; and &quot; ## ## [[2]] ## [1] &quot; and &quot; ## ## [[3]] ## [1] &quot; and &quot; ## ## [[4]] ## [1] &quot; and &quot; ## ## [[5]] ## [1] &quot; and &quot; Un formato más compacto del resultado anterior se logra al agregar el parámetro “simplfy = TRUE” dentro de la función de extracción. Para visualizar aleatoriamente diez de los resultados generados, se puede hacer uso de la función sample_n() de la librería dplyr. dplyr::sample_n( tbl = as_tibble(str_extract_all(coincidencias, patron, simplify = TRUE)), size = 10 ) ## # A tibble: 10 × 2 ## V1 V2 ## &lt;chr&gt; &lt;chr&gt; ## 1 &quot; and &quot; &quot;&quot; ## 2 &quot; and &quot; &quot;&quot; ## 3 &quot; and &quot; &quot;&quot; ## 4 &quot; or &quot; &quot;&quot; ## 5 &quot; and &quot; &quot;&quot; ## 6 &quot; and &quot; &quot;&quot; ## 7 &quot; or &quot; &quot;&quot; ## 8 &quot; and &quot; &quot;&quot; ## 9 &quot; and &quot; &quot;&quot; ## 10 &quot; and &quot; &quot;&quot; Si en alguna cadena existieran más de dos patrones coincidentes, aparecería en la segunda columna el patrón encontrado (e.g., elemento en el séptimo renglón), de lo contrario, el elemento de la segunda columna permanecerá vacío a través de dos comillas. El resultado será un objeto de la clase data.frame que tendrá tantas columnas como coincidencias máximas hayan existido en una sentencia. La siguientes línea de código permite hacer conteos del número de veces que el patrón coincidente fue detectado en el vector de oraciones. La función str_count() indicará el número de veces que el patrón fue detectado en cada oración. Finalmente, el vector numérico se suma. sum(str_count(coincidencias, pattern = patron)) ## [1] 126 Con este dato, se puede decir que a lo largo de 123 oraciones, se puede encontrar 126 veces el patrón indicado. Este tipo de análisis nos permite hacer reportes como el siguiente: En promedio, cada oración tiene incluido 1.02 veces el patrón coincidente. A continuación, se revisará el modo de detectar y reemplazar patrones regulares. 3.4.9 Reemplazar coincidencias A menudo es necesario reemplazar algunos patrones. Ya sea derivado de un error en las cadenas de texto o por interés de presentar los resultados de una manera distinta, identificar y sustituir un subconjunto de caracteres es algo que la función str_replace() de la paquetería stringr puede hacer. Como todas las funciones vistas hasta el momento provenientes de la paquetería stringr, la función str_replace() recibe el objeto con las cadenas de caracteres originales y a través de un patrón de texto se hace la búsqueda de las coincidencias. Es posible incluir más de 1 patrón y asignar el nuevo texto que sustituirá al anterior para cada uno de los patrones definidos. La función str_replace() hará la sustitución de un solo patrón coincidente y la función str_replace_all() lo hará para todos los patrones definidos. # Ejemplos de cambio de códigos a palabras o invertido x &lt;- c(&quot;1&quot;,&quot;2&quot;,&quot;1&quot;,&quot;2&quot;,&quot;1&quot;,&quot;2&quot;,&quot;1&quot;,&quot;2&quot;,&quot;1&quot;,&quot;2&quot;) x1 &lt;- str_replace(x, &quot;1&quot;,&quot;Hombre&quot;) print(x1) ## [1] &quot;Hombre&quot; &quot;2&quot; &quot;Hombre&quot; &quot;2&quot; &quot;Hombre&quot; &quot;2&quot; &quot;Hombre&quot; &quot;2&quot; ## [9] &quot;Hombre&quot; &quot;2&quot; x2 &lt;- str_replace(x1, &quot;2&quot;,&quot;Mujer&quot;) print(x2) ## [1] &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; ## [9] &quot;Hombre&quot; &quot;Mujer&quot; # Es posible replicar el resultado en un solo paso mediante str_replace_all str_replace_all(x, c(&quot;1&quot; = &quot;Hombre&quot;, &quot;2&quot; = &quot;Mujer&quot;)) ## [1] &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; &quot;Hombre&quot; &quot;Mujer&quot; ## [9] &quot;Hombre&quot; &quot;Mujer&quot; 3.4.10 Divisiones mediante patrones La información se presenta en diferentes formatos todo el tiempo. A veces cada variable tiene su propia columna, pero a veces la información está mezclada y es necesario dividirla a fin de trabajar mejor con ella. Un caso recurrente en donde se presenta esta operación es con las fechas. El formato de una fecha a menudo se presenta como dd/mm/aaaa. Bajo este formato se puede encontrar tres datos en uno solo (día, mes y año). Para dividirlo, se podría utilizar el caracter “/” como patrón de coincidencia que permita dividir los datos en tres columnas separadas. Se debe agregar el parámetro “simplify = T” para poder simplificar los resultados y visualizarlos en un objeto data.frame(). La manera de hacerlo es la siguiente: Primero se genera un vector con fechas fechas &lt;- c(&quot;15/11/1991&quot;,&quot;20/11/1981&quot;,&quot;04/02/1966&quot;,&quot;01/10/1958&quot;,&quot;23/04/1992&quot;);fechas ## [1] &quot;15/11/1991&quot; &quot;20/11/1981&quot; &quot;04/02/1966&quot; &quot;01/10/1958&quot; &quot;23/04/1992&quot; Ahora, se generan tres columnas, una para el campo “Día”, otra para el campo “Mes” y otra para “Año” str_split(string = fechas,pattern = &quot;/&quot;,n = 3, simplify = T) %&gt;% as_tibble() %&gt;% rename(day = V1, month = V2, year = V3) ## # A tibble: 5 × 3 ## day month year ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 15 11 1991 ## 2 20 11 1981 ## 3 04 02 1966 ## 4 01 10 1958 ## 5 23 04 1992 3.4.11 Localización de coincidencias Para poder hacer operaciones con algunas cadenas de caracteres, en ocasiones es necesario proporcionar los índices que denotan el inicio y el término de algún patrón de caracteres. La función str_locate() devuelve dichos índices una vez que se le haya proporcionado como argumento el patrón coincidente y el vector de cadenas de texto. x &lt;- c(&quot;090020001-123&quot;,&quot;090001-512&quot;,&quot;09002-1236&quot;,&quot;90020001-1237&quot;,&quot;09001-123811&quot;) str_locate(x,&quot;-\\\\d{2,}&quot;) ## start end ## [1,] 10 13 ## [2,] 7 10 ## [3,] 6 10 ## [4,] 9 13 ## [5,] 6 12 El ejemplo anterior muestra la manera en la que se localizan los índices iniciales y finales de los caracteres posteriores al símbolo “-”, que cumplan con tener al menos 2 dígitos. Hay que tomar en cuenta que bajo esta forma de extraer los índices, la posición del caracter “-” está incluida y es ahí donde inicia el conteo. Habiendo platicado de esto, podemos hablar de uno de los temas importantes en muchas ocasiones complejos de la manipulación de datos… las fechas. 3.5 Manipulación de tiempo 3.5.1 Lectura y creación de datos temporales Una de la tareas más comunes en el análisis de datos es la manipulación de fechas y horas. Existe una infinidad de situaciones en donde saber operar con esta clase de datos es vital para el análisis de datos general. El primer paso es lograr identificar una cadena de caracteres como un dato temporal. Veamos un primer ejemplo: library(lubridate) fechas &lt;- c(&quot;2018/09/11&quot;, &quot;1992/04/23&quot;, &quot;1966/02/04&quot;, &quot;1958/10/01&quot;, &quot;1991/11/15&quot;) class(fechas) ## [1] &quot;character&quot; class(as_date(fechas)) ## [1] &quot;Date&quot; Como puede apreciarse, los elementos del vector ahora son de la clase “Date”. La función as_date() transforma caracteres a fechas. Otra forma de realizar la implementación de datos temporales es directamente la creación de datos temporales a través de las funciones make_date() y make_datetime(). Esta función recibe los parámetros de cada unidad temporal y crea el dato adecuado para representarlo, ya sea date o datetime. make_date(year = 1999, month = 06, day = 16) ## [1] &quot;1999-06-16&quot; make_datetime(year = 1999:2001, month = 06, day = 16, hour = 10:12, min = 37, sec = 15) ## [1] &quot;1999-06-16 10:37:15 UTC&quot; &quot;2000-06-16 11:37:15 UTC&quot; ## [3] &quot;2001-06-16 12:37:15 UTC&quot; El segundo ejemplo muestra la capacidad de estas funciones para crear una secuencia de fechas a partir de vectores de cada posible unidad temporal (día, mes año, hora, etc) Algo que puede apreciarse en los ejemplos anteriores y que es necesario mencionar, es que el formato universal de fecha se escribe: yyyy/mm/dd. En países como USA el formato es mm/dd/yyyy y en México y otras partes del mundo puede escribirse comúnmente dd/mm/yyyy. Este tipo de diferencia a veces puede llegar a generar confusión sobre la fecha exacta en cuestión, más aún si se abrevia el año a dos caracteres yy. La librería lubridate ofrece funciones para lidiar con el formato de lectura. Estas funciones son: dmy / dmy_h / dmy_hm / dmy_hms mdy / mdy_h / mdy_hm / mdy_hms ymd / ymd_h / ymd_hm / ymd_hms hm / hms Con todas las funciones mencionadas anteriormente se puede leer cualquier cadena de caracteres que contenga el formato especificado. A continuación, un ejemplo: mdy(&quot;11/25/1982&quot;) ## [1] &quot;1982-11-25&quot; Automáticamente cualquiera de las funciones antes mencionadas transforma el formato específico al formato universal. 3.5.2 Extracción de datos temporales Una vez que los datos temporales ya se encuentran creados, es importante saber la manera de extraer información particular de nuestro interés. En esta sección se revisará la manera de extraer cualquier unidad temporal a partir de una cadena completa de caracteres. a través de lubridate, las funciones para extracción de sub-unidades temporales son intuitivas. tiempo &lt;- make_datetime(year = 2004, month = 9, day = 25, hour = 11, min = 30, sec = 1) year(tiempo) ## [1] 2004 month(tiempo) ## [1] 9 month(tiempo, label = T, abbr = F) ## [1] septiembre ## 12 Levels: enero &lt; febrero &lt; marzo &lt; abril &lt; mayo &lt; junio &lt; ... &lt; diciembre day(tiempo) ## [1] 25 hour(tiempo) ## [1] 11 minute(tiempo) ## [1] 30 second(tiempo) ## [1] 1 Después de las unidades temporales básicas, es posible también extraer día de la semana o día del mes, si es de interés. wday(tiempo) ## [1] 7 wday(tiempo, label = T, abbr = F) ## [1] sábado ## 7 Levels: domingo &lt; lunes &lt; martes &lt; miércoles &lt; jueves &lt; ... &lt; sábado mday(tiempo) ## [1] 25 yday(tiempo) ## [1] 269 3.5.3 Operaciones temporales Las operaciones aritméticas entre datos temporales es cotidiano en todo momento cuando se analizan datos. Operaciones de sumas y restas de fechas y horas que permiten conocer la longitud de tiempo en dos momentos es una tarea que puede resolverse a través de los operadores aritméticos y lógicos. Resta entre fechas as_date(&quot;1991/11/15&quot;) - as_date(&quot;1992/04/23&quot;) ## Time difference of -160 days as_date(&quot;1992/04/23&quot;) - as_date(&quot;1991/11/15&quot;) ## Time difference of 160 days Suma y resta de días as_date(&quot;1991/11/15&quot;) + 365 ## [1] &quot;1992-11-14&quot; Operadores lógicos as_date(&quot;1992/04/23&quot;) &gt; as_date(&quot;1991/11/15&quot;) ## [1] TRUE as_date(&quot;1992/04/23&quot;) &lt; as_date(&quot;1991/11/15&quot;) ## [1] FALSE Cada una de las operaciones vistas en este capítulo son compatibles con dplyr y el resto de las librerías tidyverse. 3.6 Iteraciones Los procesos en R muchas veces son iterativos en distintas partes del desarrollo de una solución. Existe una librería que facilita el entendimiento, orden, legibilidad y limpieza a la orden de iterar. La librería lleva por nombre purrr. Purrr presenta funciones de mapeo, así como algunas funciones nuevas para manipular listas. Mientras que el caballo de batalla de dplyr es el marco de datos (data.frame / tibble), el caballo de batalla de purrr es la lista. Recordemos que un vector es una forma de almacenar muchos elementos individuales (un solo número o un solo carácter o cadena) del mismo tipo en un solo objeto. Un marco de datos (data.frame / tibble) es una forma de almacenar muchos vectores de la misma longitud pero posiblemente de diferentes tipos juntos en un solo objeto. Una lista es una forma de almacenar muchos objetos de cualquier tipo (por ejemplo, marcos de datos, diagramas, vectores) juntos en un solo objeto. Aquí hay un ejemplo de una lista que tiene tres elementos: un solo número, un vector y un marco de datos mi_2da_lista &lt;- list( my_number = 5, my_vector = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), my_dataframe = data.frame( a = 1:3, b = c(&quot;q&quot;, &quot;b&quot;, &quot;z&quot;), c = c(&quot;bananas&quot;, &quot;are&quot;, &quot;so very great&quot;)) ) mi_2da_lista ## $my_number ## [1] 5 ## ## $my_vector ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; ## ## $my_dataframe ## a b c ## 1 1 q bananas ## 2 2 b are ## 3 3 z so very great Un marco de datos es en realidad un caso especial de una lista donde cada elemento de la lista es un vector de la misma longitud. Una función de mapeo es aquella que aplica la misma acción/función a cada elemento de un objeto (por ejemplo, cada entrada de una lista o un vector, o cada una de las columnas de un marco de datos). ¡¡ RECORDAR !! La funciones que serán revisadas son súper útiles para realizar una acción de forma iterativa en las entradas de un vector o lista sin tener que escribir un bucle for. La convención de nomenclatura de las funciones de mapeo es tal que el tipo de salida se especifica mediante el término que sigue al guión bajo en el nombre de la función. map(.x, .f) Es la función principal y regresa una lista map_df(.x, .f) regresa un data frame map_dbl(.x, .f) regresa un vector numérico (double) map_chr(.x, .f) regresa un vector de caracter map_lgl(.x, .f) regresa un vector lógico De acuerdo con la forma del tidyverse, el primer argumento de cada función de mapeo es siempre el objeto de datos sobre el que desea mapear, y el segundo argumento es siempre la función que desea aplicar iterativamente a cada elemento del objeto de entrada. 3.6.1 Bucles Fundamentalmente, los mapeos son para iteraciones. En el ejemplo de abajo, se iterará sobre el vector 1, 4, 7 añadiendo el valor 10 a cada entrada del vector a través de una función llamada addTen(). Esta función será aplicada a cada número único, el cual llamaremos “.x”. addTen &lt;- function(.x) { return(.x + 10) } La función map() de abajo, itera sobre todos los enteros aplicando la función addTen() a los elementos del vector y regresa la salida como una lista. library(purrr) map( .x = c(1, 4, 7), .f = addTen ) ## [[1]] ## [1] 11 ## ## [[2]] ## [1] 14 ## ## [[3]] ## [1] 17 Hay que notar en los siguientes ejemplos que el mecanismo es funcional independientemente de si se trata de una lista o un marco de datos: map(list(1, 4, 7), addTen) ## [[1]] ## [1] 11 ## ## [[2]] ## [1] 14 ## ## [[3]] ## [1] 17 map(data.frame(a = 1, b = 4, c = 7), addTen) ## $a ## [1] 11 ## ## $b ## [1] 14 ## ## $c ## [1] 17 la estructura resultante por default es una lista, no obstante, es posible especificar el tipo de salida deseado. Por ejemplo, para mapear el resultado de una iteración en un vector ‘double’, puede implementarse la función map_dbl(), la cual mapea a un vector double: map_dbl(c(1, 4, 7), addTen) ## [1] 11 14 17 Para mapear a un vector de clase ‘caracter’, puede implementarse la función map_chr(): map_chr(c(1, 4, 7), addTen) ## [1] &quot;11.000000&quot; &quot;14.000000&quot; &quot;17.000000&quot; Incluso puede realizarse este mismo proceso iterativo en búsqueda de obtener como resultado un data frame: map_df(c(1, 4, 7), function(.x) { return(data.frame(old_number = .x, new_number = addTen(.x))) }) ## old_number new_number ## 1 1 11 ## 2 4 14 ## 3 7 17 3.6.2 Bucles dobles En caso de haber dominado el uso del bucle mediante la función map(), es posible proceder a intentar iterar sobre dos objetos. El código de abajo una las funciones de mapeo para crear una lista de gráficos para comparar la esperanza de vida y el ingreso per cápita en cada combinación de continente y país. La función de mapeo que itera sobre dos objetos en vez de uno, es llamada map2(). Los primeros dos argumentos son los dos objetos sobre los cuales se realiza la iteración y el tercero es la función con 2 argumentos (uno por cada objeto). x &lt;- list(1, 5, 15) y &lt;- list(10, 20, 30) map2(x, y, ~ .x + .y) ## [[1]] ## [1] 11 ## ## [[2]] ## [1] 25 ## ## [[3]] ## [1] 45 map2_dbl(x, y, ~ .x + .y) ## [1] 11 25 45 map2_chr(x, y, ~ .x + .y) ## [1] &quot;11.000000&quot; &quot;25.000000&quot; &quot;45.000000&quot; Otro ejemplo: df &lt;- data.frame( x = c(1, 2, 5), y = c(5, 4, 8) ) df ## x y ## 1 1 5 ## 2 2 4 ## 3 5 8 map2_dbl(df$x, df$y, min) ## [1] 1 2 5 "],["visualización.html", "Capítulo 4 Visualización 4.1 EDA: Análisis Exploratorio de Datos 4.2 GEDA: Análisis Exploratorio de Datos Gráficos 4.3 Creación de gráficos 4.4 Análisis univariado 4.5 Análisis multivariado 4.6 Visualización interactiva", " Capítulo 4 Visualización “El análisis exploratorio de datos se refiere al proceso de realizar investigaciones iniciales sobre los datos para descubrir patrones, detectar anomalías, probar hipótesis y verificar suposiciones con la ayuda de estadísticas resumidas y representaciones gráficas.” Towards 4.1 EDA: Análisis Exploratorio de Datos Un análisis exploratorio de datos tiene principalmente 5 objetivos: Maximizar el conocimiento de un conjunto de datos Descubrir la estructura subyacente de los datos Extraer variables importantes Detectar valores atípicos y anomalías Probar los supuestos subyacentes EDA no es idéntico a los gráficos estadísticos aunque los dos términos se utilizan casi indistintamente. Los gráficos estadísticos son una colección de técnicas, todas basadas en gráficos y todas centradas en un aspecto de caracterización de datos. EDA abarca un lugar más grande. EDA es una filosofía sobre cómo diseccionar un conjunto de datos; lo que buscamos; cómo nos vemos; y cómo interpretamos. Los científicos de datos pueden utilizar el análisis exploratorio para garantizar que los resultados que producen sean válidos y aplicables a los resultados y objetivos comerciales deseados. EDA se utiliza principalmente para ver qué datos pueden revelar más allá del modelado formal o la tarea de prueba de hipótesis y proporciona una mejor comprensión de las variables del conjunto de datos y las relaciones entre ellas. También puede ayudar a determinar si las técnicas estadísticas que está considerando para el análisis de datos son apropiadas. Dependiendo del tipo de variable queremos obtener la siguiente información: Variables numéricas: Tipo de dato: float, integer Número de observaciones Mean Desviación estándar Cuartiles: 25%, 50%, 75% Valor máximo Valor mínimo Número de observaciones únicos Top 5 observaciones repetidas Número de observaciones con valores faltantes ¿Hay redondeos? Variables categóricas Número de categorías Valor de las categorías Moda Valores faltantes Número de observaciones con valores faltantes Proporción de observaciones por categoría Top 1, top 2, top 3 (moda 1, moda 2, moda 3) Faltas de ortografía ? Fechas Fecha inicio Fecha fin Huecos en las fechas: sólo tenemos datos entre semana, etc. Formatos de fecha (YYYY-MM-DD) Tipo de dato: date, time, timestamp Número de faltantes (NA) Número de observaciones Texto Longitud promedio de cada observación Identificar el lenguaje, si es posible Longitud mínima de cada observación Longitud máxima de cada observación Cuartiles de longitud: 25%, 50%, 75% Coordenadas geoespaciales Primero se pone la latitud y luego la longitud Primer decimal: 111 kms Segundo decimal: 11.1 kms Tercer decimal: 1.1 kms Cuarto decimal: 11 mts Quinto decimal: 1.1 mt Sexto decimal: 0.11 mts Valores que están cercanos al 100 representan la longitud El símbolo en cada coordenada representa si estamos al norte (positivo) o sur (negativo) -en la latitud-, al este (positivo) o al - oeste (negativo) -en la longitud-. 4.2 GEDA: Análisis Exploratorio de Datos Gráficos Como complemento al EDA podemos realizar un GEDA, que es un análisis exploratorio de los datos apoyándonos de visualizaciones, la visualización de datos no trata de hacer gráficas “bonitas” o “divertidas”, ni de simplificar lo complejo. Más bien, trata de aprovechar nuestra gran capacidad de procesamiento visual para exhibir de manera clara aspectos importantes de los datos. 4.2.1 Gráficos univariados: Histograma: El histograma es la forma más popular de mostrar la forma de un conjunto de datos. Se divide la escala de la variable en intervalos, y se realiza un conteo de los casos que caen en cada uno de los intervalos. Los histogramas pueden mostrar distintos aspectos de los datos dependiendo del tamaño y posición de los intervalos. Diagramas de caja y brazos: Es un método estandarizado para representar gráficamente una serie de datos numéricos a través de sus cuartiles. El diagrama de caja muestra a simple vista la mediana y los cuartiles de los datos, pudiendo también representar los valores atípicos de estos. Gráficas de barras: Una gráfica de este tipo nos muestra la frecuencia con la que se han observado los datos de una variable discreta, con una barra para cada categoría de esta variable. Gráficos Circulares (Pie Charts): Un gráfico circular o gráfica circular, también llamado “gráfico de pastel”, es un recurso estadístico que se utiliza para representar porcentajes y proporciones. 4.2.2 Gráficos multivariados Gráfico de dispersión: Los gráficos de dispersión se usan para trazar puntos de datos en un eje vertical y uno horizontal, mediante lo que se trata de mostrar cuánto afecta una variable a otra. Si no existe una variable dependiente, cualquier variable se puede representar en cada eje y el diagrama de dispersión mostrará el grado de correlación (no causalidad) entre las dos variables. Gráficas de líneas: Uno de los tipos de gráfica más utilizados es la de líneas, especialmente cuando se quieren comparar visualmente varias variables a lo largo del tiempo o algún otro parámetro. 4.3 Creación de gráficos Comparando con los gráficos base de R, ggplot2: Tiene una gramática más compleja para gráficos simples Tiene una gramática menos compleja para gráficos complejos o muy personalizados. Los datos siempre deben ser un data.frame. Usa un sistema diferente para añadir elementos al gráfico. Histograma con los gráficos base: Histograma con ggplot2: Ahora vamos a ver un gráfico con colores y varias series de datos. Con los gráficos base: Con ggplot2: 4.3.1 Estéticas En ggplot2, aestetics significa “algo que puedes ver”. Algunos ejemplos son: Posición (por ejemplo, los ejes x e y) Color (color “externo”) Fill (color de relleno) Shape (forma de puntos) Linetype (tipo de linea) Size (tamaño) Alpha (para la transparencia: los valores más altos tendrían formas opacas y los más bajos, casi transparentes). Hay que advertir que no todas las estéticas tienen la misma potencia en un gráfico. El ojo humano percibe fácilmente longitudes distintas. Pero tiene problemas para comparar áreas (que es lo que regula la estética size) o intensidades de color. Se recomienda usar las estéticas más potentes para representar las variables más importantes. Cada tipo de objeto geométrico (geom) solo acepta un subconjunto de todos los aestéticos. Puedes consultar la pagina de ayuda de geom() para ver que aestéticos acepta. El mapeo aestético se hace con la función aes(). 4.3.2 Objetos geométricos o capas Los objetos geométricos son las formas que puede tomar un gráfico. Algunos ejemplos son: Barras (geom_bar(), para las variables univariados discretos o nominales) Histogramas (geom_hist() para aquellas variables univariadas continuas) Puntos (geom_point() para scatter plots, gráficos de puntos, etc…) Lineas (geom_line() para series temporales, lineas de tendencia, etc…) Cajas (geom_boxplot() para gráficos de cajas) Un gráfico debe tener al menos un geom, pero no hay limite. Puedes añadir más geom usando el signo +. Una vez añadida una capa al gráfico a este pueden agregarse nuevas capas 4.3.3 Facetas Muchos de los gráficos que pueden generarse con los elementos anteriores pueden reproducirse usando los gráficos tradicionales de R, pero no los que usan facetas, que pueden permitirnos explorar las variables de diferente forma, por ejemplo: crea tres gráficos dispuestos horizontalmente que comparan la relación entre la anchura y la longitud del pétalo de las tres especies de iris. Una característica de estos gráficos, que es crítica para poder hacer comparaciones adecuadas, es que comparten ejes. 4.3.4 Más sobre estéticas Para los ejercicios en clase utilizaremos el set de datos: Diamonds: library(dplyr) library(ggplot2) library(reshape2) data(&quot;diamonds&quot;) Descripción Un conjunto de datos que contiene los precios y otros atributos de casi 54.000 diamantes. Las variables son las siguientes: price: precio en dólares estadounidenses ( $ 326 -  $ 18,823) carat: peso del diamante (0.2–5.01) cut: calidad del corte (Regular, Bueno, Muy Bueno, Premium, Ideal) color: color del diamante, de D (mejor) a J (peor) clarity: una medida de la claridad del diamante (I1 (peor), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (mejor)) x: longitud en mm (0-10,74) y: ancho en mm (0–58,9) width in mm (0–58.9) -z: profundidad en mm (0–31,8) depth porcentaje de profundidad total = z / media (x, y) = 2 * z / (x + y) (43–79) table: ancho de la parte superior del diamante en relación con el punto más ancho (43–95) Ejemplo práctico: diamonds %>% ggplot() + aes(x = cut_number(carat, 5), y = price) + geom_boxplot() + aes(color = cut) + labs(title = 'Distribución de precio por categoría de corte') + labs(caption = 'Data source:Diamont set') + labs(x = 'Peso del diamante') + labs(y = 'Precio') + guides(color = guide_legend(title = 'Calidad del corte')) + ylim(0, 20000) + scale_y_continuous( labels = scales::dollar_format(), breaks = seq(0, 20000,2500 ), limits = c(0, 20000) ) 4.3.5 Quick View library(DataExplorer) plot_intro(diamonds) plot_missing(diamonds) 4.4 Análisis univariado El análisis univariado tiene como objetivo conocer la calidad y distribución de los datos. Se busca conocer medidas de tendencia central, variación promedio, cantidad de valores perdidos, etc. Es vital conocer los datos y su calidad antes de usarlos. 4.4.1 Variables numéricas Los histogramas son gráficas de barras que se obtienen a partir de tablas de frecuencias, donde cada barra se escala según la frecuencia relativa entre el ancho del intervalo de clase correspondiente. Un histograma muestra la acumulación ó tendencia, la variabilidad o dispersión y la forma de la distribución. El Diagrama de Caja y bigotes un tipo de gráfico que muestra un resumen de una gran cantidad de datos en cinco medidas descriptivas, además de intuir su morfología y simetría. Este tipo de gráficos nos permite identificar valores atípicos y comparar distribuciones. Además de conocer de una forma cómoda y rápida como el 50% de los valores centrales se distribuyen. Se puede detectar rápidamente los siguientes valores: Primer cuartil: el 25% de los valores son menores o igual a este valor (punto 2 en el gráfico anterior). Mediana o Segundo Cuartil: Divide en dos partes iguales la distribución. De forma que el 50% de los valores son menores o igual a este valor (punto 3 en el gráfico siguiente). Tercer cuartil: el 75% de los valores son menores o igual a este valor (punto 4 en el gráfico siguiente). Rango Intercuartílico (RIC): Diferencia entre el valor del tercer cuartil y el primer cuartil. Tip: El segmento que divide la caja en dos partes es la mediana (punto 3 del gráfico), que facilitará la comprensión de si la distribución es simétrica o asimétrica, si la mediana se sitúa en el centro de la caja entonces la distribución es simétrica y tanto la media, mediana y moda coinciden. Precio diamonds %&gt;% ggplot( aes( x = price)) + geom_histogram( aes(y = ..density..), color= &quot;Blue&quot;, fill= &quot;White&quot;, bins = 30 ) + stat_density(geom = &quot;line&quot;, colour = &quot;black&quot;, size = 1)+ scale_x_continuous(labels = scales::dollar_format()) + scale_y_continuous(labels = scales::comma_format()) + stat_density(geom = &quot;line&quot;, colour = &quot;black&quot;, size = 1) + ggtitle(&quot;Distribución de precio&quot;) diamonds %&gt;% ggplot( aes( x = price)) + geom_boxplot(binwidth = 1000, color= &quot;Blue&quot;, fill= &quot;lightblue&quot;) + scale_x_continuous(labels = scales::dollar_format()) + scale_y_continuous(labels = scales::comma_format()) + ggtitle(&quot;Distribución de precio&quot;) Peso del diamante diamonds %&gt;% ggplot( aes( x = carat)) + geom_histogram(binwidth = .03, color= &quot;purple&quot;, fill= &quot;pink&quot;, alpha= 0.3) + scale_y_continuous(labels = scales::comma_format()) + ggtitle(&quot;Distribución de peso de los diamantes&quot;) + theme_bw() diamonds %&gt;% ggplot( aes( x = carat)) + geom_boxplot(binwidth = .3, color= &quot;purple&quot;, fill= &quot;pink&quot;, alpha= 0.3) + scale_x_continuous(labels = scales::comma_format()) + ggtitle(&quot;Distribución de peso de los diamantes&quot;) + theme_bw() 4.4.2 Variables nominales/categóricas Calidad de corte diamonds %&gt;% ggplot( aes( x = cut)) + geom_bar( color= &quot;darkblue&quot;, fill= &quot;cyan&quot;, alpha= 0.7) + scale_y_continuous(labels = scales::comma_format()) + ggtitle(&quot;Distribución de cálidad de corte&quot;) + theme_dark() df_pie &lt;- diamonds %&gt;% group_by(cut) %&gt;% summarise(freq = n(), .groups=&#39;drop&#39;) df_pie %&gt;% ggplot( aes( x = &quot;&quot;, y=freq, fill = factor(cut))) + geom_bar(width = 1, stat = &quot;identity&quot;) + coord_polar(theta = &quot;y&quot;, start=0) ggplot(data = diamonds)+ geom_bar( mapping = aes(x = cut, fill = cut), show.legend = F, width = 1)+ theme(aspect.ratio = 1)+ labs(x= NULL, y = NULL)+ coord_polar() Claridad diamonds %&gt;% ggplot( aes( y = clarity)) + geom_bar( color= &quot;darkblue&quot;, fill= &quot;black&quot;, alpha= 0.7) + geom_text(aes(label = ..count..), stat = &quot;count&quot;, vjust = 1, hjust = 1.5,colour = &quot;blue&quot;)+ scale_x_continuous(labels = scales::comma_format()) + ggtitle(&quot;Distribución claridad&quot;) + theme_get() 4.5 Análisis multivariado Un buen análisis de datos, requiere del análisis conjunto de variables. Una sola variable es importante de analizar en cuanto a su distribución y calidad, no obstante, no dice mucho al analizarse por sí sola. Es por ello, que es indispensable analizar la covariabilidad y dependencia entre los distintos atributos de la información. En el análisis multivariado, se busca comparar la información haciendo contrastes de colores, formas, tamaños, páneles, etc. Precio vs Calidad del corte diamonds %&gt;% ggplot(aes(y= price,x=cut,color=cut)) + geom_jitter(size=1.2, alpha= 0.5) diamonds %&gt;% ggplot(aes(y= price,x=cut,color=cut)) + geom_boxplot(size=1.2, alpha= 0.5) diamonds %&gt;% ggplot(aes(x= price ,fill=cut)) + geom_histogram(position = &#39;identity&#39;, alpha = 0.5) diamonds %&gt;% ggplot(aes(x= price ,fill=cut)) + geom_histogram(position = &#39;identity&#39;, alpha = 0.5) + facet_wrap(~cut, ncol = 1) diamonds %&gt;% ggplot( aes(x = carat ,y=price)) + geom_point(aes(col = clarity) ) + geom_smooth() diamonds %&gt;% ggplot( aes(x = carat ,y=price)) + geom_point(aes(col = clarity) ) + facet_wrap(~clarity)+ geom_smooth() 4.6 Visualización interactiva A través de la librería plotly es posible crear interactividad entre las gráficas creadas con gglot2. Es posible tanto usar las funciones existentes como crear funciones que enriquezcan las estéticas comunes. A continuación se hace uso de una combinación de nuevas estéticas con la interactividad añadida. library(stringr) fun_mean &lt;- function(x){ mean &lt;- data.frame( y = mean(x), label = mean(x, na.rm = T) ) return(mean) } means &lt;- diamonds %&gt;% group_by(clarity) %&gt;% summarise(price = round(mean(price), 1)) plot &lt;- diamonds %&gt;% ggplot(aes(x = clarity, y = price)) + geom_boxplot(aes(fill = clarity)) + stat_summary( fun = mean, geom = &quot;point&quot;, colour = &quot;darkred&quot;, shape = 18, size = 2 ) + geom_text( data = means, aes(label = str_c(&quot;$&quot;,price), y = price + 600) ) + ggtitle(&quot;Precio vs Claridad de diamantes&quot;) + xlab(&quot;Claridad&quot;) + ylab(&quot;Precio&quot;) plotly::ggplotly(plot) Como puede apreciarse, este nuevo gráfico permite hacer uso de zoom, filtros, etiquetas, snapshots, etc. El contenido es creado como HTML, por lo que puede integrarse a documentos web como bookdown, shiny, xaringan, markdown, etc. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
