<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 9 Árboles de decisión | Ciencia de Datos y Machine Learning</title>
  <meta name="description" content="Capítulo 9 Árboles de decisión | Ciencia de Datos y Machine Learning" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 9 Árboles de decisión | Ciencia de Datos y Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Capítulo 9 Árboles de decisión | Ciencia de Datos y Machine Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 9 Árboles de decisión | Ciencia de Datos y Machine Learning" />
  
  <meta name="twitter:description" content="Capítulo 9 Árboles de decisión | Ciencia de Datos y Machine Learning" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="k-nearest-neighbor.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.1/str_view.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/aserta-logo.png" width="280"></a></li|
|:-:|  
<center>Ciencia de Datos y Machine Learning</center>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BIENVENIDA</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alcances-del-curso"><i class="fa fa-check"></i>Alcances del curso</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructores"><i class="fa fa-check"></i>Instructores</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#temario"><i class="fa fa-check"></i>Temario</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-1-introducción-a-r-22-hrs"><i class="fa fa-check"></i>Módulo 1: Introducción a R (22 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-2-introducción-a-ciencia-de-datos-18-hrs"><i class="fa fa-check"></i>Módulo 2: Introducción a Ciencia de Datos (18 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-3-machine-learning-supervisado-38-hrs"><i class="fa fa-check"></i>Módulo 3: Machine Learning: Supervisado (38 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-4-machine-learning-no-supervisado-12-hrs"><i class="fa fa-check"></i>Módulo 4: Machine Learning: No Supervisado (12 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#requisitos"><i class="fa fa-check"></i>Requisitos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#duración-y-evaluación-del-curso"><i class="fa fa-check"></i>Duración y evaluación del curso</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recursos-y-dinámica-de-clase"><i class="fa fa-check"></i>Recursos y dinámica de clase</a></li>
</ul></li>
<li class="part"><span><b>Parte 1: Introducción</b></span></li>
<li class="chapter" data-level="1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html"><i class="fa fa-check"></i><b>1</b> Conceptos de Ciencia de Datos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#qué-es-ciencia-de-datos"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es Ciencia de Datos?</a>
<ul>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#definiendo-conceptos"><i class="fa fa-check"></i>Definiendo conceptos:</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#objetivos"><i class="fa fa-check"></i><b>1.2</b> Objetivos</a></li>
<li class="chapter" data-level="1.3" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#requisitos-1"><i class="fa fa-check"></i><b>1.3</b> Requisitos</a></li>
<li class="chapter" data-level="1.4" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aplicaciones"><i class="fa fa-check"></i><b>1.4</b> Aplicaciones</a></li>
<li class="chapter" data-level="1.5" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#tipos-de-algoritmos"><i class="fa fa-check"></i><b>1.5</b> Tipos de algoritmos</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aprendizaje-supervisado"><i class="fa fa-check"></i><b>1.5.1</b> Aprendizaje supervisado</a></li>
<li class="chapter" data-level="1.5.2" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>1.5.2</b> Aprendizaje no supervisado</a></li>
<li class="chapter" data-level="1.5.3" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aprendizaje-por-refuerzo"><i class="fa fa-check"></i><b>1.5.3</b> Aprendizaje por refuerzo</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#perfiles-de-un-equipo"><i class="fa fa-check"></i><b>1.6</b> Perfiles de un equipo</a>
<ul>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ingeniero-de-datos"><i class="fa fa-check"></i>1) Ingeniero de datos</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#decisor"><i class="fa fa-check"></i>2) Decisor</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#analista"><i class="fa fa-check"></i>3) Analista</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#analista-experto"><i class="fa fa-check"></i>4) Analista experto</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#estadístico"><i class="fa fa-check"></i>5) Estadístico</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ingeniero-de-machine-learning"><i class="fa fa-check"></i>6) Ingeniero de Machine Learning</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#científico-de-datos"><i class="fa fa-check"></i>7) Científico de Datos</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#gerente-de-análisis-líder-de-ciencia-de-datos"><i class="fa fa-check"></i>8) Gerente de Análisis / Líder de Ciencia de Datos</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#experto-cualitativo-científico-social"><i class="fa fa-check"></i>9) Experto Cualitativo / Científico Social</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#investigador"><i class="fa fa-check"></i>10) Investigador</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#extra-personal-adicional"><i class="fa fa-check"></i>Extra) Personal Adicional</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#google-data-career-path"><i class="fa fa-check"></i>Google Data Career Path</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#flujo-de-trabajo-en-ml"><i class="fa fa-check"></i><b>1.7</b> Flujo de trabajo en <em>ML</em></a></li>
<li class="chapter" data-level="1.8" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ciclo-de-un-proyecto"><i class="fa fa-check"></i><b>1.8</b> Ciclo de un proyecto</a></li>
<li class="chapter" data-level="1.9" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#taller-de-scoping"><i class="fa fa-check"></i><b>1.9</b> Taller de Scoping</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#data-maturity-framework"><i class="fa fa-check"></i><b>1.9.1</b> Data Maturity Framework</a></li>
<li class="chapter" data-level="1.9.2" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#scoping"><i class="fa fa-check"></i><b>1.9.2</b> Scoping</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ejemplos"><i class="fa fa-check"></i>Ejemplos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducción-a-r.html"><a href="introducción-a-r.html"><i class="fa fa-check"></i><b>2</b> Introducción a R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#cómo-obtener-r"><i class="fa fa-check"></i><b>2.1</b> ¿Cómo obtener <em>R</em>?</a></li>
<li class="chapter" data-level="2.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#qué-es-rstudio"><i class="fa fa-check"></i><b>2.2</b> ¿Qué es RStudio?</a></li>
<li class="chapter" data-level="2.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#r-como-lenguaje-orientado-a-objetos"><i class="fa fa-check"></i><b>2.3</b> <em>R</em> como lenguaje orientado a objetos</a></li>
<li class="chapter" data-level="2.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#estructuras-de-almacenamiento"><i class="fa fa-check"></i><b>2.4</b> Estructuras de almacenamiento</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#operadores-de-asignación"><i class="fa fa-check"></i><b>2.4.1</b> Operadores de asignación</a></li>
<li class="chapter" data-level="2.4.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#variables"><i class="fa fa-check"></i><b>2.4.2</b> Variables</a></li>
<li class="chapter" data-level="2.4.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#vectores"><i class="fa fa-check"></i><b>2.4.3</b> Vectores</a></li>
<li class="chapter" data-level="2.4.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#matrices"><i class="fa fa-check"></i><b>2.4.4</b> Matrices</a></li>
<li class="chapter" data-level="2.4.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#arreglos"><i class="fa fa-check"></i><b>2.4.5</b> Arreglos</a></li>
<li class="chapter" data-level="2.4.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#data-frames"><i class="fa fa-check"></i><b>2.4.6</b> Data Frames</a></li>
<li class="chapter" data-level="2.4.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#listas"><i class="fa fa-check"></i><b>2.4.7</b> Listas</a></li>
<li class="chapter" data-level="2.4.8" data-path="introducción-a-r.html"><a href="introducción-a-r.html#ejercicios"><i class="fa fa-check"></i><b>2.4.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#funbas"><i class="fa fa-check"></i><b>2.5</b> Funciones básicas de R</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#qué-es-una-función-de-r"><i class="fa fa-check"></i><b>2.5.1</b> ¿Qué es una función de R?</a></li>
<li class="chapter" data-level="2.5.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#operaciones-básicas"><i class="fa fa-check"></i><b>2.5.2</b> Operaciones básicas</a></li>
<li class="chapter" data-level="2.5.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#pruebas-lógicas"><i class="fa fa-check"></i><b>2.5.3</b> Pruebas lógicas</a></li>
<li class="chapter" data-level="2.5.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#operadores-lógicos"><i class="fa fa-check"></i><b>2.5.4</b> Operadores lógicos</a></li>
<li class="chapter" data-level="2.5.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#funciones-sobre-vectores"><i class="fa fa-check"></i><b>2.5.5</b> Funciones sobre vectores</a></li>
<li class="chapter" data-level="2.5.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#función-rep"><i class="fa fa-check"></i><b>2.5.6</b> Función <code>rep</code></a></li>
<li class="chapter" data-level="2.5.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#función-seq"><i class="fa fa-check"></i><b>2.5.7</b> Función <code>seq</code></a></li>
<li class="chapter" data-level="2.5.8" data-path="introducción-a-r.html"><a href="introducción-a-r.html#ejercicios-1"><i class="fa fa-check"></i><b>2.5.8</b> EJERCICIOS</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#bucles"><i class="fa fa-check"></i><b>2.6</b> Estructuras de control</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-if"><i class="fa fa-check"></i><b>2.6.1</b> Instrucción <code>if</code></a></li>
<li class="chapter" data-level="2.6.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-if-else"><i class="fa fa-check"></i><b>2.6.2</b> Instrucción <code>if</code> <code>else</code></a></li>
<li class="chapter" data-level="2.6.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-ifelse"><i class="fa fa-check"></i><b>2.6.3</b> Instrucción <code>ifelse</code></a></li>
<li class="chapter" data-level="2.6.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-else-if"><i class="fa fa-check"></i><b>2.6.4</b> Instrucción else if</a></li>
<li class="chapter" data-level="2.6.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-for"><i class="fa fa-check"></i><b>2.6.5</b> Instrucción <code>for</code></a></li>
<li class="chapter" data-level="2.6.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-while"><i class="fa fa-check"></i><b>2.6.6</b> Instrucción <code>while</code></a></li>
<li class="chapter" data-level="2.6.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-repeat"><i class="fa fa-check"></i><b>2.6.7</b> Instrucción <code>repeat</code></a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#estilo"><i class="fa fa-check"></i><b>2.7</b> Guía de estilo</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#nombres-de-los-archivos"><i class="fa fa-check"></i><b>2.7.1</b> Nombres de los archivos</a></li>
<li class="chapter" data-level="2.7.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#nombres-de-los-objetos"><i class="fa fa-check"></i><b>2.7.2</b> Nombres de los objetos</a></li>
<li class="chapter" data-level="2.7.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#longitud-de-una-línea-de-código"><i class="fa fa-check"></i><b>2.7.3</b> Longitud de una línea de código</a></li>
<li class="chapter" data-level="2.7.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#espacios"><i class="fa fa-check"></i><b>2.7.4</b> Espacios</a></li>
<li class="chapter" data-level="2.7.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#asignación"><i class="fa fa-check"></i><b>2.7.5</b> Asignación</a></li>
<li class="chapter" data-level="2.7.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#punto-y-coma"><i class="fa fa-check"></i><b>2.7.6</b> Punto y coma</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>3</b> Tidyverse</a>
<ul>
<li class="chapter" data-level="3.1" data-path="tidyverse.html"><a href="tidyverse.html#lectura-de-archivos"><i class="fa fa-check"></i><b>3.1</b> Lectura de archivos</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="tidyverse.html"><a href="tidyverse.html#archivos-csv"><i class="fa fa-check"></i><b>3.1.1</b> Archivos <em>csv</em></a></li>
<li class="chapter" data-level="3.1.2" data-path="tidyverse.html"><a href="tidyverse.html#archivos-txt"><i class="fa fa-check"></i><b>3.1.2</b> Archivos txt</a></li>
<li class="chapter" data-level="3.1.3" data-path="tidyverse.html"><a href="tidyverse.html#archivos-xls-y-xlsx"><i class="fa fa-check"></i><b>3.1.3</b> Archivos <em>xls</em> y <em>xlsx</em></a></li>
<li class="chapter" data-level="3.1.4" data-path="tidyverse.html"><a href="tidyverse.html#archivos-json"><i class="fa fa-check"></i><b>3.1.4</b> Archivos json</a></li>
<li class="chapter" data-level="3.1.5" data-path="tidyverse.html"><a href="tidyverse.html#archivos-rds"><i class="fa fa-check"></i><b>3.1.5</b> Archivos rds</a></li>
<li class="chapter" data-level="3.1.6" data-path="tidyverse.html"><a href="tidyverse.html#bases-de-datos"><i class="fa fa-check"></i><b>3.1.6</b> Bases de Datos</a></li>
<li class="chapter" data-level="3.1.7" data-path="tidyverse.html"><a href="tidyverse.html#oracle-database"><i class="fa fa-check"></i><b>3.1.7</b> Oracle Database</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="tidyverse.html"><a href="tidyverse.html#consultas-de-datos"><i class="fa fa-check"></i><b>3.2</b> Consultas de datos</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="tidyverse.html"><a href="tidyverse.html#seleccionar-columnas"><i class="fa fa-check"></i><b>3.2.1</b> Seleccionar columnas</a></li>
<li class="chapter" data-level="3.2.2" data-path="tidyverse.html"><a href="tidyverse.html#filtrar-observaciones"><i class="fa fa-check"></i><b>3.2.2</b> Filtrar observaciones</a></li>
<li class="chapter" data-level="3.2.3" data-path="tidyverse.html"><a href="tidyverse.html#ordenar-registros"><i class="fa fa-check"></i><b>3.2.3</b> Ordenar registros</a></li>
<li class="chapter" data-level="3.2.4" data-path="tidyverse.html"><a href="tidyverse.html#agregar-modificar"><i class="fa fa-check"></i><b>3.2.4</b> Agregar / Modificar</a></li>
<li class="chapter" data-level="3.2.5" data-path="tidyverse.html"><a href="tidyverse.html#resumen-estadístico"><i class="fa fa-check"></i><b>3.2.5</b> Resumen estadístico</a></li>
<li class="chapter" data-level="3.2.6" data-path="tidyverse.html"><a href="tidyverse.html#agrupamiento"><i class="fa fa-check"></i><b>3.2.6</b> Agrupamiento</a></li>
<li class="chapter" data-level="3.2.7" data-path="tidyverse.html"><a href="tidyverse.html#cruces-de-tablas"><i class="fa fa-check"></i><b>3.2.7</b> Cruces de tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tidyverse.html"><a href="tidyverse.html#orden-y-estructura"><i class="fa fa-check"></i><b>3.3</b> Orden y estructura</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="tidyverse.html"><a href="tidyverse.html#pivote-horizontal"><i class="fa fa-check"></i><b>3.3.1</b> Pivote horizontal</a></li>
<li class="chapter" data-level="3.3.2" data-path="tidyverse.html"><a href="tidyverse.html#pivote-vertical"><i class="fa fa-check"></i><b>3.3.2</b> Pivote vertical</a></li>
<li class="chapter" data-level="3.3.3" data-path="tidyverse.html"><a href="tidyverse.html#unión-de-columnas"><i class="fa fa-check"></i><b>3.3.3</b> Unión de columnas</a></li>
<li class="chapter" data-level="3.3.4" data-path="tidyverse.html"><a href="tidyverse.html#separador-de-columnas"><i class="fa fa-check"></i><b>3.3.4</b> Separador de columnas</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tidyverse.html"><a href="tidyverse.html#manipulación-de-texto"><i class="fa fa-check"></i><b>3.4</b> Manipulación de texto</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="tidyverse.html"><a href="tidyverse.html#caracteres-especiales"><i class="fa fa-check"></i><b>3.4.1</b> Caracteres especiales</a></li>
<li class="chapter" data-level="3.4.2" data-path="tidyverse.html"><a href="tidyverse.html#tamaño-de-cadena"><i class="fa fa-check"></i><b>3.4.2</b> Tamaño de cadena</a></li>
<li class="chapter" data-level="3.4.3" data-path="tidyverse.html"><a href="tidyverse.html#concatenar"><i class="fa fa-check"></i><b>3.4.3</b> Concatenar</a></li>
<li class="chapter" data-level="3.4.4" data-path="tidyverse.html"><a href="tidyverse.html#extraer-y-reemplazar"><i class="fa fa-check"></i><b>3.4.4</b> Extraer y reemplazar</a></li>
<li class="chapter" data-level="3.4.5" data-path="tidyverse.html"><a href="tidyverse.html#expresiones-regulares"><i class="fa fa-check"></i><b>3.4.5</b> Expresiones regulares</a></li>
<li class="chapter" data-level="3.4.6" data-path="tidyverse.html"><a href="tidyverse.html#detectar-coincidencias"><i class="fa fa-check"></i><b>3.4.6</b> Detectar coincidencias</a></li>
<li class="chapter" data-level="3.4.7" data-path="tidyverse.html"><a href="tidyverse.html#contabilizar-coincidencias"><i class="fa fa-check"></i><b>3.4.7</b> Contabilizar coincidencias</a></li>
<li class="chapter" data-level="3.4.8" data-path="tidyverse.html"><a href="tidyverse.html#extraer-coincidencias"><i class="fa fa-check"></i><b>3.4.8</b> Extraer coincidencias</a></li>
<li class="chapter" data-level="3.4.9" data-path="tidyverse.html"><a href="tidyverse.html#reemplazar-coincidencias"><i class="fa fa-check"></i><b>3.4.9</b> Reemplazar coincidencias</a></li>
<li class="chapter" data-level="3.4.10" data-path="tidyverse.html"><a href="tidyverse.html#divisiones-mediante-patrones"><i class="fa fa-check"></i><b>3.4.10</b> Divisiones mediante patrones</a></li>
<li class="chapter" data-level="3.4.11" data-path="tidyverse.html"><a href="tidyverse.html#localización-de-coincidencias"><i class="fa fa-check"></i><b>3.4.11</b> Localización de coincidencias</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="tidyverse.html"><a href="tidyverse.html#manipulación-de-tiempo"><i class="fa fa-check"></i><b>3.5</b> Manipulación de tiempo</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="tidyverse.html"><a href="tidyverse.html#lectura-y-creación-de-datos-temporales"><i class="fa fa-check"></i><b>3.5.1</b> Lectura y creación de datos temporales</a></li>
<li class="chapter" data-level="3.5.2" data-path="tidyverse.html"><a href="tidyverse.html#extracción-de-datos-temporales"><i class="fa fa-check"></i><b>3.5.2</b> Extracción de datos temporales</a></li>
<li class="chapter" data-level="3.5.3" data-path="tidyverse.html"><a href="tidyverse.html#operaciones-temporales"><i class="fa fa-check"></i><b>3.5.3</b> Operaciones temporales</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tidyverse.html"><a href="tidyverse.html#iteraciones"><i class="fa fa-check"></i><b>3.6</b> Iteraciones</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="tidyverse.html"><a href="tidyverse.html#bucles-1"><i class="fa fa-check"></i><b>3.6.1</b> Bucles</a></li>
<li class="chapter" data-level="3.6.2" data-path="tidyverse.html"><a href="tidyverse.html#bucles-dobles"><i class="fa fa-check"></i><b>3.6.2</b> Bucles dobles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="visualización.html"><a href="visualización.html"><i class="fa fa-check"></i><b>4</b> Visualización</a>
<ul>
<li class="chapter" data-level="4.1" data-path="visualización.html"><a href="visualización.html#eda-análisis-exploratorio-de-datos"><i class="fa fa-check"></i><b>4.1</b> EDA: Análisis Exploratorio de Datos</a></li>
<li class="chapter" data-level="4.2" data-path="visualización.html"><a href="visualización.html#geda-análisis-exploratorio-de-datos-gráficos"><i class="fa fa-check"></i><b>4.2</b> GEDA: Análisis Exploratorio de Datos Gráficos</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="visualización.html"><a href="visualización.html#lo-que-no-se-debe-hacer"><i class="fa fa-check"></i><b>4.2.1</b> Lo que no se debe hacer…</a></li>
<li class="chapter" data-level="4.2.2" data-path="visualización.html"><a href="visualización.html#principios-de-visualización"><i class="fa fa-check"></i><b>4.2.2</b> Principios de visualización</a></li>
<li class="chapter" data-level="4.2.3" data-path="visualización.html"><a href="visualización.html#principios-generales-del-diseño-analítico"><i class="fa fa-check"></i><b>4.2.3</b> Principios generales del diseño analítico:</a></li>
<li class="chapter" data-level="4.2.4" data-path="visualización.html"><a href="visualización.html#técnicas-de-visualización"><i class="fa fa-check"></i><b>4.2.4</b> Técnicas de visualización:</a></li>
<li class="chapter" data-level="4.2.5" data-path="visualización.html"><a href="visualización.html#indicadores-de-calidad-gráfica"><i class="fa fa-check"></i><b>4.2.5</b> Indicadores de calidad gráfica:</a></li>
<li class="chapter" data-level="4.2.6" data-path="visualización.html"><a href="visualización.html#gráficos-univariados"><i class="fa fa-check"></i><b>4.2.6</b> Gráficos univariados:</a></li>
<li class="chapter" data-level="4.2.7" data-path="visualización.html"><a href="visualización.html#gráficos-multivariados"><i class="fa fa-check"></i><b>4.2.7</b> Gráficos multivariados</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="visualización.html"><a href="visualización.html#creación-de-gráficos"><i class="fa fa-check"></i><b>4.3</b> Creación de gráficos</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="visualización.html"><a href="visualización.html#estéticas"><i class="fa fa-check"></i><b>4.3.1</b> Estéticas</a></li>
<li class="chapter" data-level="4.3.2" data-path="visualización.html"><a href="visualización.html#objetos-geométricos-o-capas"><i class="fa fa-check"></i><b>4.3.2</b> Objetos geométricos o capas</a></li>
<li class="chapter" data-level="4.3.3" data-path="visualización.html"><a href="visualización.html#facetas"><i class="fa fa-check"></i><b>4.3.3</b> Facetas</a></li>
<li class="chapter" data-level="4.3.4" data-path="visualización.html"><a href="visualización.html#más-sobre-estéticas"><i class="fa fa-check"></i><b>4.3.4</b> Más sobre estéticas</a></li>
<li class="chapter" data-level="4.3.5" data-path="visualización.html"><a href="visualización.html#quick-view"><i class="fa fa-check"></i><b>4.3.5</b> Quick View</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="visualización.html"><a href="visualización.html#análisis-univariado"><i class="fa fa-check"></i><b>4.4</b> Análisis univariado</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="visualización.html"><a href="visualización.html#variables-numéricas"><i class="fa fa-check"></i><b>4.4.1</b> Variables numéricas</a></li>
<li class="chapter" data-level="4.4.2" data-path="visualización.html"><a href="visualización.html#variables-nominalescategóricas"><i class="fa fa-check"></i><b>4.4.2</b> Variables nominales/categóricas</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="visualización.html"><a href="visualización.html#análisis-multivariado"><i class="fa fa-check"></i><b>4.5</b> Análisis multivariado</a></li>
<li class="chapter" data-level="4.6" data-path="visualización.html"><a href="visualización.html#visualización-interactiva"><i class="fa fa-check"></i><b>4.6</b> Visualización interactiva</a>
<ul>
<li class="chapter" data-level="" data-path="visualización.html"><a href="visualización.html#warning"><i class="fa fa-check"></i>¡ Warning !</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="visualización.html"><a href="visualización.html#reporte-interactivos"><i class="fa fa-check"></i><b>4.7</b> Reporte interactivos</a></li>
</ul></li>
<li class="part"><span><b>Parte 2: Machine Learning</b></span></li>
<li class="chapter" data-level="5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html"><i class="fa fa-check"></i><b>5</b> Introducción a Machine Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#análisis-supervisado-vs-no-supervisado"><i class="fa fa-check"></i><b>5.1</b> Análisis Supervisado vs No supervisado</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#regresión-vs-clasificación"><i class="fa fa-check"></i><b>5.1.1</b> Regresión vs clasificación</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#sesgo-vs-varianza"><i class="fa fa-check"></i><b>5.2</b> Sesgo vs varianza</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#errores-reducibles"><i class="fa fa-check"></i><b>5.2.1</b> Errores reducibles</a></li>
<li class="chapter" data-level="5.2.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#error-irreducible"><i class="fa fa-check"></i><b>5.2.2</b> Error irreducible</a></li>
<li class="chapter" data-level="5.2.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#balance-entre-sesgo-y-varianza-o-trade-off"><i class="fa fa-check"></i><b>5.2.3</b> Balance entre sesgo y varianza o Trade-off</a></li>
<li class="chapter" data-level="5.2.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#error-total"><i class="fa fa-check"></i><b>5.2.4</b> Error total</a></li>
<li class="chapter" data-level="5.2.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#overfitting"><i class="fa fa-check"></i><b>5.2.5</b> Overfitting</a></li>
<li class="chapter" data-level="5.2.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#underfitting"><i class="fa fa-check"></i><b>5.2.6</b> Underfitting</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#orden-y-estructura-de-proyecto"><i class="fa fa-check"></i><b>5.3</b> Orden y estructura de proyecto</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#plantilla-de-estructura-proyecto"><i class="fa fa-check"></i><b>5.3.1</b> Plantilla de estructura proyecto</a></li>
<li class="chapter" data-level="5.3.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#reproducibilidad"><i class="fa fa-check"></i><b>5.3.2</b> Reproducibilidad</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#partición-de-datos"><i class="fa fa-check"></i><b>5.4</b> Partición de datos</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#métodos-comunes-para-particionar-datos"><i class="fa fa-check"></i><b>5.4.1</b> Métodos comunes para particionar datos</a></li>
<li class="chapter" data-level="5.4.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#conjunto-de-validación"><i class="fa fa-check"></i><b>5.4.2</b> Conjunto de validación</a></li>
<li class="chapter" data-level="5.4.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>5.4.3</b> Leave-one-out cross-validation</a></li>
<li class="chapter" data-level="5.4.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#v-fold-cross-validation"><i class="fa fa-check"></i><b>5.4.4</b> V Fold Cross Validation</a></li>
<li class="chapter" data-level="5.4.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#medidas-de-ajuste"><i class="fa fa-check"></i><b>5.4.5</b> Medidas de ajuste</a></li>
<li class="chapter" data-level="5.4.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#validación-cruzada-para-series-de-tiempo"><i class="fa fa-check"></i><b>5.4.6</b> Validación cruzada para series de tiempo</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#pre-procesamiento-de-datos"><i class="fa fa-check"></i><b>5.5</b> Pre-procesamiento de datos</a></li>
<li class="chapter" data-level="5.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#ingeniería-de-datos"><i class="fa fa-check"></i><b>5.6</b> Ingeniería de datos</a></li>
<li class="chapter" data-level="5.7" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#recetas"><i class="fa fa-check"></i><b>5.7</b> Recetas</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#pasos-y-estructura-de-recetas"><i class="fa fa-check"></i><b>5.7.1</b> Pasos y estructura de recetas</a></li>
<li class="chapter" data-level="5.7.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#imputaciones"><i class="fa fa-check"></i><b>5.7.2</b> Imputaciones</a></li>
<li class="chapter" data-level="5.7.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#agregar-o-modificar-columnas"><i class="fa fa-check"></i><b>5.7.3</b> Agregar o modificar columnas</a></li>
<li class="chapter" data-level="5.7.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#interacciones"><i class="fa fa-check"></i><b>5.7.4</b> Interacciones</a></li>
<li class="chapter" data-level="5.7.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#transformaciones-generales"><i class="fa fa-check"></i><b>5.7.5</b> Transformaciones generales</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#datos-y-tipos-de-modelos"><i class="fa fa-check"></i><b>5.8</b> Datos y tipos de modelos</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#separación-de-los-datos"><i class="fa fa-check"></i><b>5.8.1</b> Separación de los datos</a></li>
<li class="chapter" data-level="5.8.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#definición-de-la-receta"><i class="fa fa-check"></i><b>5.8.2</b> Definición de la receta</a></li>
<li class="chapter" data-level="5.8.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#separación-de-los-datos-1"><i class="fa fa-check"></i><b>5.8.3</b> Separación de los datos</a></li>
<li class="chapter" data-level="5.8.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#definición-de-la-receta-1"><i class="fa fa-check"></i><b>5.8.4</b> Definición de la receta</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresión-lineal.html"><a href="regresión-lineal.html"><i class="fa fa-check"></i><b>6</b> Regresión Lineal</a>
<ul>
<li class="chapter" data-level="6.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#ajuste-de-modelo"><i class="fa fa-check"></i><b>6.1</b> Ajuste de modelo</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-de-parámetros-regresión-lineal-simple"><i class="fa fa-check"></i><b>6.1.1</b> Estimación de parámetros: Regresión lineal simple</a></li>
<li class="chapter" data-level="6.1.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-de-parámetros-regresión-lineal-múltiple"><i class="fa fa-check"></i><b>6.1.2</b> Estimación de parámetros: Regresión lineal múltiple</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#residuos-del-modelo"><i class="fa fa-check"></i><b>6.2</b> Residuos del modelo</a>
<ul>
<li class="chapter" data-level="" data-path="regresión-lineal.html"><a href="regresión-lineal.html#condiciones-para-el-ajuste-de-una-regresión-lineal"><i class="fa fa-check"></i>Condiciones para el ajuste de una regresión lineal:</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#métricas-de-desempeño"><i class="fa fa-check"></i><b>6.3</b> Métricas de desempeño</a></li>
<li class="chapter" data-level="6.4" data-path="regresión-lineal.html"><a href="regresión-lineal.html#implementación-en-r"><i class="fa fa-check"></i><b>6.4</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#coeficientes-del-modelo"><i class="fa fa-check"></i><b>6.4.1</b> Coeficientes del modelo</a></li>
<li class="chapter" data-level="6.4.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#métricas-de-desempeño-1"><i class="fa fa-check"></i><b>6.4.2</b> Métricas de desempeño</a></li>
<li class="chapter" data-level="6.4.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#gráfica-de-ajuste"><i class="fa fa-check"></i><b>6.4.3</b> Gráfica de ajuste</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="regresión-lineal.html"><a href="regresión-lineal.html#métodos-se-selección-de-variables"><i class="fa fa-check"></i><b>6.5</b> Métodos se selección de variables</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#forward-selection-selección-hacia-adelante"><i class="fa fa-check"></i><b>6.5.1</b> Forward selection (selección hacia adelante)</a></li>
<li class="chapter" data-level="6.5.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#backward-selection-selección-hacia-atrás"><i class="fa fa-check"></i><b>6.5.2</b> Backward selection (selección hacia atrás)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>7</b> Regresión Logística</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regresión-logística.html"><a href="regresión-logística.html#función-sigmoide"><i class="fa fa-check"></i><b>7.1</b> Función sigmoide</a></li>
<li class="chapter" data-level="7.2" data-path="regresión-logística.html"><a href="regresión-logística.html#ajuste-del-modelo"><i class="fa fa-check"></i><b>7.2</b> Ajuste del modelo</a></li>
<li class="chapter" data-level="7.3" data-path="regresión-logística.html"><a href="regresión-logística.html#clasificación-2"><i class="fa fa-check"></i><b>7.3</b> Clasificación</a></li>
<li class="chapter" data-level="7.4" data-path="regresión-logística.html"><a href="regresión-logística.html#métricas-de-desempeño-2"><i class="fa fa-check"></i><b>7.4</b> Métricas de desempeño</a></li>
<li class="chapter" data-level="7.5" data-path="regresión-logística.html"><a href="regresión-logística.html#implementación-en-r-1"><i class="fa fa-check"></i><b>7.5</b> Implementación en R</a></li>
<li class="chapter" data-level="7.6" data-path="regresión-logística.html"><a href="regresión-logística.html#matriz-de-confusión"><i class="fa fa-check"></i><b>7.6</b> Matriz de Confusión</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html"><i class="fa fa-check"></i><b>8</b> K-Nearest-Neighbor</a>
<ul>
<li class="chapter" data-level="8.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#clasificación-3"><i class="fa fa-check"></i><b>8.1</b> Clasificación</a></li>
<li class="chapter" data-level="8.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#regresión-2"><i class="fa fa-check"></i><b>8.2</b> Regresión</a></li>
<li class="chapter" data-level="8.3" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#ajuste-del-modelo-1"><i class="fa fa-check"></i><b>8.3</b> Ajuste del modelo</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#selección-de-hiper-parámetro-k"><i class="fa fa-check"></i><b>8.3.1</b> Selección de Hiper-parámetro K</a></li>
<li class="chapter" data-level="8.3.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#métodos-de-cálculo-de-la-distancia-entre-observaciones"><i class="fa fa-check"></i><b>8.3.2</b> Métodos de cálculo de la distancia entre observaciones</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#implementación-en-r-2"><i class="fa fa-check"></i><b>8.4</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#regresión-3"><i class="fa fa-check"></i><b>8.4.1</b> Regresión</a></li>
<li class="chapter" data-level="8.4.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#clasificación-4"><i class="fa fa-check"></i><b>8.4.2</b> Clasificación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html"><i class="fa fa-check"></i><b>9</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="9.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#ajuste-del-modelo-2"><i class="fa fa-check"></i><b>9.1</b> Ajuste del modelo</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#attribute-selective-measure-asm"><i class="fa fa-check"></i><b>9.1.1</b> Attribute Selective Measure (ASM)</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#regularización-de-árboles"><i class="fa fa-check"></i><b>9.2</b> Regularización de árboles</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#nivel-de-profundidad-de-árbol"><i class="fa fa-check"></i><b>9.2.1</b> Nivel de profundidad de árbol</a></li>
<li class="chapter" data-level="9.2.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#poda-de-árbol"><i class="fa fa-check"></i><b>9.2.2</b> Poda de árbol</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#aprendizaje-conjunto"><i class="fa fa-check"></i><b>9.3</b> Aprendizaje conjunto</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging-vs.-boosting"><i class="fa fa-check"></i><b>9.3.1</b> Bagging vs. boosting</a></li>
<li class="chapter" data-level="9.3.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#error-out-of-bag"><i class="fa fa-check"></i><b>9.3.2</b> Error Out-Of-Bag</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging"><i class="fa fa-check"></i><b>9.4</b> Bagging</a></li>
<li class="chapter" data-level="9.5" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#random-forest"><i class="fa fa-check"></i><b>9.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#qué-es"><i class="fa fa-check"></i><b>9.5.1</b> ¿Qué es?</a></li>
<li class="chapter" data-level="9.5.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#características-de-los-bosques-aleatorios"><i class="fa fa-check"></i><b>9.5.2</b> Características de los bosques aleatorios</a></li>
<li class="chapter" data-level="9.5.3" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#aplicar-árboles-de-decisión-en-un-bosque-aleatorio"><i class="fa fa-check"></i><b>9.5.3</b> Aplicar árboles de decisión en un bosque aleatorio</a></li>
<li class="chapter" data-level="9.5.4" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#ventajas-y-desventjas-de-bosques-aleatorios"><i class="fa fa-check"></i><b>9.5.4</b> Ventajas y desventjas de bosques aleatorios</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#implementación-en-r-3"><i class="fa fa-check"></i><b>9.6</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#regresión-4"><i class="fa fa-check"></i><b>9.6.1</b> Regresión</a></li>
<li class="chapter" data-level="9.6.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#clasificación-5"><i class="fa fa-check"></i><b>9.6.2</b> Clasificación</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#boosting"><i class="fa fa-check"></i><b>9.7</b> Boosting</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#predicciones-boosting"><i class="fa fa-check"></i><b>9.7.1</b> Predicciones <em>Boosting</em></a></li>
<li class="chapter" data-level="9.7.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#modelos-boosting"><i class="fa fa-check"></i><b>9.7.2</b> Modelos <em>Boosting</em></a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#implementación-de-xgb-en-r"><i class="fa fa-check"></i><b>9.8</b> Implementación de XGB en R</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#xgboost-para-regresión"><i class="fa fa-check"></i><b>9.8.1</b> XGBoost para regresión</a></li>
<li class="chapter" data-level="9.8.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#xgboost-para-clasificación"><i class="fa fa-check"></i><b>9.8.2</b> XGBoost para clasificación</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Ciencia de Datos y Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="árboles-de-decisión" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Capítulo 9</span> Árboles de decisión<a href="árboles-de-decisión.html#árboles-de-decisión" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><img src="img/09-ml-tree/0-arboles.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>Un árbol de decisiones es un algoritmo del aprendizaje supervisado que se puede utilizar tanto para problemas de <strong>clasificación</strong> como de <strong>regresión</strong>. Es un clasificador estructurado en árbol, donde los nodos internos representan las características de un conjunto de datos, las ramas representan las reglas de decisión y cada nodo hoja representa el resultado. La idea básica de los árboles es buscar puntos de cortes en las variables de entrada para hacer predicciones, ir dividiendo la muestra, y encontrar cortes sucesivos para refinar las predicciones.</p>
<p>En un árbol de decisión, hay dos tipos nodos, el nodo de decisión o nodos internos (<em>Decision Node</em>) y el nodo hoja o nodo terminal (Leaf node). Los nodos de decisión se utilizan para tomar cualquier decisión y tienen múltiples ramas, mientras que los nodos hoja son el resultado de esas decisiones y no contienen más ramas.</p>
<p><img src="img/09-ml-tree/1-arboles.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Regresión:</strong> En el caso de la regresión de árboles de decisión, en los nodos finales se calcula el promedio de la variable de respuesta. El promedio será la estimación del modelo.</li>
</ul>
<p><img src="img/09-ml-tree/2-arbol-reg-graph.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p><img src="img/09-ml-tree/3-arbol-reg-diagram.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Clasificación:</strong> Por otro lado, en los árboles de clasificación se calcula la proporción de elementos de cada categoría en los nodos finales. De esta manera se calcula la probabilidad de pertenencia a la categoría.</li>
</ul>
<p><img src="img/09-ml-tree/4-arbol-cla-graph.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p><img src="img/09-ml-tree/5-arbol-cla-diagram.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<div id="ajuste-del-modelo-2" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Ajuste del modelo<a href="árboles-de-decisión.html#ajuste-del-modelo-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En un árbol de decisión, para predecir la clase del conjunto de datos, el algoritmo comienza desde el nodo raíz del árbol. Este algoritmo compara los valores de la variable raíz con la variable de registro y, según la comparación, sigue una rama y salta al siguiente nodo.</p>
<p>Para el siguiente nodo, el algoritmo vuelve a comparar el valor de la siguiente variable con los otros sub-nodos y avanza. Continúa el proceso hasta que se llega a un nodo hoja. El proceso completo se puede comprender mejor con los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li><p>Comenzamos el árbol con el nodo raíz (llamado S), que contiene el conjunto de entrenamiento completo.</p></li>
<li><p>Encuentre la mejor variable en el conjunto de datos usando <em>Attribute Selective Measure</em> (ASM).</p></li>
<li><p>Divida la S en subconjuntos que contengan valores posibles para la mejor variable.</p></li>
<li><p>Genere el nodo del árbol de decisión, que contiene la mejor variable.</p></li>
<li><p>Cree de forma recursiva nuevos árboles de decisión utilizando los subconjuntos del conjunto de datos creado en el paso 3. Continúe este proceso hasta que se alcance una etapa en la que no pueda particionar más los nodos y este nodo final sera un nodo hoja.</p></li>
<li><p>Para clasificación nos quedaremos la moda de la variable respuesta del nodo hoja y para regresión usaremos la media de la variable respuesta.</p></li>
</ol>
<div id="attribute-selective-measure-asm" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Attribute Selective Measure (ASM)<a href="árboles-de-decisión.html#attribute-selective-measure-asm" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Al implementar un árbol de decisión, surge el problema principal de cómo seleccionar la mejor variable para el nodo raíz y para los sub-nodos. Para resolver este problemas existe una técnica que se llama medida de selección de atributos o <em>ASM</em>. Mediante esta medición, podemos seleccionar fácilmente la mejor variable para los nodos del árbol. Hay dos técnicas populares para <em>ASM</em>, que son:</p>
<ul>
<li>Índice de Gini</li>
</ul>
<p>La medida del grado de probabilidad de que una variable en particular se clasifique incorrectamente cuando se elige al azar se llama índice de Gini o impureza de Gini. Los datos se distribuyen por igual según el índice de Gini.</p>
<p><span class="math display">\[Gini = \sum_{i=1}^{n}\hat{p_i}(1-\hat{p}_i)\]</span></p>
<p>Con <span class="math inline">\(p_i\)</span> como la probabilidad de que un objeto se clasifique en una clase particular.</p>
<p>Esta métrica puede analizarse como una métrica de impureza. Cuando todos o la mayoría de elementos dentro de un nodo pertenecen a una misma clase, el índice de Gini toma valores cercanos a cero.</p>
<p>Cuando se utiliza el índice de Gini como criterio seleccionar la variable para el nodo raíz, seleccionaremos la variable con el índice de Gini menor.</p>
</div>
</div>
<div id="regularización-de-árboles" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Regularización de árboles<a href="árboles-de-decisión.html#regularización-de-árboles" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para asegurarse de que no exista sobre-ajuste en el modelo, es importante considerar algunas regularizaciones a los hiper-parámetros implementados. Posteriormente, se determinará cuál de las posibles combinaciones produce mejores resultados.</p>
<div id="nivel-de-profundidad-de-árbol" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Nivel de profundidad de árbol<a href="árboles-de-decisión.html#nivel-de-profundidad-de-árbol" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Podríamos preguntarnos cuándo dejar de crecer un árbol. Pueden existir problemas que tengan un gran conjunto de variables y esto da como resultado una gran cantidad de divisiones, lo que a su vez genera un árbol de decisión muy grande. Estos árboles son complejos y pueden provocar un sobre-ajuste. Entonces, necesitamos saber cuándo parar.</p>
<ol style="list-style-type: decimal">
<li><p>Una forma de hacer esto es establecer un número mínimo de entradas de entrenamiento para dividir un nodo.</p></li>
<li><p>Otra forma es establecer la profundidad máxima de su modelo. La profundidad máxima se refiere a la longitud del camino más largo desde el nodo raíz hasta un nodo hoja.</p></li>
</ol>
</div>
<div id="poda-de-árbol" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Poda de árbol<a href="árboles-de-decisión.html#poda-de-árbol" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El rendimiento de un árbol se puede aumentar aún más mediante la poda del árbol. Esto se refiere a eliminar las ramas que hacen uso de variables de poca importancia. De esta manera, reducimos la complejidad del árbol y, por lo tanto, <strong>aumentamos su poder predictivo al reducir el sobre-ajuste.</strong></p>
<p><img src="img/09-ml-tree/6-podar.jpg" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>La poda puede comenzar en la raíz o en las hojas. El método más simple de poda comienza en las hojas y elimina cada nodo con la clase más popular en esa hoja, este cambio se mantiene si no deteriora la precisión. Se pueden usar métodos de poda más sofisticados, como la poda de complejidad de costos, donde se usa un parámetro de aprendizaje (alfa) para observar si los nodos se pueden eliminar en función del tamaño del sub-árbol.</p>
<!-- ### Implementación en R -->
<!-- Usaremos las recetas antes implementadas para ajustar tanto el modelo de regresión como el de clasificación. Exploraremos un conjunto de hiperparámetros para elegir el mejor modelo. En esta ocasión usamos la función *grid_random()* donde el parámetro *size* indica el número total de combinaciones a implementar. En caso de que haya duplicados, un número menor de combinaciones a las establecidas será devuelto como resultado. -->
<!-- #### Regresión {-} -->
<!-- **Paso 1: Separación inicial de datos ( test, train, KFCV)** -->
<!-- ```{r} -->
<!-- library(tidymodels) -->
<!-- data(ames) -->
<!-- set.seed(4595) -->
<!-- ames_split <- initial_split(ames, prop = 0.75) -->
<!-- ames_train <- training(ames_split) -->
<!-- ames_test  <- testing(ames_split) -->
<!-- ames_folds <- vfold_cv(ames_train) -->
<!-- ``` -->
<!-- Contando con datos de entrenamiento, procedemos a realizar el feature engineering para extraer las mejores características que permitirán realizar las estimaciones en el modelo. -->
<!-- **Paso 2: Pre-procesamiento e ingeniería de variables** -->
<!-- ```{r, warning=FALSE,message=FALSE} -->
<!-- receta_casas <- recipe( -->
<!--  Sale_Price ~ Gr_Liv_Area + TotRms_AbvGrd + Exter_Cond + Bsmt_Cond + -->
<!--   Year_Sold + Year_Remod_Add,  -->
<!--  data = ames_train) %>% -->
<!--   step_mutate( -->
<!--     Age_House = Year_Sold - Year_Remod_Add, -->
<!--     Exter_Cond = forcats::fct_collapse(Exter_Cond, Good = c("Typical", "Good", "Excellent"))) %>%  -->
<!--   step_relevel(Exter_Cond, ref_level = "Good") %>%  -->
<!--   step_normalize(all_numeric_predictors()) %>% -->
<!--   step_dummy(all_nominal_predictors()) %>%  -->
<!--   step_interact(~ matches("Bsmt_Cond"):TotRms_AbvGrd) %>%  -->
<!--   prep() -->
<!-- receta_casas -->
<!-- ``` -->
<!-- Recordemos que la función **recipe()** solo son los pasos a seguir, necesitamos usar la función **prep()** que nos devuelve una receta actualizada con las estimaciones y la función **juice()** que nos devuelve la matriz de diseño. -->
<!-- Una vez que la receta de transformación de datos está lista, procedemos a implementar el pipeline del modelo de interés. -->
<!-- **Paso 3: Selección de tipo de modelo con hiperparámetros iniciales** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=TRUE} -->
<!-- # install.packages("rpart") -->
<!-- tree_model <- decision_tree( -->
<!--   mode = "regression", -->
<!--   tree_depth = tune(), -->
<!--   cost_complexity = tune(), -->
<!--   min_n = tune()) %>%  -->
<!--   set_engine("rpart") -->
<!-- ``` -->
<!-- **Paso 4: Inicialización de workflow o pipeline** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=TRUE} -->
<!-- tree_workflow <- workflow() %>%  -->
<!--   add_recipe(receta_casas) %>%  -->
<!--   add_model(tree_model) -->
<!-- ``` -->
<!-- **Paso 5: Creación de grid search** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=TRUE} -->
<!-- tree_parameters_set <- extract_parameter_set_dials(tree_workflow) %>%  -->
<!--  update( -->
<!--   min_n = min_n(range = c(2L, 40L)), -->
<!--   tree_depth = tree_depth(range = c(1L, 15L)), -->
<!--   cost_complexity = cost_complexity(range = c(-10, -1), trans = log10_trans()) -->
<!--   ) -->
<!-- set.seed(123) -->
<!-- tree_grid <- tree_parameters_set %>%  -->
<!--  grid_random(size = 100) -->
<!-- ctrl_grid <- control_grid(save_pred = T, verbose = T) -->
<!-- ``` -->
<!-- **Paso 6: Entrenamiento de modelos con hiperparámetros definidos** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=FALSE} -->
<!-- library(doParallel) -->
<!-- UseCores <- detectCores() - 1 -->
<!-- cluster <- makeCluster(UseCores) -->
<!-- registerDoParallel(cluster) -->
<!-- tree1 <- Sys.time() -->
<!-- tree_tune_result <- tune_grid( -->
<!--   tree_workflow, -->
<!--   resamples = ames_folds, -->
<!--   grid = tree_grid, -->
<!--   metrics = metric_set(rmse, mae, mape, rsq), -->
<!--   control = ctrl_grid -->
<!-- ) -->
<!-- tree2 <- Sys.time(); tree2 - tree1 -->
<!-- stopCluster(cluster) -->
<!-- tree_tune_result %>% saveRDS("models/tree_model_reg.rds") -->
<!-- ``` -->
<!-- ```{r} -->
<!-- tree_tune_result <- readRDS("models/tree_model_reg.rds") -->
<!-- ``` -->
<!-- **Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)** -->
<!-- Podemos obtener las métricas de cada *fold* con el siguiente código: -->
<!-- ```{r} -->
<!-- collect_metrics(tree_tune_result) -->
<!-- ``` -->
<!-- En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos: -->
<!-- ```{r} -->
<!-- tree_tune_result %>% autoplot() -->
<!-- ``` -->
<!-- En la siguiente gráfica observamos el error cuadrático medio de las distintas métricas con distintos números de vecinos. -->
<!-- ```{r} -->
<!-- tree_tune_result %>% autoplot(metric = "rmse") -->
<!-- ``` -->
<!-- En la siguiente gráfica observamos el error absoluto promedio de las distintas métricas con distintos números de vecinos. -->
<!-- ```{r} -->
<!-- tree_tune_result %>% autoplot(metric = "mae") -->
<!-- ``` -->
<!-- **Paso 8: Selección de modelo a usar** -->
<!-- Con el siguiente código obtenemos los mejores 10 modelos respecto al *rmse*. -->
<!-- ```{r} -->
<!-- show_best(tree_tune_result, n = 10, metric = "rmse") -->
<!-- ``` -->
<!-- ```{r} -->
<!-- tree_tune_result %>% show_best(n = 10, metric = "mape") -->
<!-- ``` -->
<!-- Ahora obtendremos el modelo que mejor desempeño tiene tomando en cuenta el *rmse* y haremos las predicciones del conjunto de prueba con este modelo. -->
<!-- ```{r} -->
<!-- best_tree_model_reg <- tree_tune_result %>% select_best(metric = "rmse") -->
<!-- best_tree_model_reg -->
<!-- ``` -->
<!-- ```{r} -->
<!-- tree_regression_best_1se_model <- tree_tune_result %>%  -->
<!--   select_by_one_std_err(metric = "rmse", "rmse") -->
<!-- tree_regression_best_1se_model -->
<!-- ``` -->
<!-- **Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)** -->
<!-- ```{r} -->
<!-- final_tree_model_reg <- tree_workflow %>%  -->
<!--   finalize_workflow(best_tree_model_reg) %>%  -->
<!--   parsnip::fit(data = ames_train) -->
<!-- ``` -->
<!-- Este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.  -->
<!-- El árbol final se ve de la siguiente manera: -->
<!-- ```{r, warning=FALSE, message=FALSE} -->
<!-- library(rpart.plot) -->
<!-- final_tree_model_reg %>% -->
<!--   extract_fit_engine() %>% -->
<!--   rpart.plot(roundint = FALSE) -->
<!-- ``` -->
<!-- Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos [data leakage](https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba). Para enfrentar esto, ayuda estimar y ordenar el valor de importancia de cada variable en el modelo. -->
<!-- Podemos obtener la importancia de las variables de manera gráfica: -->
<!-- ```{r, message=F, warning=FALSE} -->
<!-- library(vip) -->
<!-- final_tree_model_reg %>%  -->
<!--  extract_fit_parsnip() %>%  -->
<!--  vip(geom = "col") +  -->
<!--  ggtitle("Importancia de las variables") -->
<!-- ``` -->
<!-- **Paso 10: Validar poder predictivo con datos de prueba** -->
<!-- Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos: -->
<!-- ```{r} -->
<!-- results_reg <- predict(final_tree_model_reg, ames_test) %>%  -->
<!--   dplyr::bind_cols(Sale_Price = ames_test$Sale_Price, .) %>%  -->
<!--   dplyr::rename(pred_tree_reg = .pred) -->
<!-- results_reg -->
<!-- ``` -->
<!-- **Métricas de desempeño** -->
<!-- Ahora para calcular las métricas de desempeño usaremos la paquetería *MLmetrics*. Es posible definir nuestro propio conjunto de métricas que deseamos reportar creando el objeto *metric_set*: -->
<!-- ```{r, message=F, warning=FALSE} -->
<!-- library(MLmetrics) -->
<!-- multi_metric <- metric_set(mae, mape, rmse, rsq, ccc) -->
<!-- multi_metric(results_reg, truth = Sale_Price, estimate = pred_tree_reg) %>%  -->
<!--   mutate(.estimate = round(.estimate, 2)) %>%  -->
<!--   select(-.estimator) -->
<!-- ``` -->
<!-- ```{r} -->
<!-- results_reg %>%  -->
<!--   ggplot(aes(x = pred_tree_reg, y = Sale_Price)) + -->
<!--   geom_point() + -->
<!--   geom_abline(color = "red") + -->
<!--   xlab("Prediction") + -->
<!--   ylab("Observation") + -->
<!--   ggtitle("Comparisson") -->
<!-- ``` -->
<!-- #### Clasificación {-} -->
<!-- Es turno de revisar la implementación del árbol de decisión con nuestro bien conocido problema de predicción de cancelación de servicios de telecomunicaciones. Los datos se encuentran disponibles en el siguiente [enlace](https://drive.google.com/drive/folders/1mlDGHvUy-81qfvQi_iB7tqMb9yhy3vyh?usp=sharing): -->
<!-- Los pasos para implementar en *R* este modelo predictivo son los mismos, cambiando únicamente las especificaciones del tipo de modelo, pre-procesamiento e hiper-parámetros. -->
<!-- ```{r, warning=FALSE, message=FALSE} -->
<!-- library(readr) -->
<!-- library(tidyverse) -->
<!-- library(tidymodels) -->
<!-- tidymodels_prefer() -->
<!-- telco <- read_csv("data/Churn.csv") -->
<!-- glimpse(telco) -->
<!-- ``` -->
<!-- **Paso 1: Separación inicial de datos ( test, train <KFCV> )** -->
<!-- ```{r} -->
<!-- set.seed(1234) -->
<!-- telco_split <- initial_split(telco, prop = .70) -->
<!-- telco_train <- training(telco_split) -->
<!-- telco_test  <- testing(telco_split) -->
<!-- telco_folds <- vfold_cv(telco_train) -->
<!-- telco_folds -->
<!-- ``` -->
<!-- **Paso 2: Pre-procesamiento e ingeniería de variables** -->
<!-- ```{r} -->
<!-- telco_rec <- recipe( -->
<!--   Churn ~ customerID + TotalCharges + MonthlyCharges + SeniorCitizen + Contract,  -->
<!--   data = telco_train) %>%  -->
<!--   update_role(customerID, new_role = "id variable") %>%  -->
<!--   step_mutate(Contract = as.factor(Contract)) %>%  -->
<!--   step_impute_median(all_numeric_predictors()) %>%  -->
<!--   step_normalize(all_numeric_predictors()) %>%  -->
<!--   step_dummy(all_nominal_predictors()) %>%  -->
<!--   prep() -->
<!-- telco_rec -->
<!-- ``` -->
<!-- **Paso 3: Selección de tipo de modelo con hiperparámetros iniciales** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=TRUE} -->
<!-- tree_model <- decision_tree( -->
<!--   mode = "classification", -->
<!--   tree_depth = tune(), -->
<!--   cost_complexity = tune(), -->
<!--   min_n = tune()) %>%  -->
<!--   set_engine("rpart") -->
<!-- tree_model -->
<!-- ``` -->
<!-- **Paso 4: Inicialización de workflow o pipeline** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=TRUE} -->
<!-- tree_workflow <- workflow() %>%  -->
<!--   add_recipe(telco_rec) %>%  -->
<!--   add_model(tree_model) -->
<!-- tree_workflow -->
<!-- ``` -->
<!-- **Paso 5: Creación de grid search** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=TRUE} -->
<!-- tree_parameters_set <- extract_parameter_set_dials(tree_workflow) %>%  -->
<!--   update( -->
<!--    min_n = min_n(range = c(4, 50)), -->
<!--    tree_depth = tree_depth(range = c(1L, 15L)), -->
<!--    cost_complexity = cost_complexity(range = c(-10, -1), trans = log10_trans()) -->
<!--  ) -->
<!-- set.seed(123) -->
<!-- tree_grid <- tree_parameters_set %>%  -->
<!--  grid_random(size = 30) -->
<!-- ctrl_grid <- control_grid(save_pred = T, verbose = T) -->
<!-- ``` -->
<!-- **Paso 6: Entrenamiento de modelos con hiperparámetros definidos** -->
<!-- ```{r, warning=FALSE,message=FALSE, eval=FALSE} -->
<!-- library(doParallel) -->
<!-- UseCores <- detectCores() - 1 -->
<!-- cluster <- makeCluster(UseCores) -->
<!-- registerDoParallel(cluster) -->
<!-- tree1 <- Sys.time() -->
<!-- tree_tune_result <- tune_grid( -->
<!--   tree_workflow, -->
<!--   resamples = telco_folds, -->
<!--   grid = tree_grid, -->
<!--   metrics = metric_set(roc_auc, pr_auc), -->
<!--   control = ctrl_grid -->
<!-- ) -->
<!-- tree2 <- Sys.time(); tree2 - tree1 -->
<!-- stopCluster(cluster) -->
<!-- tree_tune_result %>% saveRDS("models/tree_model_cla.rds") -->
<!-- ``` -->
<!-- ```{r} -->
<!-- tree_tune_result <- readRDS("models/tree_model_cla.rds") -->
<!-- ``` -->
<!-- **Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)** -->
<!-- ```{r} -->
<!-- collect_metrics(tree_tune_result) -->
<!-- ``` -->
<!-- En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos. -->
<!-- ```{r} -->
<!-- autoplot(tree_tune_result, metric = "pr_auc") -->
<!-- ``` -->
<!-- ```{r} -->
<!-- autoplot(tree_tune_result, metric = "roc_auc") -->
<!-- ``` -->
<!-- ```{r} -->
<!-- show_best(tree_tune_result, n = 10, metric = "pr_auc") -->
<!-- ``` -->
<!-- **Paso 8: Selección de modelo a usar** -->
<!-- ```{r} -->
<!-- best_tree_model_cla <- select_best(tree_tune_result, metric = "pr_auc") -->
<!-- best_tree_model_cla -->
<!-- tree_classification_best_1se_model <- tree_tune_result %>%  -->
<!--   select_by_one_std_err(metric = "roc_auc", "roc_auc") -->
<!-- tree_classification_best_1se_model -->
<!-- ``` -->
<!-- **Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)** -->
<!-- ```{r} -->
<!-- final_tree_model_cla <- tree_workflow %>%  -->
<!--   finalize_workflow(best_tree_model_cla) %>%  -->
<!--   parsnip::fit(data = telco_train) -->
<!-- ``` -->
<!-- Este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.  -->
<!-- El árbol ajustado con todos los datos de entrenamiento se ve de la siguiente manera: -->
<!-- ```{r, message=FALSE, warning=FALSE} -->
<!-- library(rpart.plot) -->
<!-- final_tree_model_cla %>% -->
<!--   extract_fit_engine() %>% -->
<!--   rpart.plot(roundint = FALSE) -->
<!-- ``` -->
<!-- Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos [data leakage](https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba). Para enfrentar esto, ayuda estimar y ordenar el valor de importancia del modelo. -->
<!-- ```{r, eval=FALSE} -->
<!-- library(vip) -->
<!-- final_tree_model_cla %>%  -->
<!--   extract_fit_parsnip() %>%  -->
<!--   vip() + ggtitle("Importancia de las variables") -->
<!-- ``` -->
<!-- **Paso 10: Validar poder predictivo con datos de prueba** -->
<!-- Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos: -->
<!-- ```{r} -->
<!-- results_cla <- predict(final_tree_model_cla, telco_test, type = 'prob') %>%  -->
<!--   dplyr::bind_cols(Churn = telco_test$Churn, .) %>%  -->
<!--   mutate(Churn = factor(Churn, levels = c('Yes', 'No'), labels = c('Yes', 'No'))) -->
<!-- results_cla -->
<!-- bind_rows( -->
<!--   roc_auc(results_cla, truth = Churn, estimate = .pred_Yes), -->
<!--   pr_auc(results_cla, truth = Churn, estimate = .pred_Yes) -->
<!-- ) -->
<!-- ``` -->
<!-- ```{r, eval=TRUE} -->
<!-- pr_curve_data <- pr_curve( -->
<!--   results_cla,  -->
<!--   truth = Churn,  -->
<!--   estimate = .pred_Yes -->
<!--   ) -->
<!-- pr_curve_data -->
<!-- roc_curve_data <- roc_curve( -->
<!--   results_cla,  -->
<!--   truth = Churn,  -->
<!--   estimate = .pred_Yes -->
<!--   ) -->
<!-- roc_curve_data -->
<!-- ``` -->
<!-- ```{r, message=FALSE} -->
<!-- pr_curve_plot <- pr_curve_data %>%  -->
<!--   ggplot(aes(x = recall, y = precision)) + -->
<!--   geom_path(size = 1, colour = 'lightblue') + -->
<!--   geom_abline(slope = -1, intercept = 1) + -->
<!--   ylim(0, 1) + -->
<!--   coord_equal() + -->
<!--   ggtitle("Precision vs Recall")+ -->
<!--   theme_minimal() -->
<!-- pr_curve_plot -->
<!-- roc_curve_plot <- roc_curve_data %>%  -->
<!--   ggplot(aes(x = 1 - specificity, y = sensitivity)) + -->
<!--   geom_path(size = 1, colour = 'lightblue') + -->
<!--   geom_abline() + -->
<!--   ylim(0, 1) + -->
<!--   coord_equal() + -->
<!--   ggtitle("ROC Curve")+ -->
<!--   theme_minimal() -->
<!-- roc_curve_plot -->
<!-- ``` -->
<!-- Pueden usar la app de [shiny](https://acturio.shinyapps.io/confusion_matrix/?_ga=2.157345976.322506426.1653670259-130075619.1646374742) que nos permite jugar con el threshold de clasificación para tomar la mejor decisión. -->
</div>
</div>
<div id="aprendizaje-conjunto" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Aprendizaje conjunto<a href="árboles-de-decisión.html#aprendizaje-conjunto" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El aprendizaje conjunto da crédito a la idea de la “sabiduría de las multitudes”, lo que sugiere que <strong>la toma de decisiones de un grupo más grande de individuos (modelos) suele ser mejor que la de un individuo.</strong></p>
<p>El aprendizaje en conjunto <strong>es un grupo (o conjunto) de individuos o modelos, que trabajan colectivamente para lograr una mejor predicción final</strong>. Un solo modelo, también conocido como aprendiz básico puede no funcionar bien individualmente debido a una gran variación o un alto sesgo, sin embargo, cuando se agregan individuos débiles, pueden formar un individuo fuerte, ya que su combinación reduce el sesgo o la varianza, lo que produce un mejor rendimiento del modelo.</p>
<p><img src="img/09-ml-tree/ramitas.jpg" width="600pt" height="350pt" style="display: block; margin: auto;" /></p>
<p>Los métodos de conjunto se ilustran con frecuencia utilizando árboles de decisión, ya que este algoritmo puede ser propenso a sobre ajustar (alta varianza y bajo sesgo) y también puede prestarse a desajuste (baja varianza y alto sesgo) cuando es muy pequeño, como un árbol de decisión con un nivel.</p>
<p><strong>Nota:</strong> Cuando un algoritmo se adapta o no se adapta a su conjunto de entrenamiento, no se puede generalizar bien a nuevos conjuntos de datos, por lo que se utilizan métodos de conjunto para contrarrestar este comportamiento y permitir la generalización del modelo a nuevos conjuntos de datos.</p>
<div id="bagging-vs.-boosting" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Bagging vs. boosting<a href="árboles-de-decisión.html#bagging-vs.-boosting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><em>Bagging</em> y el <em>boosting (refuerzo o impulso)</em> son dos tipos principales de métodos de aprendizaje por conjuntos. La principal diferencia entre estos métodos de aprendizaje es la forma en que se capacitan.</p>
<p>En <strong><em>bagging</em>, los modelos se entrenan en paralelo, pero en el <em>boosting</em>, aprenden secuencialmente.</strong> Esto significa que se construyen una serie de modelos y con cada nueva iteración del modelo, se incrementan los pesos de los datos clasificados erróneamente en el modelo anterior. Esta redistribución de pesos ayuda al algoritmo a identificar los parámetros en los que necesita enfocarse para mejorar su desempeño.</p>
<p><img src="img/09-ml-tree/bagging-boosting.jpeg" width="600pt" height="350pt" style="display: block; margin: auto;" /></p>
<p>Un ejemplo de modelo secuencial es: <strong>Adaboost</strong> y significa “algoritmo de boosting adaptativo”, es uno de los algoritmos de boosting más populares, ya que fue uno de los primeros de su tipo. Otros tipos de algoritmos de boosting incluyen <strong>XGBoost</strong>, <em>GradientBoost</em> y <em>BrownBoost</em>.</p>
<p>Otra diferencia en la que difieren <em>bagging</em> y <em>boosting</em> son los escenarios en los que se utilizan. Por ejemplo, los métodos de <em>bagging</em> se utilizan típicamente en modelos débiles que exhiben alta varianza y bajo sesgo, mientras que los métodos de <em>boosting</em> se aprovechan cuando se observa baja varianza y alto sesgo.</p>
<div class="infobox note">
<p><strong>¡¡ RECORDAR !!</strong></p>
<p>Bagging realiza replicaciones bootstrap y ajusta un árbol a cada muestra de manera independiente, mientras que boosting ajusta un árbol a una versión modificada del conjunto original de datos, la cual se modifica en cada iteración de entrenamiento.</p>
</div>
</div>
<div id="error-out-of-bag" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Error Out-Of-Bag<a href="árboles-de-decisión.html#error-out-of-bag" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este error es conocido como “OOB”. Se trata de un enfoque distinto a KFCV en donde el error predictivo es calculado a través de los elementos que <strong>no fueron seleccionados</strong> en la muestra bootstrap. Recordemos que en las muestras bootstrap algunos elementos son seleccionados más de una vez, mientras que otros no aparecen en la muestra. Empíricamente, en cada replicación bootstrap se observan 2/3 partes de la muestra y el resto queda “fuera de la bolsa” (OOB) de entrenamiento.</p>
<p>Si <strong>B</strong> es el número de replicaciones bootstrap, entonces cada observación <em>i</em> recibe cerca de B/3 predicciones, las cuales son usadas para estimar el error predictivo. Para obtener una única predicción en cada observación, las B/3 predicciones son promediadas.</p>
</div>
</div>
<div id="bagging" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Bagging<a href="árboles-de-decisión.html#bagging" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Primero tenemos que definir qué es la <strong>Agregación de Bootstrap o Bagging</strong>. Este es un algoritmo de aprendizaje automático diseñado para mejorar la estabilidad y precisión de algoritmos de ML usados en clasificación estadística y regresión. Además reduce la varianza y ayuda a evitar el sobre-ajuste. Aunque es usualmente aplicado a métodos de árboles de decisión, puede ser usado con cualquier tipo de método. Bagging es un caso especial del promediado de modelos.</p>
<p><img src="img/09-ml-tree/bootstrap.svg" width="800pt" height="450pt" style="display: block; margin: auto;" /></p>
<p>Los métodos de <em>bagging</em> son métodos donde los algoritmos simples son usados en paralelo. El principal objetivo de los métodos en paralelo es el de aprovecharse de la independencia que hay entre los algoritmos simples, ya que el error se puede reducir bastante al promediar las salidas de los modelos simples. Es como si, queriendo resolver un problema entre varias personas independientes unas de otras, damos por bueno lo que eligiese la mayoría de las personas.</p>
<p>Para obtener la agregación de las salidas de cada modelo simple e independiente, bagging puede usar la votación para los métodos de clasificación y el promedio para los métodos de regresión.</p>
<p><img src="img/09-ml-tree/7-bag.png" width="500pt" height="300pt" style="display: block; margin: auto;" /></p>
<p>El <em>bagging o agregación bootstrap</em>, es un método de aprendizaje por conjuntos que se usa comúnmente para reducir la varianza dentro de un conjunto de datos ruidoso.</p>
</div>
<div id="random-forest" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Random Forest<a href="árboles-de-decisión.html#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un bosque aleatorio es un algoritmo de aprendizaje automático supervisado que se construye a partir de algoritmos de árbol de decisión. Este algoritmo se aplica en diversas industrias, como la banca y el comercio electrónico, para predecir el comportamiento y los resultados.</p>
<p>En esta clase se dará una descripción general del algoritmo de bosque aleatorio, cómo funciona y las características del algoritmo.</p>
<p>También se señalan las ventajas y desventajas de este algoritmo.</p>
<p><img src="img/09-ml-tree/bagging.jpeg" width="900pt" height="500pt" style="display: block; margin: auto;" /></p>
<div id="qué-es" class="section level3 hasAnchor" number="9.5.1">
<h3><span class="header-section-number">9.5.1</span> ¿Qué es?<a href="árboles-de-decisión.html#qué-es" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Un bosque aleatorio es una técnica de aprendizaje automático que se utiliza para resolver problemas de regresión y clasificación. Utiliza el aprendizaje por conjuntos, que es una técnica que combina muchos clasificadores para proporcionar soluciones a problemas complejos.</p>
<p>Este algoritmo consta de muchos árboles de decisión. El “bosque” generado se entrena
mediante <strong>agregación de bootstrap (bagging)</strong>, el cual es es un meta-algoritmo
de conjunto que mejora la precisión de los algoritmos de aprendizaje automático.</p>
<p>El algoritmo establece el resultado en función de las predicciones de los árboles de decisión. Predice tomando el promedio o la media de la salida de varios árboles. El aumento del número de árboles aumenta la precisión del resultado.</p>
<p>Un bosque aleatorio erradica las limitaciones de un algoritmo de árbol de decisión. Reduce el sobre-ajuste de conjuntos de datos y aumenta la precisión. Genera predicciones sin requerir muchas configuraciones.</p>
<p><img src="img/09-ml-tree/3-10-1-bosques-aleatorios.png" width="600pt" height="300pt" style="display: block; margin: auto;" /></p>
</div>
<div id="características-de-los-bosques-aleatorios" class="section level3 hasAnchor" number="9.5.2">
<h3><span class="header-section-number">9.5.2</span> Características de los bosques aleatorios<a href="árboles-de-decisión.html#características-de-los-bosques-aleatorios" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Es más preciso que el algoritmo árbol de decisiones.</p></li>
<li><p>Proporciona una forma eficaz de gestionar los datos faltantes.</p></li>
<li><p>Puede producir una predicción razonable sin ajuste de hiperparámetros.</p></li>
<li><p>Resuelve el problema del sobre-ajuste en los árboles de decisión.</p></li>
<li><p>En cada árbol forestal aleatorio, se selecciona aleatoriamente un subconjunto
de características en el punto de división del nodo.</p></li>
</ul>
</div>
<div id="aplicar-árboles-de-decisión-en-un-bosque-aleatorio" class="section level3 hasAnchor" number="9.5.3">
<h3><span class="header-section-number">9.5.3</span> Aplicar árboles de decisión en un bosque aleatorio<a href="árboles-de-decisión.html#aplicar-árboles-de-decisión-en-un-bosque-aleatorio" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La principal diferencia entre el algoritmo de árbol de decisión y el algoritmo de bosque aleatorio es que el establecimiento de nodos raíz y la desagregación de nodos se realiza de forma aleatoria en este último. <strong>El bosque aleatorio emplea el método de bagging para generar la predicción requerida.</strong></p>
<p><strong>El método bagging implica el uso de diferentes muestras de datos (datos de entrenamiento) en lugar de una sola muestra.</strong> Los árboles de decisión producen diferentes resultados, dependiendo de los datos de entrenamiento alimentados al algoritmo de bosque aleatorio.</p>
<p>Nuestro primer ejemplo todavía se puede utilizar para explicar cómo funcionan los bosques aleatorios. Supongamos que solo tenemos cuatro árboles de decisión. En este caso, los datos de entrenamiento que comprenden las observaciones y características de estudio se dividirán en cuatro nodos raíz. Supongamos que queremos modelar si un cliente compra o no compra un teléfono.</p>
<p>Los nodos raíz podrían representar cuatro características que podrían influir en la elección de un cliente (precio, almacenamiento interno, cámara y RAM). <strong>El bosque aleatorio dividirá los nodos seleccionando características al azar. La predicción final se seleccionará en función del resultado de los cuatro árboles.</strong></p>
<p><strong>El resultado elegido por la mayoría de los árboles de decisión será la elección final.</strong></p>
<p>Si tres árboles predicen la compra y un árbol predice que no comprará, entonces la predicción final será la compra. En este caso, se prevé que el cliente comprará.</p>
<p>El siguiente diagrama muestra un clasificador de bosque aleatorio simple.</p>
<p><img src="img/09-ml-tree/3-10-3-bosques-aleatorios-clasificador.png" width="600pt" height="300pt" style="display: block; margin: auto;" /></p>
<p><img src="img/09-ml-tree/3-13-1-randomforest.png" width="600pt" height="300pt" style="display: block; margin: auto;" /></p>
</div>
<div id="ventajas-y-desventjas-de-bosques-aleatorios" class="section level3 hasAnchor" number="9.5.4">
<h3><span class="header-section-number">9.5.4</span> Ventajas y desventjas de bosques aleatorios<a href="árboles-de-decisión.html#ventajas-y-desventjas-de-bosques-aleatorios" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Ventajas</strong></p>
<ul>
<li><p>Puede realizar tareas de regresión y clasificación.</p></li>
<li><p>Un bosque aleatorio produce buenas predicciones que se pueden entender fácilmente.</p></li>
<li><p>Puede manejar grandes conjuntos de datos de manera eficiente.</p></li>
<li><p>Proporciona un mayor nivel de precisión en la predicción de resultados sobre el algoritmo del árbol de decisión.</p></li>
</ul>
<p><strong>Desventajas</strong></p>
<ul>
<li><p>Cuando se usa un bosque aleatorio, se requieren bastantes recursos para el cálculo.</p></li>
<li><p>Consume más tiempo en comparación con un algoritmo de árbol de decisiones.</p></li>
<li><p>No producen buenos resultados cuando los datos son muy escasos. En este caso, el subconjunto de características y la muestra de arranque producirán un espacio invariante. Esto conducirá a divisiones improductivas, que afectarán el resultado.</p></li>
</ul>
</div>
</div>
<div id="implementación-en-r-3" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Implementación en R<a href="árboles-de-decisión.html#implementación-en-r-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="regresión-4" class="section level3 hasAnchor" number="9.6.1">
<h3><span class="header-section-number">9.6.1</span> Regresión<a href="árboles-de-decisión.html#regresión-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Paso 1: Separación inicial de datos ( test, train <KFCV> )</strong></p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="árboles-de-decisión.html#cb638-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb638-2"><a href="árboles-de-decisión.html#cb638-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb638-3"><a href="árboles-de-decisión.html#cb638-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(ames)</span>
<span id="cb638-4"><a href="árboles-de-decisión.html#cb638-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb638-5"><a href="árboles-de-decisión.html#cb638-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4595</span>)</span>
<span id="cb638-6"><a href="árboles-de-decisión.html#cb638-6" aria-hidden="true" tabindex="-1"></a>ames_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(ames, <span class="at">prop =</span> <span class="fl">0.75</span>)</span>
<span id="cb638-7"><a href="árboles-de-decisión.html#cb638-7" aria-hidden="true" tabindex="-1"></a>ames_train <span class="ot">&lt;-</span> <span class="fu">training</span>(ames_split)</span>
<span id="cb638-8"><a href="árboles-de-decisión.html#cb638-8" aria-hidden="true" tabindex="-1"></a>ames_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(ames_split)</span>
<span id="cb638-9"><a href="árboles-de-decisión.html#cb638-9" aria-hidden="true" tabindex="-1"></a>ames_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(ames_train)</span></code></pre></div>
<p>Contando con datos de entrenamiento, procedemos a realizar el feature engineering para extraer las mejores características que permitirán realizar las estimaciones en el modelo.</p>
<p><strong>Paso 2: Pre-procesamiento e ingeniería de variables</strong></p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="árboles-de-decisión.html#cb639-1" aria-hidden="true" tabindex="-1"></a>receta_casas <span class="ot">&lt;-</span> <span class="fu">recipe</span>(</span>
<span id="cb639-2"><a href="árboles-de-decisión.html#cb639-2" aria-hidden="true" tabindex="-1"></a> Sale_Price <span class="sc">~</span> Gr_Liv_Area <span class="sc">+</span> TotRms_AbvGrd <span class="sc">+</span> Exter_Cond <span class="sc">+</span> Bsmt_Cond <span class="sc">+</span></span>
<span id="cb639-3"><a href="árboles-de-decisión.html#cb639-3" aria-hidden="true" tabindex="-1"></a>  Year_Sold <span class="sc">+</span> Year_Remod_Add, </span>
<span id="cb639-4"><a href="árboles-de-decisión.html#cb639-4" aria-hidden="true" tabindex="-1"></a> <span class="at">data =</span> ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb639-5"><a href="árboles-de-decisión.html#cb639-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_mutate</span>(</span>
<span id="cb639-6"><a href="árboles-de-decisión.html#cb639-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">Age_House =</span> Year_Sold <span class="sc">-</span> Year_Remod_Add,</span>
<span id="cb639-7"><a href="árboles-de-decisión.html#cb639-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">Exter_Cond =</span> forcats<span class="sc">::</span><span class="fu">fct_collapse</span>(Exter_Cond, <span class="at">Good =</span> <span class="fu">c</span>(<span class="st">&quot;Typical&quot;</span>, <span class="st">&quot;Good&quot;</span>, <span class="st">&quot;Excellent&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb639-8"><a href="árboles-de-decisión.html#cb639-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_relevel</span>(Exter_Cond, <span class="at">ref_level =</span> <span class="st">&quot;Good&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb639-9"><a href="árboles-de-decisión.html#cb639-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb639-10"><a href="árboles-de-decisión.html#cb639-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb639-11"><a href="árboles-de-decisión.html#cb639-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_interact</span>(<span class="sc">~</span> <span class="fu">matches</span>(<span class="st">&quot;Bsmt_Cond&quot;</span>)<span class="sc">:</span>TotRms_AbvGrd) <span class="sc">%&gt;%</span> </span>
<span id="cb639-12"><a href="árboles-de-decisión.html#cb639-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb639-13"><a href="árboles-de-decisión.html#cb639-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb639-14"><a href="árboles-de-decisión.html#cb639-14" aria-hidden="true" tabindex="-1"></a>receta_casas</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          6
## 
## Training data contained 2197 data points and no missing data.
## 
## Operations:
## 
## Variable mutation for ~Year_Sold - Year_Remod_Add, ~forcats::fct... [trained]
## Re-order factor level to ref_level for Exter_Cond [trained]
## Centering and scaling for Gr_Liv_Area, TotRms_AbvGrd, Year_Sold, Year_Rem... [trained]
## Dummy variables from Exter_Cond, Bsmt_Cond [trained]
## Interactions with (Bsmt_Cond_Fair + Bsmt_Cond_Good + Bsmt_Cond_No_Ba... [trained]</code></pre>
<p>Recordemos que la función <strong>recipe()</strong> solo son los pasos a seguir, necesitamos usar la función <strong>prep()</strong> que nos devuelve una receta actualizada con las estimaciones y la función <strong>juice()</strong> que nos devuelve la matriz de diseño.</p>
<p>Una vez que la receta de transformación de datos está lista, procedemos a implementar el pipeline del modelo de interés.</p>
<p><strong>Paso 3: Selección de tipo de modelo con hiperparámetros iniciales</strong></p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb641-1"><a href="árboles-de-decisión.html#cb641-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;ranger&quot;)</span></span>
<span id="cb641-2"><a href="árboles-de-decisión.html#cb641-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb641-3"><a href="árboles-de-decisión.html#cb641-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb641-4"><a href="árboles-de-decisión.html#cb641-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb641-5"><a href="árboles-de-decisión.html#cb641-5" aria-hidden="true" tabindex="-1"></a>rforest_model <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(</span>
<span id="cb641-6"><a href="árboles-de-decisión.html#cb641-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>,</span>
<span id="cb641-7"><a href="árboles-de-decisión.html#cb641-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">1000</span>,</span>
<span id="cb641-8"><a href="árboles-de-decisión.html#cb641-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb641-9"><a href="árboles-de-decisión.html#cb641-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb641-10"><a href="árboles-de-decisión.html#cb641-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>, <span class="at">importance =</span> <span class="st">&quot;impurity&quot;</span>)</span></code></pre></div>
<p><strong>Paso 4: Inicialización de workflow o pipeline</strong></p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="árboles-de-decisión.html#cb642-1" aria-hidden="true" tabindex="-1"></a>rforest_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb642-2"><a href="árboles-de-decisión.html#cb642-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rforest_model) <span class="sc">%&gt;%</span></span>
<span id="cb642-3"><a href="árboles-de-decisión.html#cb642-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(receta_casas)</span></code></pre></div>
<p><strong>Paso 5: Creación de grid search</strong></p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb643-1"><a href="árboles-de-decisión.html#cb643-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">195628</span>)</span>
<span id="cb643-2"><a href="árboles-de-decisión.html#cb643-2" aria-hidden="true" tabindex="-1"></a>rforest_param_grid <span class="ot">&lt;-</span> <span class="fu">grid_random</span>(</span>
<span id="cb643-3"><a href="árboles-de-decisión.html#cb643-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtry</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">15</span>)),</span>
<span id="cb643-4"><a href="árboles-de-decisión.html#cb643-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">min_n</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">16</span>)),</span>
<span id="cb643-5"><a href="árboles-de-decisión.html#cb643-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">50</span></span>
<span id="cb643-6"><a href="árboles-de-decisión.html#cb643-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb643-7"><a href="árboles-de-decisión.html#cb643-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb643-8"><a href="árboles-de-decisión.html#cb643-8" aria-hidden="true" tabindex="-1"></a>ctrl_grid <span class="ot">&lt;-</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> T, <span class="at">verbose =</span> T)</span></code></pre></div>
<p><strong>Paso 6: Entrenamiento de modelos con hiperparámetros definidos</strong></p>
<div class="sourceCode" id="cb644"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb644-1"><a href="árboles-de-decisión.html#cb644-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb644-2"><a href="árboles-de-decisión.html#cb644-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb644-3"><a href="árboles-de-decisión.html#cb644-3" aria-hidden="true" tabindex="-1"></a>UseCores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb644-4"><a href="árboles-de-decisión.html#cb644-4" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(UseCores)</span>
<span id="cb644-5"><a href="árboles-de-decisión.html#cb644-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cluster)</span>
<span id="cb644-6"><a href="árboles-de-decisión.html#cb644-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb644-7"><a href="árboles-de-decisión.html#cb644-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajuste de parámetros</span></span>
<span id="cb644-8"><a href="árboles-de-decisión.html#cb644-8" aria-hidden="true" tabindex="-1"></a>rft1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb644-9"><a href="árboles-de-decisión.html#cb644-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb644-10"><a href="árboles-de-decisión.html#cb644-10" aria-hidden="true" tabindex="-1"></a>rforest_tune_result <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb644-11"><a href="árboles-de-decisión.html#cb644-11" aria-hidden="true" tabindex="-1"></a>  rforest_workflow,</span>
<span id="cb644-12"><a href="árboles-de-decisión.html#cb644-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> ames_folds,</span>
<span id="cb644-13"><a href="árboles-de-decisión.html#cb644-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> rforest_param_grid,</span>
<span id="cb644-14"><a href="árboles-de-decisión.html#cb644-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(rmse, rsq, mae),</span>
<span id="cb644-15"><a href="árboles-de-decisión.html#cb644-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> ctrl_grid</span>
<span id="cb644-16"><a href="árboles-de-decisión.html#cb644-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb644-17"><a href="árboles-de-decisión.html#cb644-17" aria-hidden="true" tabindex="-1"></a>rft2 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); rft2 <span class="sc">-</span> rft1</span>
<span id="cb644-18"><a href="árboles-de-decisión.html#cb644-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb644-19"><a href="árboles-de-decisión.html#cb644-19" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cluster)</span>
<span id="cb644-20"><a href="árboles-de-decisión.html#cb644-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb644-21"><a href="árboles-de-decisión.html#cb644-21" aria-hidden="true" tabindex="-1"></a>rforest_tune_result <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/random_forest_model_reg.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="árboles-de-decisión.html#cb645-1" aria-hidden="true" tabindex="-1"></a>rforest_tune_result <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/random_forest_model_reg.rds&quot;</span>)</span></code></pre></div>
<p><strong>Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)</strong></p>
<p>Podemos obtener las métricas de cada <em>fold</em> con el siguiente código:</p>
<div class="sourceCode" id="cb646"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb646-1"><a href="árboles-de-decisión.html#cb646-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(rforest_tune_result)</span></code></pre></div>
<pre><code>## # A tibble: 132 × 8
##     mtry min_n .metric .estimator      mean     n   std_err .config             
##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;               
##  1    11    11 mae     standard   28160.       10  560.     Preprocessor1_Model…
##  2    11    11 rmse    standard   42133.       10 1126.     Preprocessor1_Model…
##  3    11    11 rsq     standard       0.721    10    0.0116 Preprocessor1_Model…
##  4    11    13 mae     standard   28139.       10  556.     Preprocessor1_Model…
##  5    11    13 rmse    standard   42183.       10 1118.     Preprocessor1_Model…
##  6    11    13 rsq     standard       0.720    10    0.0114 Preprocessor1_Model…
##  7     7     3 mae     standard   28054.       10  576.     Preprocessor1_Model…
##  8     7     3 rmse    standard   41511.       10 1145.     Preprocessor1_Model…
##  9     7     3 rsq     standard       0.728    10    0.0115 Preprocessor1_Model…
## 10     9    16 mae     standard   27991.       10  568.     Preprocessor1_Model…
## # … with 122 more rows</code></pre>
<p>En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos:</p>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="árboles-de-decisión.html#cb648-1" aria-hidden="true" tabindex="-1"></a>rforest_tune_result <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-472-1.png" width="672" /></p>
<p>En la siguiente gráfica observamos el error cuadrático medio de las distintas métricas con distintos números de vecinos.</p>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="árboles-de-decisión.html#cb649-1" aria-hidden="true" tabindex="-1"></a>rforest_tune_result <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>(<span class="at">metric =</span> <span class="st">&quot;rsq&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-473-1.png" width="672" /></p>
<div class="sourceCode" id="cb650"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb650-1"><a href="árboles-de-decisión.html#cb650-1" aria-hidden="true" tabindex="-1"></a>multiparams_plot <span class="ot">&lt;-</span> rforest_tune_result <span class="sc">%&gt;%</span> </span>
<span id="cb650-2"><a href="árboles-de-decisión.html#cb650-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">collect_metrics</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb650-3"><a href="árboles-de-decisión.html#cb650-3" aria-hidden="true" tabindex="-1"></a> <span class="fu">filter</span>(.metric <span class="sc">==</span> <span class="st">&quot;rmse&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb650-4"><a href="árboles-de-decisión.html#cb650-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">rename</span>(<span class="at">rmse =</span> mean) <span class="sc">%&gt;%</span> </span>
<span id="cb650-5"><a href="árboles-de-decisión.html#cb650-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mtry, <span class="at">y =</span> min_n, <span class="at">colour =</span> rmse)) <span class="sc">+</span></span>
<span id="cb650-6"><a href="árboles-de-decisión.html#cb650-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb650-7"><a href="árboles-de-decisión.html#cb650-7" aria-hidden="true" tabindex="-1"></a> <span class="fu">scale_color_gradientn</span>(<span class="at">colours =</span> <span class="fu">rainbow</span>(<span class="dv">7</span>)) <span class="sc">+</span></span>
<span id="cb650-8"><a href="árboles-de-decisión.html#cb650-8" aria-hidden="true" tabindex="-1"></a> <span class="fu">labs</span>(</span>
<span id="cb650-9"><a href="árboles-de-decisión.html#cb650-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">title =</span> <span class="st">&quot;Análisis de R^2 mediante ajuste de hiperparámetros&quot;</span>,</span>
<span id="cb650-10"><a href="árboles-de-decisión.html#cb650-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> <span class="st">&quot;Número de ramas&quot;</span>,</span>
<span id="cb650-11"><a href="árboles-de-decisión.html#cb650-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> <span class="st">&quot;Mínimo de elementos por nodo&quot;</span></span>
<span id="cb650-12"><a href="árboles-de-decisión.html#cb650-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb650-13"><a href="árboles-de-decisión.html#cb650-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb650-14"><a href="árboles-de-decisión.html#cb650-14" aria-hidden="true" tabindex="-1"></a>plotly<span class="sc">::</span><span class="fu">ggplotly</span>(multiparams_plot)</span></code></pre></div>
<div id="htmlwidget-a793f3174aa545d636f9" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-a793f3174aa545d636f9">{"x":{"data":[{"x":[11,11,7,9,3,5,6,3,11,6,14,3,13,5,12,3,4,8,2,4,13,8,12,10,15,14,4,10,11,3,5,10,8,6,3,11,2,2,10,14,8,8,13,14],"y":[11,13,3,16,15,16,10,9,4,9,7,13,11,6,2,4,7,7,15,10,4,12,7,16,12,14,12,6,7,6,7,11,4,8,10,5,5,4,13,4,3,16,9,8],"text":["mtry: 11<br />min_n: 11<br />rmse: 42132.58","mtry: 11<br />min_n: 13<br />rmse: 42183.47","mtry:  7<br />min_n:  3<br />rmse: 41510.86","mtry:  9<br />min_n: 16<br />rmse: 41868.90","mtry:  3<br />min_n: 15<br />rmse: 44531.65","mtry:  5<br />min_n: 16<br />rmse: 41889.60","mtry:  6<br />min_n: 10<br />rmse: 41447.47","mtry:  3<br />min_n:  9<br />rmse: 44395.12","mtry: 11<br />min_n:  4<br />rmse: 42165.73","mtry:  6<br />min_n:  9<br />rmse: 41569.48","mtry: 14<br />min_n:  7<br />rmse: 42512.84","mtry:  3<br />min_n: 13<br />rmse: 44480.97","mtry: 13<br />min_n: 11<br />rmse: 42418.91","mtry:  5<br />min_n:  6<br />rmse: 41525.47","mtry: 12<br />min_n:  2<br />rmse: 42315.79","mtry:  3<br />min_n:  4<br />rmse: 44227.95","mtry:  4<br />min_n:  7<br />rmse: 42296.75","mtry:  8<br />min_n:  7<br />rmse: 41708.25","mtry:  2<br />min_n: 15<br />rmse: 49622.69","mtry:  4<br />min_n: 10<br />rmse: 42334.51","mtry: 13<br />min_n:  4<br />rmse: 42397.58","mtry:  8<br />min_n: 12<br />rmse: 41718.16","mtry: 12<br />min_n:  7<br />rmse: 42255.93","mtry: 10<br />min_n: 16<br />rmse: 41996.77","mtry: 15<br />min_n: 12<br />rmse: 42698.56","mtry: 14<br />min_n: 14<br />rmse: 42549.37","mtry:  4<br />min_n: 12<br />rmse: 42434.90","mtry: 10<br />min_n:  6<br />rmse: 41990.31","mtry: 11<br />min_n:  7<br />rmse: 42071.64","mtry:  3<br />min_n:  6<br />rmse: 44304.18","mtry:  5<br />min_n:  7<br />rmse: 41551.37","mtry: 10<br />min_n: 11<br />rmse: 42040.63","mtry:  8<br />min_n:  4<br />rmse: 41711.26","mtry:  6<br />min_n:  8<br />rmse: 41536.95","mtry:  3<br />min_n: 10<br />rmse: 44420.13","mtry: 11<br />min_n:  5<br />rmse: 42047.60","mtry:  2<br />min_n:  5<br />rmse: 49399.32","mtry:  2<br />min_n:  4<br />rmse: 49535.02","mtry: 10<br />min_n: 13<br />rmse: 42064.91","mtry: 14<br />min_n:  4<br />rmse: 42606.89","mtry:  8<br />min_n:  3<br />rmse: 41727.17","mtry:  8<br />min_n: 16<br />rmse: 41850.42","mtry: 13<br />min_n:  9<br />rmse: 42434.40","mtry: 14<br />min_n:  8<br />rmse: 42515.50"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":["rgba(255,142,0,1)","rgba(255,148,0,1)","rgba(255,37,0,1)","rgba(255,108,0,1)","rgba(68,255,66,1)","rgba(255,111,0,1)","rgba(255,0,0,1)","rgba(71,255,51,1)","rgba(255,146,0,1)","rgba(255,54,0,1)","rgba(255,186,0,1)","rgba(69,255,61,1)","rgba(255,176,0,1)","rgba(255,42,0,1)","rgba(255,164,0,1)","rgba(73,255,21,1)","rgba(255,162,0,1)","rgba(255,83,0,1)","rgba(255,0,219,1)","rgba(255,166,0,1)","rgba(255,173,0,1)","rgba(255,84,0,1)","rgba(255,157,0,1)","rgba(255,125,0,1)","rgba(255,207,0,1)","rgba(255,191,0,1)","rgba(255,178,0,1)","rgba(255,124,0,1)","rgba(255,135,0,1)","rgba(72,255,37,1)","rgba(255,50,0,1)","rgba(255,131,0,1)","rgba(255,83,0,1)","rgba(255,46,0,1)","rgba(70,255,54,1)","rgba(255,132,0,1)","rgba(233,0,225,1)","rgba(246,0,221,1)","rgba(255,134,0,1)","rgba(255,197,0,1)","rgba(255,86,0,1)","rgba(255,105,0,1)","rgba(255,178,0,1)","rgba(255,187,0,1)"],"opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":["rgba(255,142,0,1)","rgba(255,148,0,1)","rgba(255,37,0,1)","rgba(255,108,0,1)","rgba(68,255,66,1)","rgba(255,111,0,1)","rgba(255,0,0,1)","rgba(71,255,51,1)","rgba(255,146,0,1)","rgba(255,54,0,1)","rgba(255,186,0,1)","rgba(69,255,61,1)","rgba(255,176,0,1)","rgba(255,42,0,1)","rgba(255,164,0,1)","rgba(73,255,21,1)","rgba(255,162,0,1)","rgba(255,83,0,1)","rgba(255,0,219,1)","rgba(255,166,0,1)","rgba(255,173,0,1)","rgba(255,84,0,1)","rgba(255,157,0,1)","rgba(255,125,0,1)","rgba(255,207,0,1)","rgba(255,191,0,1)","rgba(255,178,0,1)","rgba(255,124,0,1)","rgba(255,135,0,1)","rgba(72,255,37,1)","rgba(255,50,0,1)","rgba(255,131,0,1)","rgba(255,83,0,1)","rgba(255,46,0,1)","rgba(70,255,54,1)","rgba(255,132,0,1)","rgba(233,0,225,1)","rgba(246,0,221,1)","rgba(255,134,0,1)","rgba(255,197,0,1)","rgba(255,86,0,1)","rgba(255,105,0,1)","rgba(255,178,0,1)","rgba(255,187,0,1)"]}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[4],"y":[4],"name":"99_92b9a2caab5e4eb590c62358c3b235e8","type":"scatter","mode":"markers","opacity":0,"hoverinfo":"skip","showlegend":false,"marker":{"color":[0,1],"colorscale":[[0,"#FF0000"],[0.00334448160535082,"#FF1600"],[0.00668896321070253,"#FF2200"],[0.0100334448160533,"#FF2C00"],[0.0133779264214051,"#FF3300"],[0.0167224080267559,"#FF3A00"],[0.0200668896321067,"#FF4000"],[0.0234113712374584,"#FF4600"],[0.0267558528428092,"#FF4B00"],[0.0301003344481609,"#FF5000"],[0.0334448160535118,"#FF5500"],[0.0367892976588626,"#FF5900"],[0.0401337792642143,"#FF5E00"],[0.0434782608695651,"#FF6200"],[0.0468227424749168,"#FF6600"],[0.0501672240802676,"#FF6A00"],[0.0535117056856185,"#FF6E00"],[0.0568561872909702,"#FF7200"],[0.060200668896321,"#FF7500"],[0.0635451505016727,"#FF7900"],[0.0668896321070235,"#FF7D00"],[0.0702341137123743,"#FF8000"],[0.073578595317726,"#FF8400"],[0.0769230769230769,"#FF8700"],[0.0802675585284277,"#FF8B00"],[0.0836120401337794,"#FF8E00"],[0.0869565217391302,"#FF9100"],[0.0903010033444819,"#FF9500"],[0.0936454849498327,"#FF9800"],[0.0969899665551835,"#FF9B00"],[0.100334448160535,"#FF9E00"],[0.103678929765886,"#FFA200"],[0.107023411371238,"#FFA500"],[0.110367892976589,"#FFA800"],[0.113712374581939,"#FFAB00"],[0.117056856187291,"#FFAE00"],[0.120401337792642,"#FFB100"],[0.123745819397994,"#FFB400"],[0.127090301003344,"#FFB800"],[0.130434782608695,"#FFBB00"],[0.133779264214047,"#FFBE00"],[0.137123745819398,"#FFC100"],[0.14046822742475,"#FFC400"],[0.1438127090301,"#FFC700"],[0.147157190635451,"#FFCA00"],[0.150501672240803,"#FFCD00"],[0.153846153846154,"#FFD000"],[0.157190635451505,"#FFD300"],[0.160535117056856,"#FFD600"],[0.163879598662207,"#FFD900"],[0.167224080267559,"#FFDB00"],[0.17056856187291,"#FCDC00"],[0.17391304347826,"#FADD00"],[0.177257525083612,"#F7DE00"],[0.180602006688963,"#F5DF00"],[0.183946488294315,"#F2E000"],[0.187290969899665,"#EFE100"],[0.190635451505016,"#EDE100"],[0.193979933110368,"#EAE200"],[0.197324414715719,"#E8E300"],[0.200668896321071,"#E5E400"],[0.204013377926421,"#E2E500"],[0.207357859531772,"#DFE600"],[0.210702341137124,"#DDE600"],[0.214046822742475,"#DAE700"],[0.217391304347826,"#D7E800"],[0.220735785953177,"#D4E900"],[0.224080267558528,"#D1EA00"],[0.22742474916388,"#CFEA00"],[0.230769230769231,"#CCEB00"],[0.234113712374582,"#C9EC00"],[0.237458193979933,"#C6ED00"],[0.240802675585284,"#C3ED00"],[0.244147157190636,"#C0EE00"],[0.247491638795986,"#BDEF00"],[0.250836120401338,"#B9F000"],[0.254180602006689,"#B6F000"],[0.25752508361204,"#B3F100"],[0.260869565217392,"#B0F200"],[0.264214046822742,"#ACF200"],[0.267558528428094,"#A9F300"],[0.270903010033445,"#A5F400"],[0.274247491638796,"#A2F400"],[0.277591973244147,"#9EF500"],[0.280936454849498,"#9AF600"],[0.28428093645485,"#97F600"],[0.287625418060201,"#93F700"],[0.290969899665552,"#8FF800"],[0.294314381270903,"#8AF800"],[0.297658862876254,"#86F900"],[0.301003344481606,"#82F900"],[0.304347826086957,"#7DFA00"],[0.307692307692307,"#78FB00"],[0.311036789297659,"#73FB00"],[0.31438127090301,"#6EFC00"],[0.317725752508362,"#69FC00"],[0.321070234113712,"#63FD00"],[0.324414715719063,"#5DFE00"],[0.327759197324415,"#56FE00"],[0.331103678929766,"#4EFF00"],[0.334448160535117,"#49FF04"],[0.337792642140468,"#49FF10"],[0.341137123745819,"#48FF17"],[0.344481605351171,"#48FF1E"],[0.347826086956522,"#48FF23"],[0.351170568561873,"#48FF28"],[0.354515050167224,"#47FF2C"],[0.357859531772575,"#47FF30"],[0.361204013377927,"#47FF33"],[0.364548494983278,"#46FF37"],[0.367892976588628,"#46FF3A"],[0.37123745819398,"#45FF3D"],[0.374581939799331,"#45FF40"],[0.377926421404683,"#44FF43"],[0.381270903010033,"#44FF46"],[0.384615384615384,"#43FF48"],[0.387959866220736,"#43FF4B"],[0.391304347826087,"#42FF4E"],[0.394648829431439,"#41FF50"],[0.397993311036789,"#41FF53"],[0.40133779264214,"#40FF55"],[0.404682274247492,"#3FFF57"],[0.408026755852843,"#3FFF5A"],[0.411371237458193,"#3EFF5C"],[0.414715719063545,"#3DFF5E"],[0.418060200668896,"#3CFF61"],[0.421404682274248,"#3BFF63"],[0.424749163879599,"#3AFF65"],[0.428093645484949,"#39FF67"],[0.431438127090301,"#38FF69"],[0.434782608695652,"#37FF6B"],[0.438127090301004,"#36FF6E"],[0.441471571906354,"#35FF70"],[0.444816053511705,"#33FF72"],[0.448160535117057,"#32FF74"],[0.451505016722408,"#30FF76"],[0.45484949832776,"#2FFF78"],[0.45819397993311,"#2DFF7A"],[0.461538461538461,"#2BFF7C"],[0.464882943143813,"#2AFF7E"],[0.468227424749164,"#28FF80"],[0.471571906354515,"#25FF82"],[0.474916387959866,"#23FF84"],[0.478260869565217,"#20FF86"],[0.481605351170569,"#1DFF88"],[0.48494983277592,"#1AFF89"],[0.488294314381271,"#16FF8B"],[0.491638795986622,"#12FF8D"],[0.494983277591973,"#0CFF8F"],[0.498327759197325,"#04FF91"],[0.501672240802675,"#09FE93"],[0.505016722408027,"#16FC96"],[0.508361204013378,"#1EF998"],[0.511705685618729,"#24F79B"],[0.51505016722408,"#29F59D"],[0.518394648829431,"#2DF3A0"],[0.521739130434783,"#31F1A2"],[0.525083612040134,"#34EEA5"],[0.528428093645485,"#37ECA7"],[0.531772575250836,"#39EAAA"],[0.535117056856187,"#3CE8AC"],[0.538461538461539,"#3EE5AE"],[0.54180602006689,"#3FE3B1"],[0.545150501672241,"#41E1B3"],[0.548494983277592,"#42DFB5"],[0.551839464882943,"#44DDB7"],[0.555183946488295,"#45DABA"],[0.558528428093646,"#46D8BC"],[0.561872909698996,"#46D6BE"],[0.565217391304348,"#47D4C0"],[0.568561872909699,"#48D2C2"],[0.571906354515051,"#48CFC5"],[0.575250836120401,"#48CDC7"],[0.578595317725752,"#49CBC9"],[0.581939799331104,"#49C9CB"],[0.585284280936455,"#49C7CD"],[0.588628762541807,"#48C4CF"],[0.591973244147157,"#48C2D1"],[0.595317725752508,"#48C0D4"],[0.59866220735786,"#47BED6"],[0.602006688963211,"#47BCD8"],[0.605351170568561,"#46BADA"],[0.608695652173913,"#45B7DC"],[0.612040133779264,"#44B5DE"],[0.615384615384616,"#43B3E0"],[0.618729096989967,"#41B1E2"],[0.622073578595317,"#40AFE4"],[0.625418060200669,"#3EADE6"],[0.62876254180602,"#3CAAE8"],[0.632107023411372,"#3AA8EA"],[0.635451505016722,"#38A6EC"],[0.638795986622073,"#35A4EE"],[0.642140468227425,"#33A2F0"],[0.645484949832776,"#2FA0F2"],[0.648829431438127,"#2C9DF4"],[0.652173913043478,"#279BF6"],[0.655518394648829,"#2299F8"],[0.658862876254181,"#1C97FA"],[0.662207357859532,"#1395FC"],[0.665551839464882,"#0693FE"],[0.668896321070234,"#0791FF"],[0.672240802675585,"#108FFF"],[0.675585284280937,"#168DFF"],[0.678929765886288,"#1B8BFF"],[0.682274247491638,"#2089FF"],[0.68561872909699,"#2387FF"],[0.688963210702341,"#2685FF"],[0.692307692307693,"#2983FF"],[0.695652173913043,"#2C81FF"],[0.698996655518394,"#2E7FFF"],[0.702341137123746,"#307DFF"],[0.705685618729097,"#327AFF"],[0.709030100334448,"#3478FF"],[0.712374581939799,"#3576FF"],[0.71571906354515,"#3774FF"],[0.719063545150502,"#3872FF"],[0.722408026755853,"#3A70FF"],[0.725752508361204,"#3B6EFF"],[0.729096989966555,"#3C6CFF"],[0.732441471571906,"#3D6AFF"],[0.735785953177258,"#3F67FF"],[0.739130434782609,"#4065FF"],[0.74247491638796,"#4063FF"],[0.745819397993311,"#4161FF"],[0.749163879598662,"#425EFF"],[0.752508361204014,"#435CFF"],[0.755852842809364,"#445AFF"],[0.759197324414716,"#4457FF"],[0.762541806020067,"#4555FF"],[0.765886287625418,"#4553FF"],[0.769230769230769,"#4650FF"],[0.77257525083612,"#464EFF"],[0.775919732441472,"#474BFF"],[0.779264214046823,"#4748FF"],[0.782608695652174,"#4846FF"],[0.785953177257525,"#4843FF"],[0.789297658862876,"#4840FF"],[0.792642140468228,"#493DFF"],[0.795986622073579,"#493AFF"],[0.799331103678929,"#4937FF"],[0.802675585284281,"#4934FF"],[0.806020066889632,"#4931FF"],[0.809364548494984,"#492DFF"],[0.812709030100335,"#4929FF"],[0.816053511705685,"#4925FF"],[0.819397993311037,"#4920FF"],[0.822742474916388,"#491BFF"],[0.82608695652174,"#4915FF"],[0.82943143812709,"#490DFF"],[0.832775919732441,"#4902FF"],[0.836120401337793,"#4F00FE"],[0.839464882943144,"#5600FE"],[0.842809364548495,"#5C00FD"],[0.846153846153846,"#6200FC"],[0.849498327759197,"#6800FC"],[0.852842809364549,"#6D00FB"],[0.8561872909699,"#7200FA"],[0.85953177257525,"#7700F9"],[0.862876254180602,"#7C00F9"],[0.866220735785953,"#8000F8"],[0.869565217391305,"#8400F7"],[0.872909698996655,"#8900F7"],[0.876254180602006,"#8D00F6"],[0.879598662207358,"#9100F5"],[0.882943143812709,"#9500F4"],[0.88628762541806,"#9800F4"],[0.889632107023411,"#9C00F3"],[0.892976588628762,"#A000F2"],[0.896321070234114,"#A300F2"],[0.899665551839465,"#A700F1"],[0.903010033444816,"#AA00F0"],[0.906354515050167,"#AE00EF"],[0.909698996655518,"#B100EF"],[0.91304347826087,"#B400EE"],[0.916387959866221,"#B700ED"],[0.919732441471571,"#BB00ED"],[0.923076923076923,"#BE00EC"],[0.926421404682274,"#C100EB"],[0.929765886287626,"#C400EA"],[0.933110367892977,"#C700EA"],[0.936454849498327,"#CA00E9"],[0.939799331103679,"#CD00E8"],[0.94314381270903,"#D000E8"],[0.946488294314382,"#D300E7"],[0.949832775919732,"#D600E6"],[0.953177257525083,"#D900E5"],[0.956521739130435,"#DC00E5"],[0.959866220735786,"#DE00E4"],[0.963210702341137,"#E100E3"],[0.966555183946488,"#E400E2"],[0.969899665551839,"#E700E2"],[0.973244147157191,"#EA00E1"],[0.976588628762542,"#EC00E0"],[0.979933110367893,"#EF00DF"],[0.983277591973244,"#F200DF"],[0.986622073578595,"#F400DE"],[0.989966555183947,"#F700DD"],[0.993311036789297,"#FA00DC"],[0.996655518394649,"#FC00DC"],[1,"#FF00DB"]],"colorbar":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"thickness":23.04,"title":"rmse","titlefont":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"tickmode":"array","ticktext":["42000","44000","46000","48000"],"tickvals":[0.0675862461919513,0.312227977961061,0.556869709730171,0.801511441499281],"tickfont":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895},"ticklen":2,"len":0.5}},"xaxis":"x","yaxis":"y","frame":null}],"layout":{"margin":{"t":43.7625570776256,"r":7.30593607305936,"b":40.1826484018265,"l":37.2602739726027},"plot_bgcolor":"rgba(235,235,235,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"title":{"text":"Análisis de R^2 mediante ajuste de hiperparámetros","font":{"color":"rgba(0,0,0,1)","family":"","size":17.5342465753425},"x":0,"xref":"paper"},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[1.35,15.65],"tickmode":"array","ticktext":["4","8","12"],"tickvals":[4,8,12],"categoryorder":"array","categoryarray":["4","8","12"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"Número de ramas","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[1.3,16.7],"tickmode":"array","ticktext":["4","8","12","16"],"tickvals":[4,8,12,16],"categoryorder":"array","categoryarray":["4","8","12","16"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"Mínimo de elementos por nodo","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895},"title":{"text":"","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"source":"A","attrs":{"4641624403078":{"x":{},"y":{},"colour":{},"type":"scatter"}},"cur_data":"4641624403078","visdat":{"4641624403078":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p>En la gráfica anterior, se aprecia la distribución conjunta de hiperparámetros y su resultados en la <span class="math inline">\(R^2\)</span>. De esta forma, se puede tomar una mejor decisión sobre el subconjunto óptimo de hiperparámetros a seleccionar.</p>
<p><strong>Paso 8: Selección de modelo a usar</strong></p>
<p>Con el siguiente código obtenemos los mejores 10 modelos respecto al <em>rmse</em>.</p>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="árboles-de-decisión.html#cb651-1" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(rforest_tune_result, <span class="at">n =</span> <span class="dv">10</span>, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 8
##     mtry min_n .metric .estimator   mean     n std_err .config              
##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
##  1     6    10 rmse    standard   41447.    10   1156. Preprocessor1_Model07
##  2     7     3 rmse    standard   41511.    10   1145. Preprocessor1_Model03
##  3     5     6 rmse    standard   41525.    10   1259. Preprocessor1_Model14
##  4     6     8 rmse    standard   41537.    10   1201. Preprocessor1_Model34
##  5     5     7 rmse    standard   41551.    10   1259. Preprocessor1_Model31
##  6     6     9 rmse    standard   41569.    10   1195. Preprocessor1_Model10
##  7     8     7 rmse    standard   41708.    10   1151. Preprocessor1_Model18
##  8     8     4 rmse    standard   41711.    10   1124. Preprocessor1_Model33
##  9     8    12 rmse    standard   41718.    10   1138. Preprocessor1_Model22
## 10     8     3 rmse    standard   41727.    10   1143. Preprocessor1_Model41</code></pre>
<p>Ahora obtendremos el modelo que mejor desempeño tiene tomando en cuenta el <em>rmse</em> y haremos las predicciones del conjunto de prueba con este modelo.</p>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="árboles-de-decisión.html#cb653-1" aria-hidden="true" tabindex="-1"></a>best_rforest_model <span class="ot">&lt;-</span> <span class="fu">select_best</span>(rforest_tune_result, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb653-2"><a href="árboles-de-decisión.html#cb653-2" aria-hidden="true" tabindex="-1"></a>best_rforest_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##    mtry min_n .config              
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
## 1     6    10 Preprocessor1_Model07</code></pre>
<p><strong>Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)</strong></p>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="árboles-de-decisión.html#cb655-1" aria-hidden="true" tabindex="-1"></a>final_rforest_model <span class="ot">&lt;-</span> rforest_workflow <span class="sc">%&gt;%</span></span>
<span id="cb655-2"><a href="árboles-de-decisión.html#cb655-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(best_rforest_model) <span class="sc">%&gt;%</span></span>
<span id="cb655-3"><a href="árboles-de-decisión.html#cb655-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> ames_train)</span></code></pre></div>
<p>Este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.</p>
<p>Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos <a href="https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba">data leakage</a>. Para enfrentar esto, ayuda estimar y ordenar el valor de importancia de cada variable en el modelo.</p>
<div class="sourceCode" id="cb656"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb656-1"><a href="árboles-de-decisión.html#cb656-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vip)</span>
<span id="cb656-2"><a href="árboles-de-decisión.html#cb656-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb656-3"><a href="árboles-de-decisión.html#cb656-3" aria-hidden="true" tabindex="-1"></a>final_rforest_model <span class="sc">%&gt;%</span> </span>
<span id="cb656-4"><a href="árboles-de-decisión.html#cb656-4" aria-hidden="true" tabindex="-1"></a> <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb656-5"><a href="árboles-de-decisión.html#cb656-5" aria-hidden="true" tabindex="-1"></a> <span class="fu">vip</span>(<span class="at">geom =</span> <span class="st">&quot;col&quot;</span>) <span class="sc">+</span> </span>
<span id="cb656-6"><a href="árboles-de-decisión.html#cb656-6" aria-hidden="true" tabindex="-1"></a> <span class="fu">ggtitle</span>(<span class="st">&quot;Importancia de las variables&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-478-1.png" width="672" /></p>
<p><strong>Paso 10: Validar poder predictivo con datos de prueba</strong></p>
<p>Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos:</p>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="árboles-de-decisión.html#cb657-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_rforest_model, ames_test) <span class="sc">%&gt;%</span></span>
<span id="cb657-2"><a href="árboles-de-decisión.html#cb657-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">bind_cols</span>(<span class="at">Sale_Price =</span> ames_test<span class="sc">$</span>Sale_Price) <span class="sc">%&gt;%</span></span>
<span id="cb657-3"><a href="árboles-de-decisión.html#cb657-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="at">pred_rforest_reg =</span> .pred)</span>
<span id="cb657-4"><a href="árboles-de-decisión.html#cb657-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb657-5"><a href="árboles-de-decisión.html#cb657-5" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<pre><code>## # A tibble: 733 × 2
##    pred_rforest_reg Sale_Price
##               &lt;dbl&gt;      &lt;int&gt;
##  1          115022.     105000
##  2          164222.     185000
##  3          175564.     180400
##  4          100135.     141000
##  5          211380.     210000
##  6          201731.     216000
##  7          150731.     149900
##  8          124723.     105500
##  9          124723.      88000
## 10          156835.     146000
## # … with 723 more rows</code></pre>
<p><strong>Métricas de desempeño</strong></p>
<p>Ahora para calcular las métricas de desempeño usaremos la paquetería <em>MLmetrics</em>. Es posible definir nuestro propio conjunto de métricas que deseamos reportar creando el objeto <em>metric_set</em>:</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="árboles-de-decisión.html#cb659-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MLmetrics)</span>
<span id="cb659-2"><a href="árboles-de-decisión.html#cb659-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb659-3"><a href="árboles-de-decisión.html#cb659-3" aria-hidden="true" tabindex="-1"></a>multi_metric <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(mae, mape, rmse, rsq, ccc)</span>
<span id="cb659-4"><a href="árboles-de-decisión.html#cb659-4" aria-hidden="true" tabindex="-1"></a><span class="fu">multi_metric</span>(results, <span class="at">truth =</span> Sale_Price, <span class="at">estimate =</span> pred_rforest_reg) <span class="sc">%&gt;%</span> </span>
<span id="cb659-5"><a href="árboles-de-decisión.html#cb659-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">.estimate =</span> <span class="fu">round</span>(.estimate, <span class="dv">2</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb659-6"><a href="árboles-de-decisión.html#cb659-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>.estimator)</span></code></pre></div>
<pre><code>## # A tibble: 5 × 2
##   .metric .estimate
##   &lt;chr&gt;       &lt;dbl&gt;
## 1 mae      28848   
## 2 mape        17.0 
## 3 rmse     42780.  
## 4 rsq          0.72
## 5 ccc          0.83</code></pre>
<div class="sourceCode" id="cb661"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb661-1"><a href="árboles-de-decisión.html#cb661-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb661-2"><a href="árboles-de-decisión.html#cb661-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> pred_rforest_reg, <span class="at">y =</span> Sale_Price)) <span class="sc">+</span></span>
<span id="cb661-3"><a href="árboles-de-decisión.html#cb661-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb661-4"><a href="árboles-de-decisión.html#cb661-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb661-5"><a href="árboles-de-decisión.html#cb661-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Prediction&quot;</span>) <span class="sc">+</span></span>
<span id="cb661-6"><a href="árboles-de-decisión.html#cb661-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Observation&quot;</span>) <span class="sc">+</span></span>
<span id="cb661-7"><a href="árboles-de-decisión.html#cb661-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Comparisson&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-481-1.png" width="672" /></p>
</div>
<div id="clasificación-5" class="section level3 hasAnchor" number="9.6.2">
<h3><span class="header-section-number">9.6.2</span> Clasificación<a href="árboles-de-decisión.html#clasificación-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Es turno de revisar la implementación de <em>Random Forest</em> con nuestro bien conocido problema de predicción de cancelación de servicios de telecomunicaciones. Los datos se encuentran disponibles en el siguiente <a href="https://drive.google.com/drive/folders/1mlDGHvUy-81qfvQi_iB7tqMb9yhy3vyh?usp=sharing">enlace</a>:</p>
<p>Los pasos para implementar en <em>R</em> este modelo predictivo son los mismos, cambiando únicamente las especificaciones del tipo de modelo, pre-procesamiento e hiper-parámetros.</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="árboles-de-decisión.html#cb662-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb662-2"><a href="árboles-de-decisión.html#cb662-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb662-3"><a href="árboles-de-decisión.html#cb662-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb662-4"><a href="árboles-de-decisión.html#cb662-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb662-5"><a href="árboles-de-decisión.html#cb662-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tidymodels_prefer</span>()</span>
<span id="cb662-6"><a href="árboles-de-decisión.html#cb662-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb662-7"><a href="árboles-de-decisión.html#cb662-7" aria-hidden="true" tabindex="-1"></a>telco <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/Churn.csv&quot;</span>)</span>
<span id="cb662-8"><a href="árboles-de-decisión.html#cb662-8" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(telco)</span></code></pre></div>
<pre><code>## Rows: 7,043
## Columns: 21
## $ customerID       &lt;chr&gt; &quot;7590-VHVEG&quot;, &quot;5575-GNVDE&quot;, &quot;3668-QPYBK&quot;, &quot;7795-CFOCW…
## $ gender           &lt;chr&gt; &quot;Female&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;,…
## $ SeniorCitizen    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ Partner          &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes…
## $ Dependents       &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;…
## $ tenure           &lt;dbl&gt; 1, 34, 2, 45, 2, 8, 22, 10, 28, 62, 13, 16, 58, 49, 2…
## $ PhoneService     &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, …
## $ MultipleLines    &lt;chr&gt; &quot;No phone service&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No phone service&quot;, &quot;…
## $ InternetService  &lt;chr&gt; &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;DSL&quot;, &quot;Fiber optic&quot;, &quot;Fiber opt…
## $ OnlineSecurity   &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;…
## $ OnlineBackup     &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;N…
## $ DeviceProtection &lt;chr&gt; &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Y…
## $ TechSupport      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes…
## $ StreamingTV      &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Ye…
## $ StreamingMovies  &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes…
## $ Contract         &lt;chr&gt; &quot;Month-to-month&quot;, &quot;One year&quot;, &quot;Month-to-month&quot;, &quot;One …
## $ PaperlessBilling &lt;chr&gt; &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, …
## $ PaymentMethod    &lt;chr&gt; &quot;Electronic check&quot;, &quot;Mailed check&quot;, &quot;Mailed check&quot;, &quot;…
## $ MonthlyCharges   &lt;dbl&gt; 29.85, 56.95, 53.85, 42.30, 70.70, 99.65, 89.10, 29.7…
## $ TotalCharges     &lt;dbl&gt; 29.85, 1889.50, 108.15, 1840.75, 151.65, 820.50, 1949…
## $ Churn            &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Y…</code></pre>
<p><strong>Paso 1: Separación inicial de datos ( test, train <KFCV> )</strong></p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="árboles-de-decisión.html#cb664-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb664-2"><a href="árboles-de-decisión.html#cb664-2" aria-hidden="true" tabindex="-1"></a>telco_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(telco, <span class="at">prop =</span> .<span class="dv">70</span>)</span>
<span id="cb664-3"><a href="árboles-de-decisión.html#cb664-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-4"><a href="árboles-de-decisión.html#cb664-4" aria-hidden="true" tabindex="-1"></a>telco_train <span class="ot">&lt;-</span> <span class="fu">training</span>(telco_split)</span>
<span id="cb664-5"><a href="árboles-de-decisión.html#cb664-5" aria-hidden="true" tabindex="-1"></a>telco_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(telco_split)</span>
<span id="cb664-6"><a href="árboles-de-decisión.html#cb664-6" aria-hidden="true" tabindex="-1"></a>telco_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(telco_train)</span>
<span id="cb664-7"><a href="árboles-de-decisión.html#cb664-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb664-8"><a href="árboles-de-decisión.html#cb664-8" aria-hidden="true" tabindex="-1"></a>telco_folds</span></code></pre></div>
<pre><code>## #  10-fold cross-validation 
## # A tibble: 10 × 2
##    splits             id    
##    &lt;list&gt;             &lt;chr&gt; 
##  1 &lt;split [4437/493]&gt; Fold01
##  2 &lt;split [4437/493]&gt; Fold02
##  3 &lt;split [4437/493]&gt; Fold03
##  4 &lt;split [4437/493]&gt; Fold04
##  5 &lt;split [4437/493]&gt; Fold05
##  6 &lt;split [4437/493]&gt; Fold06
##  7 &lt;split [4437/493]&gt; Fold07
##  8 &lt;split [4437/493]&gt; Fold08
##  9 &lt;split [4437/493]&gt; Fold09
## 10 &lt;split [4437/493]&gt; Fold10</code></pre>
<p><strong>Paso 2: Pre-procesamiento e ingeniería de variables</strong></p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="árboles-de-decisión.html#cb666-1" aria-hidden="true" tabindex="-1"></a>telco_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(</span>
<span id="cb666-2"><a href="árboles-de-decisión.html#cb666-2" aria-hidden="true" tabindex="-1"></a>  Churn <span class="sc">~</span> customerID <span class="sc">+</span> TotalCharges <span class="sc">+</span> MonthlyCharges <span class="sc">+</span> SeniorCitizen <span class="sc">+</span> Contract, </span>
<span id="cb666-3"><a href="árboles-de-decisión.html#cb666-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> telco_train) <span class="sc">%&gt;%</span> </span>
<span id="cb666-4"><a href="árboles-de-decisión.html#cb666-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(customerID, <span class="at">new_role =</span> <span class="st">&quot;id variable&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb666-5"><a href="árboles-de-decisión.html#cb666-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_mutate</span>(<span class="at">Contract =</span> <span class="fu">as.factor</span>(Contract)) <span class="sc">%&gt;%</span> </span>
<span id="cb666-6"><a href="árboles-de-decisión.html#cb666-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_impute_median</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb666-7"><a href="árboles-de-decisión.html#cb666-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb666-8"><a href="árboles-de-decisión.html#cb666-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb666-9"><a href="árboles-de-decisión.html#cb666-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb666-10"><a href="árboles-de-decisión.html#cb666-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb666-11"><a href="árboles-de-decisión.html#cb666-11" aria-hidden="true" tabindex="-1"></a>telco_rec</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##         role #variables
##  id variable          1
##      outcome          1
##    predictor          4
## 
## Training data contained 4930 data points and 10 incomplete rows. 
## 
## Operations:
## 
## Variable mutation for ~as.factor(Contract) [trained]
## Median imputation for TotalCharges, MonthlyCharges, SeniorCitizen [trained]
## Centering and scaling for TotalCharges, MonthlyCharges, SeniorCitizen [trained]
## Dummy variables from Contract [trained]</code></pre>
<p><strong>Paso 3: Selección de tipo de modelo con hiperparámetros iniciales</strong></p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="árboles-de-decisión.html#cb668-1" aria-hidden="true" tabindex="-1"></a>rforest_model <span class="ot">&lt;-</span> <span class="fu">rand_forest</span>(</span>
<span id="cb668-2"><a href="árboles-de-decisión.html#cb668-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb668-3"><a href="árboles-de-decisión.html#cb668-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">1000</span>,</span>
<span id="cb668-4"><a href="árboles-de-decisión.html#cb668-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb668-5"><a href="árboles-de-decisión.html#cb668-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_n =</span> <span class="fu">tune</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb668-6"><a href="árboles-de-decisión.html#cb668-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;ranger&quot;</span>, <span class="at">importance =</span> <span class="st">&quot;impurity&quot;</span>)</span>
<span id="cb668-7"><a href="árboles-de-decisión.html#cb668-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb668-8"><a href="árboles-de-decisión.html#cb668-8" aria-hidden="true" tabindex="-1"></a>rforest_model</span></code></pre></div>
<pre><code>## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 1000
##   min_n = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: ranger</code></pre>
<p><strong>Paso 4: Inicialización de workflow o pipeline</strong></p>
<div class="sourceCode" id="cb670"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb670-1"><a href="árboles-de-decisión.html#cb670-1" aria-hidden="true" tabindex="-1"></a>rforest_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb670-2"><a href="árboles-de-decisión.html#cb670-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(telco_rec) <span class="sc">%&gt;%</span> </span>
<span id="cb670-3"><a href="árboles-de-decisión.html#cb670-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(rforest_model)</span>
<span id="cb670-4"><a href="árboles-de-decisión.html#cb670-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb670-5"><a href="árboles-de-decisión.html#cb670-5" aria-hidden="true" tabindex="-1"></a>rforest_workflow</span></code></pre></div>
<pre><code>## ══ Workflow ═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: rand_forest()
## 
## ── Preprocessor ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## • step_mutate()
## • step_impute_median()
## • step_normalize()
## • step_dummy()
## 
## ── Model ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Random Forest Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 1000
##   min_n = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: ranger</code></pre>
<p><strong>Paso 5: Creación de grid search</strong></p>
<div class="sourceCode" id="cb672"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb672-1"><a href="árboles-de-decisión.html#cb672-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">195628</span>)</span>
<span id="cb672-2"><a href="árboles-de-decisión.html#cb672-2" aria-hidden="true" tabindex="-1"></a>rforest_param_grid <span class="ot">&lt;-</span> <span class="fu">grid_random</span>(</span>
<span id="cb672-3"><a href="árboles-de-decisión.html#cb672-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtry</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">5</span>)),</span>
<span id="cb672-4"><a href="árboles-de-decisión.html#cb672-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">min_n</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">16</span>)),</span>
<span id="cb672-5"><a href="árboles-de-decisión.html#cb672-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">20</span></span>
<span id="cb672-6"><a href="árboles-de-decisión.html#cb672-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb672-7"><a href="árboles-de-decisión.html#cb672-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb672-8"><a href="árboles-de-decisión.html#cb672-8" aria-hidden="true" tabindex="-1"></a>ctrl_grid <span class="ot">&lt;-</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> T, <span class="at">verbose =</span> T)</span></code></pre></div>
<p><strong>Paso 6: Entrenamiento de modelos con hiperparámetros definidos</strong></p>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="árboles-de-decisión.html#cb673-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb673-2"><a href="árboles-de-decisión.html#cb673-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-3"><a href="árboles-de-decisión.html#cb673-3" aria-hidden="true" tabindex="-1"></a>UseCores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb673-4"><a href="árboles-de-decisión.html#cb673-4" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(UseCores)</span>
<span id="cb673-5"><a href="árboles-de-decisión.html#cb673-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cluster)</span>
<span id="cb673-6"><a href="árboles-de-decisión.html#cb673-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-7"><a href="árboles-de-decisión.html#cb673-7" aria-hidden="true" tabindex="-1"></a>rft1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb673-8"><a href="árboles-de-decisión.html#cb673-8" aria-hidden="true" tabindex="-1"></a>rf_tune_result <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb673-9"><a href="árboles-de-decisión.html#cb673-9" aria-hidden="true" tabindex="-1"></a>  rforest_workflow,</span>
<span id="cb673-10"><a href="árboles-de-decisión.html#cb673-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> telco_folds,</span>
<span id="cb673-11"><a href="árboles-de-decisión.html#cb673-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> rforest_param_grid,</span>
<span id="cb673-12"><a href="árboles-de-decisión.html#cb673-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(roc_auc, pr_auc),</span>
<span id="cb673-13"><a href="árboles-de-decisión.html#cb673-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> ctrl_grid</span>
<span id="cb673-14"><a href="árboles-de-decisión.html#cb673-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb673-15"><a href="árboles-de-decisión.html#cb673-15" aria-hidden="true" tabindex="-1"></a>rft2 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); rft2 <span class="sc">-</span> rft1</span>
<span id="cb673-16"><a href="árboles-de-decisión.html#cb673-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-17"><a href="árboles-de-decisión.html#cb673-17" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cluster)</span>
<span id="cb673-18"><a href="árboles-de-decisión.html#cb673-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb673-19"><a href="árboles-de-decisión.html#cb673-19" aria-hidden="true" tabindex="-1"></a>rf_tune_result <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/rforest_model_cla.rds&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb674"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb674-1"><a href="árboles-de-decisión.html#cb674-1" aria-hidden="true" tabindex="-1"></a>rf_tune_result <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/rforest_model_cla.rds&quot;</span>)</span></code></pre></div>
<p><strong>Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)</strong></p>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="árboles-de-decisión.html#cb675-1" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(rf_tune_result)</span></code></pre></div>
<pre><code>## # A tibble: 34 × 8
##     mtry min_n .metric .estimator  mean     n std_err .config              
##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
##  1     3    16 pr_auc  binary     0.930    10 0.00372 Preprocessor1_Model01
##  2     3    16 roc_auc binary     0.825    10 0.00623 Preprocessor1_Model01
##  3     3     8 pr_auc  binary     0.929    10 0.00385 Preprocessor1_Model02
##  4     3     8 roc_auc binary     0.822    10 0.00635 Preprocessor1_Model02
##  5     3     2 pr_auc  binary     0.927    10 0.00378 Preprocessor1_Model03
##  6     3     2 roc_auc binary     0.818    10 0.00653 Preprocessor1_Model03
##  7     5     4 pr_auc  binary     0.921    10 0.00359 Preprocessor1_Model04
##  8     5     4 roc_auc binary     0.802    10 0.00682 Preprocessor1_Model04
##  9     3    13 pr_auc  binary     0.929    10 0.00397 Preprocessor1_Model05
## 10     3    13 roc_auc binary     0.824    10 0.00640 Preprocessor1_Model05
## # … with 24 more rows</code></pre>
<p>En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="árboles-de-decisión.html#cb677-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(rf_tune_result, <span class="at">metric =</span> <span class="st">&quot;pr_auc&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-491-1.png" width="672" /></p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="árboles-de-decisión.html#cb678-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(rf_tune_result, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-492-1.png" width="672" /></p>
<div class="sourceCode" id="cb679"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb679-1"><a href="árboles-de-decisión.html#cb679-1" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(rf_tune_result, <span class="at">n =</span> <span class="dv">10</span>, <span class="at">metric =</span> <span class="st">&quot;pr_auc&quot;</span>)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 8
##     mtry min_n .metric .estimator  mean     n std_err .config              
##    &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                
##  1     2    10 pr_auc  binary     0.934    10 0.00363 Preprocessor1_Model08
##  2     2     3 pr_auc  binary     0.934    10 0.00375 Preprocessor1_Model12
##  3     3    15 pr_auc  binary     0.930    10 0.00374 Preprocessor1_Model09
##  4     3    16 pr_auc  binary     0.930    10 0.00372 Preprocessor1_Model01
##  5     3    13 pr_auc  binary     0.929    10 0.00397 Preprocessor1_Model05
##  6     3     8 pr_auc  binary     0.929    10 0.00385 Preprocessor1_Model02
##  7     3     2 pr_auc  binary     0.927    10 0.00378 Preprocessor1_Model03
##  8     3     4 pr_auc  binary     0.927    10 0.00396 Preprocessor1_Model11
##  9     5    14 pr_auc  binary     0.925    10 0.00353 Preprocessor1_Model10
## 10     4    12 pr_auc  binary     0.924    10 0.00367 Preprocessor1_Model07</code></pre>
<p><strong>Paso 8: Selección de modelo a usar</strong></p>
<div class="sourceCode" id="cb681"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb681-1"><a href="árboles-de-decisión.html#cb681-1" aria-hidden="true" tabindex="-1"></a>best_rf_model_cla <span class="ot">&lt;-</span> <span class="fu">select_best</span>(rf_tune_result, <span class="at">metric =</span> <span class="st">&quot;pr_auc&quot;</span>)</span>
<span id="cb681-2"><a href="árboles-de-decisión.html#cb681-2" aria-hidden="true" tabindex="-1"></a>best_rf_model_cla</span></code></pre></div>
<pre><code>## # A tibble: 1 × 3
##    mtry min_n .config              
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;                
## 1     2    10 Preprocessor1_Model08</code></pre>
<div class="sourceCode" id="cb683"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb683-1"><a href="árboles-de-decisión.html#cb683-1" aria-hidden="true" tabindex="-1"></a>rf_classification_best_1se_model <span class="ot">&lt;-</span> rf_tune_result <span class="sc">%&gt;%</span> </span>
<span id="cb683-2"><a href="árboles-de-decisión.html#cb683-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select_by_one_std_err</span>(<span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>, <span class="st">&quot;roc_auc&quot;</span>)</span>
<span id="cb683-3"><a href="árboles-de-decisión.html#cb683-3" aria-hidden="true" tabindex="-1"></a>rf_classification_best_1se_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 10
##    mtry min_n .metric .estimator  mean     n std_err .config        .best .bound
##   &lt;int&gt; &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;
## 1     2    10 roc_auc binary     0.836    10 0.00624 Preprocessor1… 0.836  0.830</code></pre>
<p><strong>Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)</strong></p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="árboles-de-decisión.html#cb685-1" aria-hidden="true" tabindex="-1"></a>final_rf_model_cla <span class="ot">&lt;-</span> rforest_workflow <span class="sc">%&gt;%</span> </span>
<span id="cb685-2"><a href="árboles-de-decisión.html#cb685-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(best_rf_model_cla) <span class="sc">%&gt;%</span> </span>
<span id="cb685-3"><a href="árboles-de-decisión.html#cb685-3" aria-hidden="true" tabindex="-1"></a>  parsnip<span class="sc">::</span><span class="fu">fit</span>(<span class="at">data =</span> telco_train)</span></code></pre></div>
<p>Este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.</p>
<p>Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos <a href="https://towardsdatascience.com/data-leakage-in-machine-learning-6161c167e8ba">data leakage</a>. Para enfrentar esto, ayuda estimar y ordenar el valor de importancia del modelo.</p>
<p>Después de entrenar un modelo, es natural preguntarse qué variables tienen el mayor poder predictivo. Las variables de gran importancia son impulsoras del resultado y sus valores tienen un impacto significativo en los valores del resultado. Por el contrario, las variables con poca importancia pueden omitirse de un modelo, lo que lo hace más simple y rápido de ajustar y predecir.</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="árboles-de-decisión.html#cb686-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vip)</span>
<span id="cb686-2"><a href="árboles-de-decisión.html#cb686-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb686-3"><a href="árboles-de-decisión.html#cb686-3" aria-hidden="true" tabindex="-1"></a>final_rf_model_cla <span class="sc">%&gt;%</span></span>
<span id="cb686-4"><a href="árboles-de-decisión.html#cb686-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb686-5"><a href="árboles-de-decisión.html#cb686-5" aria-hidden="true" tabindex="-1"></a>  vip<span class="sc">::</span><span class="fu">vip</span>() <span class="sc">+</span> </span>
<span id="cb686-6"><a href="árboles-de-decisión.html#cb686-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Importancia de las variables&quot;</span>)<span class="sc">+</span> </span>
<span id="cb686-7"><a href="árboles-de-decisión.html#cb686-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-496-1.png" width="672" /></p>
<p><strong>Paso 10: Validar poder predictivo con datos de prueba</strong></p>
<p>Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos:</p>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb687-1"><a href="árboles-de-decisión.html#cb687-1" aria-hidden="true" tabindex="-1"></a>results_cla <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_rf_model_cla, telco_test, <span class="at">type =</span> <span class="st">&#39;prob&#39;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb687-2"><a href="árboles-de-decisión.html#cb687-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">bind_cols</span>(<span class="at">Churn =</span> telco_test<span class="sc">$</span>Churn, .) <span class="sc">%&gt;%</span> </span>
<span id="cb687-3"><a href="árboles-de-decisión.html#cb687-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Churn =</span> <span class="fu">factor</span>(Churn, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>)))</span>
<span id="cb687-4"><a href="árboles-de-decisión.html#cb687-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb687-5"><a href="árboles-de-decisión.html#cb687-5" aria-hidden="true" tabindex="-1"></a>results_cla</span></code></pre></div>
<pre><code>## # A tibble: 2,113 × 3
##    Churn .pred_No .pred_Yes
##    &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;
##  1 No       0.936    0.0636
##  2 Yes      0.373    0.627 
##  3 No       0.635    0.365 
##  4 No       0.982    0.0176
##  5 No       0.905    0.0955
##  6 No       0.576    0.424 
##  7 No       0.973    0.0268
##  8 No       0.776    0.224 
##  9 Yes      0.551    0.449 
## 10 No       0.982    0.0183
## # … with 2,103 more rows</code></pre>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb689-1"><a href="árboles-de-decisión.html#cb689-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_rows</span>(</span>
<span id="cb689-2"><a href="árboles-de-decisión.html#cb689-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_auc</span>(results_cla, <span class="at">truth =</span> Churn, <span class="at">estimate =</span> .pred_Yes),</span>
<span id="cb689-3"><a href="árboles-de-decisión.html#cb689-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pr_auc</span>(results_cla, <span class="at">truth =</span> Churn, <span class="at">estimate =</span> .pred_Yes)</span>
<span id="cb689-4"><a href="árboles-de-decisión.html#cb689-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.838
## 2 pr_auc  binary         0.644</code></pre>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb691-1"><a href="árboles-de-decisión.html#cb691-1" aria-hidden="true" tabindex="-1"></a>pr_curve_data <span class="ot">&lt;-</span> <span class="fu">pr_curve</span>(</span>
<span id="cb691-2"><a href="árboles-de-decisión.html#cb691-2" aria-hidden="true" tabindex="-1"></a>  results_cla, </span>
<span id="cb691-3"><a href="árboles-de-decisión.html#cb691-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> Churn, </span>
<span id="cb691-4"><a href="árboles-de-decisión.html#cb691-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_Yes</span>
<span id="cb691-5"><a href="árboles-de-decisión.html#cb691-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb691-6"><a href="árboles-de-decisión.html#cb691-6" aria-hidden="true" tabindex="-1"></a>pr_curve_data</span></code></pre></div>
<pre><code>## # A tibble: 1,945 × 3
##    .threshold  recall precision
##         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;
##  1    Inf     0           1    
##  2      0.855 0.00177     1    
##  3      0.855 0.00353     1    
##  4      0.851 0.00530     1    
##  5      0.822 0.00707     1    
##  6      0.821 0.00707     0.8  
##  7      0.821 0.00883     0.833
##  8      0.816 0.0106      0.857
##  9      0.813 0.0124      0.875
## 10      0.809 0.0141      0.889
## # … with 1,935 more rows</code></pre>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="árboles-de-decisión.html#cb693-1" aria-hidden="true" tabindex="-1"></a>roc_curve_data <span class="ot">&lt;-</span> <span class="fu">roc_curve</span>(</span>
<span id="cb693-2"><a href="árboles-de-decisión.html#cb693-2" aria-hidden="true" tabindex="-1"></a>  results_cla, </span>
<span id="cb693-3"><a href="árboles-de-decisión.html#cb693-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> Churn, </span>
<span id="cb693-4"><a href="árboles-de-decisión.html#cb693-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_Yes</span>
<span id="cb693-5"><a href="árboles-de-decisión.html#cb693-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb693-6"><a href="árboles-de-decisión.html#cb693-6" aria-hidden="true" tabindex="-1"></a>roc_curve_data</span></code></pre></div>
<pre><code>## # A tibble: 1,946 × 3
##    .threshold specificity sensitivity
##         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1 -Inf           0                 1
##  2    0.00646     0                 1
##  3    0.00647     0.00259           1
##  4    0.00648     0.00323           1
##  5    0.00649     0.00582           1
##  6    0.00652     0.0200            1
##  7    0.00653     0.0297            1
##  8    0.00656     0.0304            1
##  9    0.00659     0.0310            1
## 10    0.00661     0.0323            1
## # … with 1,936 more rows</code></pre>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="árboles-de-decisión.html#cb695-1" aria-hidden="true" tabindex="-1"></a>pr_curve_plot <span class="ot">&lt;-</span> pr_curve_data <span class="sc">%&gt;%</span> </span>
<span id="cb695-2"><a href="árboles-de-decisión.html#cb695-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> recall, <span class="at">y =</span> precision)) <span class="sc">+</span></span>
<span id="cb695-3"><a href="árboles-de-decisión.html#cb695-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb695-4"><a href="árboles-de-decisión.html#cb695-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>, <span class="at">colour =</span> <span class="st">&#39;lightblue&#39;</span>) <span class="sc">+</span></span>
<span id="cb695-5"><a href="árboles-de-decisión.html#cb695-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb695-6"><a href="árboles-de-decisión.html#cb695-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb695-7"><a href="árboles-de-decisión.html#cb695-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Precision vs Recall&quot;</span>)<span class="sc">+</span></span>
<span id="cb695-8"><a href="árboles-de-decisión.html#cb695-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb695-9"><a href="árboles-de-decisión.html#cb695-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb695-10"><a href="árboles-de-decisión.html#cb695-10" aria-hidden="true" tabindex="-1"></a>pr_curve_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-499-1.png" width="672" /></p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="árboles-de-decisión.html#cb696-1" aria-hidden="true" tabindex="-1"></a>roc_curve_plot <span class="ot">&lt;-</span> roc_curve_data <span class="sc">%&gt;%</span> </span>
<span id="cb696-2"><a href="árboles-de-decisión.html#cb696-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificity, <span class="at">y =</span> sensitivity)) <span class="sc">+</span></span>
<span id="cb696-3"><a href="árboles-de-decisión.html#cb696-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>, <span class="at">colour =</span> <span class="st">&#39;lightblue&#39;</span>) <span class="sc">+</span></span>
<span id="cb696-4"><a href="árboles-de-decisión.html#cb696-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>() <span class="sc">+</span></span>
<span id="cb696-5"><a href="árboles-de-decisión.html#cb696-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb696-6"><a href="árboles-de-decisión.html#cb696-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROC Curve&quot;</span>)<span class="sc">+</span></span>
<span id="cb696-7"><a href="árboles-de-decisión.html#cb696-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb696-8"><a href="árboles-de-decisión.html#cb696-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb696-9"><a href="árboles-de-decisión.html#cb696-9" aria-hidden="true" tabindex="-1"></a>roc_curve_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-499-2.png" width="672" /></p>
<p>Pueden usar la app de <a href="https://acturio.shinyapps.io/confusion_matrix/?_ga=2.157345976.322506426.1653670259-130075619.1646374742">shiny</a> que nos permite jugar con el threshold de clasificación para tomar la mejor decisión.</p>
</div>
</div>
<div id="boosting" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Boosting<a href="árboles-de-decisión.html#boosting" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Tradicionalmente, la construcción de una aplicación de aprendizaje automático consistía en tomar un solo estimador, es decir:</p>
<ul>
<li>Un regresor logístico</li>
<li>Un árbol de decisión</li>
<li>Una red neuronal artificial</li>
<li>Un conjunto de vecinos cercanos</li>
</ul>
<p>Para posteriormente ser entrenado por un conjunto de datos.</p>
<p>Luego nacieron los <strong>métodos de conjunto</strong>, los cuales pueden describirse como <strong>técnicas que utilizan un grupo de modelos “débiles” juntos, con el fin de crear uno más fuerte y agregado</strong>.</p>
<p>El <em>Boosting</em> consiste en la idea de filtrar o <strong>ponderar los datos</strong> que se utilizan para capacitar a nuestro conjunto de modelos “débiles”, para que <strong>cada nuevo modelo pondere o “solo se entrene” con observaciones que han sido mal clasificadas por los anteriores modelos.</strong></p>
<p><img src="img/09-ml-tree/boosting2.png" width="800pt" height="400pt" style="display: block; margin: auto;" /></p>
<p>Al hacer esto, nuestro conjunto de modelos aprende a hacer predicciones precisas sobre todo tipo de datos, no solo sobre las observaciones más comunes o fáciles. Además, si uno de los modelos individuales es muy malo para hacer predicciones sobre algún tipo de observación, no importa, ya que los otros <span class="math inline">\(N - 1\)</span> modelos probablemente lo compensarán.</p>
<p><img src="img/09-ml-tree/boosting.png" width="600pt" height="250pt" style="display: block; margin: auto;" /></p>
<p>Como se puede ver en la imagen anterior, en <em>boosting</em> el conjunto de datos se pondera (representado por los diferentes tamaños de los datos), de modo que las observaciones que fueron clasificadas incorrectamente por el clasificador <span class="math inline">\(n\)</span> reciben más importancia en el entrenamiento del modelo <span class="math inline">\(n + 1\)</span>. En general, <strong>los métodos de conjunto reducen el sesgo y la varianza de nuestros modelos de aprendizaje automático</strong>.</p>
<div class="infobox note">
<p><strong>¡¡ RECORDAR !!</strong></p>
<p>Los modelos bootstrap buscan aprender lentamente patrones relevantes a lo largo de muchas iteraciones, de forma que se vaya haciendo un ajuste lento pero preciso.</p>
</div>
<p>El proceso de entrenamiento depende del algoritmo <em>boosting</em> que estemos usando <em>(Adaboost, LigthGBM, XGBoost, <span class="math inline">\(\dots\)</span>)</em>, pero generalmente sigue este patrón:</p>
<ol style="list-style-type: decimal">
<li><p>Todas las muestras de datos comienzan con los mismos pesos. Estas muestras se utilizan para entrenar un modelo individual (digamos un árbol de decisión).</p></li>
<li><p>Se calcula el error de predicción para cada muestra, <strong>aumentando los pesos de aquellas muestras que han tenido un error mayor</strong>, para hacerlas más importantes para el entrenamiento del siguiente modelo individual.</p></li>
<li><p>Dependiendo de qué tan bien le fue a este modelo individual en sus predicciones, se le asigna una importancia/peso.</p></li>
<li><p>Los datos ponderados se pasan al modelo posterior y se repiten lo pasos 2) y 3). Este paso se repite hasta que se haya alcanzado un cierto número de modelos o hasta que el error esté por debajo de un cierto umbral.</p></li>
</ol>
<p><img src="img/09-ml-tree/boosting-training.png" width="600pt" height="350pt" style="display: block; margin: auto;" /></p>
<p>En algunos casos, los modelos de <em>boosting</em> se entrenan con un peso fijo específico para cada modelo (llamado tasa de aprendizaje) y en lugar de dar a cada muestra un peso individual, los modelos se entrenan tratando de predecir las diferencias entre las predicciones anteriores en las muestras y los valores reales de la variable objetivo. Esta diferencia es conocida como residuales.</p>
<p>La forma de ajustar el modelo sigue los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li><p>Se fija <span class="math inline">\(\hat{f}(x)=0\)</span> y <span class="math inline">\(r_i=y_i\)</span> para todos los elementos del conjunto de entrenamiento</p></li>
<li><p>Para <span class="math inline">\(b=1,2,...,B\)</span>, repetir:</p></li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Ajustar un árbol <span class="math inline">\(\hat{f}^b\)</span> al conjunto de entrenamiento <span class="math inline">\((X, r)\)</span></p></li>
<li><p>Actualizar el ajuste <span class="math inline">\(\hat{f}(x)\)</span> al añadir una nueva versión restringida de un nuevo árbol:</p></li>
</ol>
<p><span class="math display">\[\hat{F}_b(X) \leftarrow \hat{F}_{b-1}(X) + \alpha_b\hat{h}_b(X, r_{b-1})\]</span>
c) Actualizar los residuos:</p>
<p><span class="math display">\[r_b \leftarrow r_{b-1} - \alpha_b\hat{f}^b(x_i)\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Resultado del modelo <em>Boosting</em>:</li>
</ol>
<p><span class="math display">\[\hat{F}=\sum_{b=1}^{B}\alpha_b\hat{F}_b(x)\]</span>
Para calcular <span class="math inline">\(\alpha_b\)</span> en cada iteración, se usa la siguiente fórmula:</p>
<p><span class="math display">\[\underset{\alpha}{\operatorname{argmin}}=\sum_{i=1}^{b}{L(Y_i, \hat{F}_{i-1}(X_i)+\alpha \hat{h}_i(X_i, r_{i-1}))}\]</span>
Donde <span class="math inline">\(L(Y, F(X))\)</span> es una función de pérdida diferenciable.</p>
<div id="predicciones-boosting" class="section level3 hasAnchor" number="9.7.1">
<h3><span class="header-section-number">9.7.1</span> Predicciones <em>Boosting</em><a href="árboles-de-decisión.html#predicciones-boosting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La forma en que un modelo de <em>boosting</em> hace predicciones sobre nuevos datos es muy simple. Cuando obtenemos una nueva observación con sus características, se pasa a través de cada uno de los modelos individuales, haciendo que cada modelo haga su propia predicción.</p>
<p>Luego, teniendo en cuenta el peso de cada uno de estos modelos, todas estas predicciones se escalan y combinan, y se da una predicción global final.</p>
<p><img src="img/09-ml-tree/boosting-predicciones.png" width="610pt" height="350pt" style="display: block; margin: auto;" /></p>
</div>
<div id="modelos-boosting" class="section level3 hasAnchor" number="9.7.2">
<h3><span class="header-section-number">9.7.2</span> Modelos <em>Boosting</em><a href="árboles-de-decisión.html#modelos-boosting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>XGBoost</strong></p>
<p>Abreviatura de <em>eXtreme Gradient Boosting</em>, como en <em>Gradient Boosting</em>, ajustamos los árboles a los residuos de las predicciones de árboles anteriores, sin embargo, en lugar de usar árboles de decisión de tamaño fijo convencionales, <strong><em>XGBoost</em> usa un tipo diferente de árboles</strong>.</p>
<p>Estos árboles se construyen calculando puntuaciones de similitud entre las observaciones que terminan en un nodo de salida. Además, <em>XGBoost</em> permite la regularización, reduciendo el posible sobre-ajuste de nuestros árboles individuales y, por lo tanto, del modelo de conjunto general.</p>
<p>Por último, <em>XGBoost</em> está optimizado para superar el límite de los recursos computacionales de los algoritmos de árbol impulsados, lo que lo convierte en un algoritmo rápido y de muy alto rendimiento en términos de tiempo y cálculo.</p>
<p><img src="img/09-ml-tree/sequential_trees.png" width="800pt" height="400pt" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="implementación-de-xgb-en-r" class="section level2 hasAnchor" number="9.8">
<h2><span class="header-section-number">9.8</span> Implementación de XGB en R<a href="árboles-de-decisión.html#implementación-de-xgb-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="xgboost-para-regresión" class="section level3 hasAnchor" number="9.8.1">
<h3><span class="header-section-number">9.8.1</span> XGBoost para regresión<a href="árboles-de-decisión.html#xgboost-para-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Paso 1: Separación inicial de datos (test, train)</strong></p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="árboles-de-decisión.html#cb697-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidymodels)</span>
<span id="cb697-2"><a href="árboles-de-decisión.html#cb697-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb697-3"><a href="árboles-de-decisión.html#cb697-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(ames)</span>
<span id="cb697-4"><a href="árboles-de-decisión.html#cb697-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb697-5"><a href="árboles-de-decisión.html#cb697-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4595</span>)</span>
<span id="cb697-6"><a href="árboles-de-decisión.html#cb697-6" aria-hidden="true" tabindex="-1"></a>ames_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(ames, <span class="at">prop =</span> <span class="fl">0.75</span>)</span>
<span id="cb697-7"><a href="árboles-de-decisión.html#cb697-7" aria-hidden="true" tabindex="-1"></a>ames_train <span class="ot">&lt;-</span> <span class="fu">training</span>(ames_split)</span>
<span id="cb697-8"><a href="árboles-de-decisión.html#cb697-8" aria-hidden="true" tabindex="-1"></a>ames_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(ames_split)</span>
<span id="cb697-9"><a href="árboles-de-decisión.html#cb697-9" aria-hidden="true" tabindex="-1"></a>ames_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(ames_train)</span></code></pre></div>
<p>Contando con datos de entrenamiento, procedemos a realizar el feature engineering para extraer las mejores características que permitirán realizar las estimaciones en el modelo.</p>
<p><strong>Paso 2: Pre-procesamiento e ingeniería de variables</strong></p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="árboles-de-decisión.html#cb698-1" aria-hidden="true" tabindex="-1"></a>receta_casas <span class="ot">&lt;-</span> <span class="fu">recipe</span>(</span>
<span id="cb698-2"><a href="árboles-de-decisión.html#cb698-2" aria-hidden="true" tabindex="-1"></a> Sale_Price <span class="sc">~</span> Gr_Liv_Area <span class="sc">+</span> TotRms_AbvGrd <span class="sc">+</span> Exter_Cond <span class="sc">+</span> Bsmt_Cond <span class="sc">+</span></span>
<span id="cb698-3"><a href="árboles-de-decisión.html#cb698-3" aria-hidden="true" tabindex="-1"></a>  Year_Sold <span class="sc">+</span> Year_Remod_Add, </span>
<span id="cb698-4"><a href="árboles-de-decisión.html#cb698-4" aria-hidden="true" tabindex="-1"></a> <span class="at">data =</span> ames_train) <span class="sc">%&gt;%</span></span>
<span id="cb698-5"><a href="árboles-de-decisión.html#cb698-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_mutate</span>(</span>
<span id="cb698-6"><a href="árboles-de-decisión.html#cb698-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">Age_House =</span> Year_Sold <span class="sc">-</span> Year_Remod_Add,</span>
<span id="cb698-7"><a href="árboles-de-decisión.html#cb698-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">Exter_Cond =</span> forcats<span class="sc">::</span><span class="fu">fct_collapse</span>(Exter_Cond, <span class="at">Good =</span> <span class="fu">c</span>(<span class="st">&quot;Typical&quot;</span>, <span class="st">&quot;Good&quot;</span>, <span class="st">&quot;Excellent&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb698-8"><a href="árboles-de-decisión.html#cb698-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_relevel</span>(Exter_Cond, <span class="at">ref_level =</span> <span class="st">&quot;Good&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb698-9"><a href="árboles-de-decisión.html#cb698-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb698-10"><a href="árboles-de-decisión.html#cb698-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb698-11"><a href="árboles-de-decisión.html#cb698-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_interact</span>(<span class="sc">~</span> <span class="fu">matches</span>(<span class="st">&quot;Bsmt_Cond&quot;</span>)<span class="sc">:</span>TotRms_AbvGrd) <span class="sc">%&gt;%</span> </span>
<span id="cb698-12"><a href="árboles-de-decisión.html#cb698-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb698-13"><a href="árboles-de-decisión.html#cb698-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb698-14"><a href="árboles-de-decisión.html#cb698-14" aria-hidden="true" tabindex="-1"></a>receta_casas</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          6
## 
## Training data contained 2197 data points and no missing data.
## 
## Operations:
## 
## Variable mutation for ~Year_Sold - Year_Remod_Add, ~forcats::fct... [trained]
## Re-order factor level to ref_level for Exter_Cond [trained]
## Centering and scaling for Gr_Liv_Area, TotRms_AbvGrd, Year_Sold, Year_Rem... [trained]
## Dummy variables from Exter_Cond, Bsmt_Cond [trained]
## Interactions with (Bsmt_Cond_Fair + Bsmt_Cond_Good + Bsmt_Cond_No_Ba... [trained]</code></pre>
<p>Recordemos que la función recipe() solo son los pasos a seguir, necesitamos usar la función prep() que nos devuelve una receta actualizada con las estimaciones y la función juice() que nos devuelve la matriz de diseño.</p>
<p><strong>Paso 3: Selección de tipo de modelo con hiperparámetros iniciales</strong></p>
<div class="sourceCode" id="cb700"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb700-1"><a href="árboles-de-decisión.html#cb700-1" aria-hidden="true" tabindex="-1"></a>xgboost_reg_model <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(</span>
<span id="cb700-2"><a href="árboles-de-decisión.html#cb700-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">&quot;regression&quot;</span>,</span>
<span id="cb700-3"><a href="árboles-de-decisión.html#cb700-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">500</span>,</span>
<span id="cb700-4"><a href="árboles-de-decisión.html#cb700-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="fu">tune</span>(),</span>
<span id="cb700-5"><a href="árboles-de-decisión.html#cb700-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_n =</span> <span class="fu">tune</span>(),</span>
<span id="cb700-6"><a href="árboles-de-decisión.html#cb700-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fu">tune</span>(),</span>
<span id="cb700-7"><a href="árboles-de-decisión.html#cb700-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="fu">tune</span>(),</span>
<span id="cb700-8"><a href="árboles-de-decisión.html#cb700-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb700-9"><a href="árboles-de-decisión.html#cb700-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">learn_rate =</span> <span class="fu">tune</span>()</span>
<span id="cb700-10"><a href="árboles-de-decisión.html#cb700-10" aria-hidden="true" tabindex="-1"></a> ) <span class="sc">%&gt;%</span> </span>
<span id="cb700-11"><a href="árboles-de-decisión.html#cb700-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(</span>
<span id="cb700-12"><a href="árboles-de-decisión.html#cb700-12" aria-hidden="true" tabindex="-1"></a>   <span class="st">&quot;xgboost&quot;</span>, </span>
<span id="cb700-13"><a href="árboles-de-decisión.html#cb700-13" aria-hidden="true" tabindex="-1"></a>   <span class="at">importance =</span> <span class="st">&quot;impurity&quot;</span></span>
<span id="cb700-14"><a href="árboles-de-decisión.html#cb700-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb700-15"><a href="árboles-de-decisión.html#cb700-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb700-16"><a href="árboles-de-decisión.html#cb700-16" aria-hidden="true" tabindex="-1"></a>xgboost_reg_model</span></code></pre></div>
<pre><code>## Boosted Tree Model Specification (regression)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 500
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: xgboost</code></pre>
<p><strong>Paso 4: Inicialización de workflow o pipeline</strong></p>
<div class="sourceCode" id="cb702"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb702-1"><a href="árboles-de-decisión.html#cb702-1" aria-hidden="true" tabindex="-1"></a>xgboost_reg_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb702-2"><a href="árboles-de-decisión.html#cb702-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(xgboost_reg_model) <span class="sc">%&gt;%</span> </span>
<span id="cb702-3"><a href="árboles-de-decisión.html#cb702-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(receta_casas)</span>
<span id="cb702-4"><a href="árboles-de-decisión.html#cb702-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb702-5"><a href="árboles-de-decisión.html#cb702-5" aria-hidden="true" tabindex="-1"></a>xgboost_reg_workflow</span></code></pre></div>
<pre><code>## ══ Workflow ═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ── Preprocessor ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## 5 Recipe Steps
## 
## • step_mutate()
## • step_relevel()
## • step_normalize()
## • step_dummy()
## • step_interact()
## 
## ── Model ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Boosted Tree Model Specification (regression)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 500
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: xgboost</code></pre>
<p><strong>Paso 5: Creación de grid search</strong></p>
<div class="sourceCode" id="cb704"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb704-1"><a href="árboles-de-decisión.html#cb704-1" aria-hidden="true" tabindex="-1"></a>xgboost_param_grid <span class="ot">&lt;-</span> <span class="fu">grid_random</span>(</span>
<span id="cb704-2"><a href="árboles-de-decisión.html#cb704-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tree_depth</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">3</span>, <span class="dv">50</span>)),</span>
<span id="cb704-3"><a href="árboles-de-decisión.html#cb704-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">min_n</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">50</span>)),</span>
<span id="cb704-4"><a href="árboles-de-decisión.html#cb704-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">loss_reduction</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="fl">1.5</span>), <span class="at">trans =</span> <span class="fu">log10_trans</span>()),</span>
<span id="cb704-5"><a href="árboles-de-decisión.html#cb704-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">learn_rate</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="sc">-</span><span class="fl">0.25</span>), <span class="at">trans =</span> <span class="fu">log10_trans</span>()),</span>
<span id="cb704-6"><a href="árboles-de-decisión.html#cb704-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtry</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">70</span>)),</span>
<span id="cb704-7"><a href="árboles-de-decisión.html#cb704-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="fu">sample_prop</span>(),</span>
<span id="cb704-8"><a href="árboles-de-decisión.html#cb704-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">50</span></span>
<span id="cb704-9"><a href="árboles-de-decisión.html#cb704-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb704-10"><a href="árboles-de-decisión.html#cb704-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb704-11"><a href="árboles-de-decisión.html#cb704-11" aria-hidden="true" tabindex="-1"></a>xgboost_param_grid</span></code></pre></div>
<pre><code>## # A tibble: 50 × 6
##    tree_depth min_n loss_reduction learn_rate  mtry sample_size
##         &lt;int&gt; &lt;int&gt;          &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt;
##  1         48    47       1.40e- 9  0.0000118    34       0.148
##  2         33    14       3.14e-10  0.0000234    23       0.341
##  3         26    31       7.83e- 6  0.276        24       0.868
##  4         40    41       3.20e- 3  0.0523       42       0.574
##  5         30    29       1.97e+ 0  0.000357     56       0.574
##  6         20    25       1.03e- 6  0.000281     58       0.696
##  7         10    34       6.78e- 6  0.00131      42       0.834
##  8         11    33       1.13e-10  0.000630     43       0.947
##  9         24    41       4.81e- 9  0.130        24       0.418
## 10         23    50       9.23e- 9  0.0000449    19       0.476
## # … with 40 more rows</code></pre>
<p><strong>Paso 6: Entrenamiento de modelos con hiperparámetros definidos</strong></p>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb706-1"><a href="árboles-de-decisión.html#cb706-1" aria-hidden="true" tabindex="-1"></a>UseCores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb706-2"><a href="árboles-de-decisión.html#cb706-2" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(UseCores)</span>
<span id="cb706-3"><a href="árboles-de-decisión.html#cb706-3" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cluster)</span>
<span id="cb706-4"><a href="árboles-de-decisión.html#cb706-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb706-5"><a href="árboles-de-decisión.html#cb706-5" aria-hidden="true" tabindex="-1"></a>ctrl_grid <span class="ot">&lt;-</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> T, <span class="at">verbose =</span> T)</span>
<span id="cb706-6"><a href="árboles-de-decisión.html#cb706-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb706-7"><a href="árboles-de-decisión.html#cb706-7" aria-hidden="true" tabindex="-1"></a>xgb1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb706-8"><a href="árboles-de-decisión.html#cb706-8" aria-hidden="true" tabindex="-1"></a>xgboost_reg_tune_result <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb706-9"><a href="árboles-de-decisión.html#cb706-9" aria-hidden="true" tabindex="-1"></a>  xgboost_reg_workflow,</span>
<span id="cb706-10"><a href="árboles-de-decisión.html#cb706-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> ames_folds,</span>
<span id="cb706-11"><a href="árboles-de-decisión.html#cb706-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> xgboost_param_grid,</span>
<span id="cb706-12"><a href="árboles-de-decisión.html#cb706-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(rmse, mae, mape, rsq),</span>
<span id="cb706-13"><a href="árboles-de-decisión.html#cb706-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> ctrl_grid</span>
<span id="cb706-14"><a href="árboles-de-decisión.html#cb706-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb706-15"><a href="árboles-de-decisión.html#cb706-15" aria-hidden="true" tabindex="-1"></a>xgb2 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); xgb2 <span class="sc">-</span> xgb1</span>
<span id="cb706-16"><a href="árboles-de-decisión.html#cb706-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb706-17"><a href="árboles-de-decisión.html#cb706-17" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cluster)</span>
<span id="cb706-18"><a href="árboles-de-decisión.html#cb706-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb706-19"><a href="árboles-de-decisión.html#cb706-19" aria-hidden="true" tabindex="-1"></a>xgboost_reg_tune_result <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/xgboost_model_reg.rds&quot;</span>)</span></code></pre></div>
<p><strong>Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)</strong></p>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="árboles-de-decisión.html#cb707-1" aria-hidden="true" tabindex="-1"></a>xgboost_reg_tune_result <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/xgboost_model_reg.rds&quot;</span>)</span>
<span id="cb707-2"><a href="árboles-de-decisión.html#cb707-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb707-3"><a href="árboles-de-decisión.html#cb707-3" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(xgboost_reg_tune_result)</span></code></pre></div>
<pre><code>## # A tibble: 200 × 12
##     mtry min_n tree_depth learn_…¹ loss_…² sampl…³ .metric .esti…⁴    mean     n
##    &lt;int&gt; &lt;int&gt;      &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;
##  1     1    12         18  0.0837  1.85e+1   0.952 mae     standa… 2.88e+4    10
##  2     1    12         18  0.0837  1.85e+1   0.952 mape    standa… 1.71e+1    10
##  3     1    12         18  0.0837  1.85e+1   0.952 rmse    standa… 4.29e+4    10
##  4     1    12         18  0.0837  1.85e+1   0.952 rsq     standa… 7.13e-1    10
##  5    18    12         49  0.00421 3.92e-7   0.457 mae     standa… 3.45e+4    10
##  6    18    12         49  0.00421 3.92e-7   0.457 mape    standa… 1.85e+1    10
##  7    18    12         49  0.00421 3.92e-7   0.457 rmse    standa… 4.98e+4    10
##  8    18    12         49  0.00421 3.92e-7   0.457 rsq     standa… 7.10e-1    10
##  9     8     9         16  0.00213 3.95e-6   0.956 mae     standa… 6.49e+4    10
## 10     8     9         16  0.00213 3.95e-6   0.956 mape    standa… 3.36e+1    10
## # … with 190 more rows, 2 more variables: std_err &lt;dbl&gt;, .config &lt;chr&gt;, and
## #   abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,
## #   ⁴​.estimator</code></pre>
<p>En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos:</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb709-1"><a href="árboles-de-decisión.html#cb709-1" aria-hidden="true" tabindex="-1"></a>xgboost_reg_tune_result <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>() </span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-512-1.png" width="672" /></p>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="árboles-de-decisión.html#cb710-1" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(xgboost_reg_tune_result, <span class="at">n =</span> <span class="dv">10</span>, <span class="at">metric =</span> <span class="st">&quot;rsq&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb710-2"><a href="árboles-de-decisión.html#cb710-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">select</span>(mtry<span class="sc">:</span>sample_size, mean<span class="sc">:</span>std_err, <span class="sc">-</span>n)</span></code></pre></div>
<pre><code>## # A tibble: 10 × 8
##     mtry min_n tree_depth learn_rate loss_reduction sample_size  mean std_err
##    &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1    30     8          7    0.00722       1.52e- 9       0.237 0.718  0.0134
##  2     1    12         18    0.0837        1.85e+ 1       0.952 0.713  0.0120
##  3    50    13         41    0.00779       6.37e- 2       0.892 0.713  0.0114
##  4    70     4         15    0.00277       2.97e- 4       0.301 0.712  0.0126
##  5    18    12         49    0.00421       3.92e- 7       0.457 0.710  0.0138
##  6    13    13         14    0.00331       5.70e- 8       0.406 0.706  0.0138
##  7     8     9         16    0.00213       3.95e- 6       0.956 0.705  0.0113
##  8    11    13         26    0.00294       2.90e- 5       0.602 0.705  0.0131
##  9    47    19         48    0.0250        1.44e- 6       0.742 0.704  0.0129
## 10    39    14         42    0.00337       8.06e-10       0.700 0.703  0.0137</code></pre>
<p><strong>Paso 8: Selección de modelo a usar</strong></p>
<div class="sourceCode" id="cb712"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb712-1"><a href="árboles-de-decisión.html#cb712-1" aria-hidden="true" tabindex="-1"></a>best_xgboost_reg_model <span class="ot">&lt;-</span> <span class="fu">select_best</span>(xgboost_reg_tune_result, <span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb712-2"><a href="árboles-de-decisión.html#cb712-2" aria-hidden="true" tabindex="-1"></a>best_xgboost_reg_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 7
##    mtry min_n tree_depth learn_rate loss_reduction sample_size .config          
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;            
## 1    30     8          7    0.00722  0.00000000152       0.237 Preprocessor1_Mo…</code></pre>
<div class="sourceCode" id="cb714"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb714-1"><a href="árboles-de-decisión.html#cb714-1" aria-hidden="true" tabindex="-1"></a>best_xgboost_reg_1se_model <span class="ot">&lt;-</span> xgboost_reg_tune_result <span class="sc">%&gt;%</span> </span>
<span id="cb714-2"><a href="árboles-de-decisión.html#cb714-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">select_by_one_std_err</span>(<span class="at">metric =</span> <span class="st">&quot;rmse&quot;</span>, <span class="st">&quot;rmse&quot;</span>)</span>
<span id="cb714-3"><a href="árboles-de-decisión.html#cb714-3" aria-hidden="true" tabindex="-1"></a>best_xgboost_reg_1se_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 14
##    mtry min_n tree_depth learn_rate loss_…¹ sampl…² .metric .esti…³   mean     n
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt; &lt;int&gt;
## 1     1    12         18     0.0837    18.5   0.952 rmse    standa… 42876.    10
## # … with 4 more variables: std_err &lt;dbl&gt;, .config &lt;chr&gt;, .best &lt;dbl&gt;,
## #   .bound &lt;dbl&gt;, and abbreviated variable names ¹​loss_reduction, ²​sample_size,
## #   ³​.estimator</code></pre>
<p><strong>Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)</strong></p>
<div class="sourceCode" id="cb716"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb716-1"><a href="árboles-de-decisión.html#cb716-1" aria-hidden="true" tabindex="-1"></a>final_xgboost_reg_model <span class="ot">&lt;-</span> xgboost_reg_workflow <span class="sc">%&gt;%</span> </span>
<span id="cb716-2"><a href="árboles-de-decisión.html#cb716-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#finalize_workflow(best_xgboost_model) %&gt;% </span></span>
<span id="cb716-3"><a href="árboles-de-decisión.html#cb716-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(best_xgboost_reg_1se_model) <span class="sc">%&gt;%</span> </span>
<span id="cb716-4"><a href="árboles-de-decisión.html#cb716-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> ames_train)</span></code></pre></div>
<pre><code>## [23:49:02] WARNING: amalgamation/../src/learner.cc:627: 
## Parameters: { &quot;importance&quot; } might not be used.
## 
##   This could be a false alarm, with some parameters getting used by language bindings but
##   then being mistakenly passed down to XGBoost core, or some parameter actually being used
##   but getting flagged wrongly here. Please open an issue if you find any such cases.</code></pre>
<div class="sourceCode" id="cb718"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb718-1"><a href="árboles-de-decisión.html#cb718-1" aria-hidden="true" tabindex="-1"></a>final_xgboost_reg_model</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ── Preprocessor ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## 5 Recipe Steps
## 
## • step_mutate()
## • step_relevel()
## • step_normalize()
## • step_dummy()
## • step_interact()
## 
## ── Model ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## ##### xgb.Booster
## raw: 492.6 Kb 
## call:
##   xgboost::xgb.train(params = list(eta = 0.0836732313996573, max_depth = 18L, 
##     gamma = 18.5133928295454, colsample_bytree = 1, colsample_bynode = 0.0588235294117647, 
##     min_child_weight = 12L, subsample = 0.951664445269853), data = x$data, 
##     nrounds = 500, watchlist = x$watchlist, verbose = 0, importance = &quot;impurity&quot;, 
##     nthread = 1, objective = &quot;reg:squarederror&quot;)
## params (as set within xgb.train):
##   eta = &quot;0.0836732313996573&quot;, max_depth = &quot;18&quot;, gamma = &quot;18.5133928295454&quot;, colsample_bytree = &quot;1&quot;, colsample_bynode = &quot;0.0588235294117647&quot;, min_child_weight = &quot;12&quot;, subsample = &quot;0.951664445269853&quot;, importance = &quot;impurity&quot;, nthread = &quot;1&quot;, objective = &quot;reg:squarederror&quot;, validate_parameters = &quot;TRUE&quot;
## xgb.attributes:
##   niter
## callbacks:
##   cb.evaluation.log()
## # of features: 17 
## niter: 500
## nfeatures : 17 
## evaluation_log:
##     iter training_rmse
##        1     183103.65
##        2     170225.79
## ---                   
##      499      37557.28
##      500      37555.72</code></pre>
<p>Como hemos hablado anteriormente, este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.</p>
<p>Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos data leakage. Para enfrentar esto, ayuda estimar y ordenar el valor de importancia del modelo</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="árboles-de-decisión.html#cb720-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vip)</span>
<span id="cb720-2"><a href="árboles-de-decisión.html#cb720-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb720-3"><a href="árboles-de-decisión.html#cb720-3" aria-hidden="true" tabindex="-1"></a>final_xgboost_reg_model <span class="sc">%&gt;%</span></span>
<span id="cb720-4"><a href="árboles-de-decisión.html#cb720-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb720-5"><a href="árboles-de-decisión.html#cb720-5" aria-hidden="true" tabindex="-1"></a>  vip<span class="sc">::</span><span class="fu">vip</span>(<span class="at">num_features =</span> <span class="dv">25</span>) <span class="sc">+</span> </span>
<span id="cb720-6"><a href="árboles-de-decisión.html#cb720-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Importancia de las variables&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-516-1.png" width="672" /></p>
<p><strong>Paso 10: Validar poder predictivo con datos de prueba</strong></p>
<p>Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos:</p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="árboles-de-decisión.html#cb721-1" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_xgboost_reg_model, ames_test) <span class="sc">%&gt;%</span> </span>
<span id="cb721-2"><a href="árboles-de-decisión.html#cb721-2" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">bind_cols</span>(<span class="at">Sale_Price =</span> ames_test<span class="sc">$</span>Sale_Price) <span class="sc">%&gt;%</span> </span>
<span id="cb721-3"><a href="árboles-de-decisión.html#cb721-3" aria-hidden="true" tabindex="-1"></a>  dplyr<span class="sc">::</span><span class="fu">rename</span>(<span class="at">pred_xgb_reg =</span> .pred)</span>
<span id="cb721-4"><a href="árboles-de-decisión.html#cb721-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb721-5"><a href="árboles-de-decisión.html#cb721-5" aria-hidden="true" tabindex="-1"></a>results</span></code></pre></div>
<pre><code>## # A tibble: 733 × 2
##    pred_xgb_reg Sale_Price
##           &lt;dbl&gt;      &lt;int&gt;
##  1      121063.     105000
##  2      172835.     185000
##  3      177081.     180400
##  4       95956.     141000
##  5      224212.     210000
##  6      201056.     216000
##  7      184153.     149900
##  8      133850.     105500
##  9      133850.      88000
## 10      159376.     146000
## # … with 723 more rows</code></pre>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="árboles-de-decisión.html#cb723-1" aria-hidden="true" tabindex="-1"></a>multi_metric <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(rmse, rsq, mae, mape, ccc)</span>
<span id="cb723-2"><a href="árboles-de-decisión.html#cb723-2" aria-hidden="true" tabindex="-1"></a><span class="fu">multi_metric</span>(results, <span class="at">truth =</span> Sale_Price, <span class="at">estimate =</span> pred_xgb_reg) <span class="sc">%&gt;%</span> </span>
<span id="cb723-3"><a href="árboles-de-decisión.html#cb723-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">.estimate =</span> <span class="fu">round</span>(.estimate, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## # A tibble: 5 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 rmse    standard    44012.  
## 2 rsq     standard        0.7 
## 3 mae     standard    29968.  
## 4 mape    standard       17.8 
## 5 ccc     standard        0.82</code></pre>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="árboles-de-decisión.html#cb725-1" aria-hidden="true" tabindex="-1"></a>results <span class="sc">%&gt;%</span> </span>
<span id="cb725-2"><a href="árboles-de-decisión.html#cb725-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> pred_xgb_reg, <span class="at">y =</span> Sale_Price)) <span class="sc">+</span></span>
<span id="cb725-3"><a href="árboles-de-decisión.html#cb725-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb725-4"><a href="árboles-de-decisión.html#cb725-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb725-5"><a href="árboles-de-decisión.html#cb725-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Prediction&quot;</span>) <span class="sc">+</span></span>
<span id="cb725-6"><a href="árboles-de-decisión.html#cb725-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;Observation&quot;</span>) <span class="sc">+</span></span>
<span id="cb725-7"><a href="árboles-de-decisión.html#cb725-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Comparisson&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-519-1.png" width="672" /></p>
</div>
<div id="xgboost-para-clasificación" class="section level3 hasAnchor" number="9.8.2">
<h3><span class="header-section-number">9.8.2</span> XGBoost para clasificación<a href="árboles-de-decisión.html#xgboost-para-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Paso 1: Separación inicial de datos (test, train)</strong></p>
<div class="sourceCode" id="cb726"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb726-1"><a href="árboles-de-decisión.html#cb726-1" aria-hidden="true" tabindex="-1"></a>telco <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;data/Churn.csv&quot;</span>)</span>
<span id="cb726-2"><a href="árboles-de-decisión.html#cb726-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb726-3"><a href="árboles-de-decisión.html#cb726-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb726-4"><a href="árboles-de-decisión.html#cb726-4" aria-hidden="true" tabindex="-1"></a>telco_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(telco, <span class="at">prop =</span> .<span class="dv">70</span>)</span>
<span id="cb726-5"><a href="árboles-de-decisión.html#cb726-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb726-6"><a href="árboles-de-decisión.html#cb726-6" aria-hidden="true" tabindex="-1"></a>telco_train <span class="ot">&lt;-</span> <span class="fu">training</span>(telco_split)</span>
<span id="cb726-7"><a href="árboles-de-decisión.html#cb726-7" aria-hidden="true" tabindex="-1"></a>telco_test  <span class="ot">&lt;-</span> <span class="fu">testing</span>(telco_split)</span>
<span id="cb726-8"><a href="árboles-de-decisión.html#cb726-8" aria-hidden="true" tabindex="-1"></a>telco_folds <span class="ot">&lt;-</span> <span class="fu">vfold_cv</span>(telco_train)</span>
<span id="cb726-9"><a href="árboles-de-decisión.html#cb726-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb726-10"><a href="árboles-de-decisión.html#cb726-10" aria-hidden="true" tabindex="-1"></a>telco_folds</span></code></pre></div>
<pre><code>## #  10-fold cross-validation 
## # A tibble: 10 × 2
##    splits             id    
##    &lt;list&gt;             &lt;chr&gt; 
##  1 &lt;split [4437/493]&gt; Fold01
##  2 &lt;split [4437/493]&gt; Fold02
##  3 &lt;split [4437/493]&gt; Fold03
##  4 &lt;split [4437/493]&gt; Fold04
##  5 &lt;split [4437/493]&gt; Fold05
##  6 &lt;split [4437/493]&gt; Fold06
##  7 &lt;split [4437/493]&gt; Fold07
##  8 &lt;split [4437/493]&gt; Fold08
##  9 &lt;split [4437/493]&gt; Fold09
## 10 &lt;split [4437/493]&gt; Fold10</code></pre>
<p><strong>Paso 2: Pre-procesamiento e ingeniería de variables</strong></p>
<div class="sourceCode" id="cb728"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb728-1"><a href="árboles-de-decisión.html#cb728-1" aria-hidden="true" tabindex="-1"></a>telco_rec <span class="ot">&lt;-</span> <span class="fu">recipe</span>(</span>
<span id="cb728-2"><a href="árboles-de-decisión.html#cb728-2" aria-hidden="true" tabindex="-1"></a>  Churn <span class="sc">~</span> customerID <span class="sc">+</span> TotalCharges <span class="sc">+</span> MonthlyCharges <span class="sc">+</span> SeniorCitizen <span class="sc">+</span> Contract, </span>
<span id="cb728-3"><a href="árboles-de-decisión.html#cb728-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> telco_train) <span class="sc">%&gt;%</span> </span>
<span id="cb728-4"><a href="árboles-de-decisión.html#cb728-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">update_role</span>(customerID, <span class="at">new_role =</span> <span class="st">&quot;id variable&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb728-5"><a href="árboles-de-decisión.html#cb728-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_mutate</span>(<span class="at">Contract =</span> <span class="fu">as.factor</span>(Contract)) <span class="sc">%&gt;%</span> </span>
<span id="cb728-6"><a href="árboles-de-decisión.html#cb728-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_impute_median</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb728-7"><a href="árboles-de-decisión.html#cb728-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb728-8"><a href="árboles-de-decisión.html#cb728-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb728-9"><a href="árboles-de-decisión.html#cb728-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prep</span>()</span>
<span id="cb728-10"><a href="árboles-de-decisión.html#cb728-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb728-11"><a href="árboles-de-decisión.html#cb728-11" aria-hidden="true" tabindex="-1"></a>telco_rec</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##         role #variables
##  id variable          1
##      outcome          1
##    predictor          4
## 
## Training data contained 4930 data points and 10 incomplete rows. 
## 
## Operations:
## 
## Variable mutation for ~as.factor(Contract) [trained]
## Median imputation for TotalCharges, MonthlyCharges, SeniorCitizen [trained]
## Centering and scaling for TotalCharges, MonthlyCharges, SeniorCitizen [trained]
## Dummy variables from Contract [trained]</code></pre>
<p><strong>Paso 3: Selección de tipo de modelo con hiperparámetros iniciales</strong></p>
<div class="sourceCode" id="cb730"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb730-1"><a href="árboles-de-decisión.html#cb730-1" aria-hidden="true" tabindex="-1"></a>xgboost_model <span class="ot">&lt;-</span> <span class="fu">boost_tree</span>(</span>
<span id="cb730-2"><a href="árboles-de-decisión.html#cb730-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb730-3"><a href="árboles-de-decisión.html#cb730-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">trees =</span> <span class="dv">500</span>,</span>
<span id="cb730-4"><a href="árboles-de-decisión.html#cb730-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">tree_depth =</span> <span class="fu">tune</span>(),</span>
<span id="cb730-5"><a href="árboles-de-decisión.html#cb730-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">min_n =</span> <span class="fu">tune</span>(),</span>
<span id="cb730-6"><a href="árboles-de-decisión.html#cb730-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss_reduction =</span> <span class="fu">tune</span>(),</span>
<span id="cb730-7"><a href="árboles-de-decisión.html#cb730-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="fu">tune</span>(),</span>
<span id="cb730-8"><a href="árboles-de-decisión.html#cb730-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">mtry =</span> <span class="fu">tune</span>(),</span>
<span id="cb730-9"><a href="árboles-de-decisión.html#cb730-9" aria-hidden="true" tabindex="-1"></a> <span class="at">learn_rate =</span> <span class="fu">tune</span>()</span>
<span id="cb730-10"><a href="árboles-de-decisión.html#cb730-10" aria-hidden="true" tabindex="-1"></a> ) <span class="sc">%&gt;%</span> </span>
<span id="cb730-11"><a href="árboles-de-decisión.html#cb730-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">set_engine</span>(</span>
<span id="cb730-12"><a href="árboles-de-decisión.html#cb730-12" aria-hidden="true" tabindex="-1"></a>   <span class="st">&quot;xgboost&quot;</span>, </span>
<span id="cb730-13"><a href="árboles-de-decisión.html#cb730-13" aria-hidden="true" tabindex="-1"></a>   <span class="at">importance =</span> <span class="st">&quot;impurity&quot;</span></span>
<span id="cb730-14"><a href="árboles-de-decisión.html#cb730-14" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb730-15"><a href="árboles-de-decisión.html#cb730-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb730-16"><a href="árboles-de-decisión.html#cb730-16" aria-hidden="true" tabindex="-1"></a>xgboost_model</span></code></pre></div>
<pre><code>## Boosted Tree Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 500
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: xgboost</code></pre>
<p><strong>Paso 4: Inicialización de workflow o pipeline</strong></p>
<div class="sourceCode" id="cb732"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb732-1"><a href="árboles-de-decisión.html#cb732-1" aria-hidden="true" tabindex="-1"></a>xgboost_workflow <span class="ot">&lt;-</span> <span class="fu">workflow</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb732-2"><a href="árboles-de-decisión.html#cb732-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_model</span>(xgboost_model) <span class="sc">%&gt;%</span> </span>
<span id="cb732-3"><a href="árboles-de-decisión.html#cb732-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_recipe</span>(telco_rec)</span>
<span id="cb732-4"><a href="árboles-de-decisión.html#cb732-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb732-5"><a href="árboles-de-decisión.html#cb732-5" aria-hidden="true" tabindex="-1"></a>xgboost_workflow</span></code></pre></div>
<pre><code>## ══ Workflow ═══════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ── Preprocessor ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## • step_mutate()
## • step_impute_median()
## • step_normalize()
## • step_dummy()
## 
## ── Model ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## Boosted Tree Model Specification (classification)
## 
## Main Arguments:
##   mtry = tune()
##   trees = 500
##   min_n = tune()
##   tree_depth = tune()
##   learn_rate = tune()
##   loss_reduction = tune()
##   sample_size = tune()
## 
## Engine-Specific Arguments:
##   importance = impurity
## 
## Computational engine: xgboost</code></pre>
<p><strong>Paso 5: Creación de grid search</strong></p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="árboles-de-decisión.html#cb734-1" aria-hidden="true" tabindex="-1"></a>xgboost_param_grid <span class="ot">&lt;-</span> <span class="fu">grid_random</span>(</span>
<span id="cb734-2"><a href="árboles-de-decisión.html#cb734-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tree_depth</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">30</span>)),</span>
<span id="cb734-3"><a href="árboles-de-decisión.html#cb734-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">min_n</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">50</span>)),</span>
<span id="cb734-4"><a href="árboles-de-decisión.html#cb734-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">loss_reduction</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">10</span>, <span class="fl">1.5</span>), <span class="at">trans =</span> <span class="fu">log10_trans</span>()),</span>
<span id="cb734-5"><a href="árboles-de-decisión.html#cb734-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">learn_rate</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">6</span>, <span class="sc">-</span><span class="fl">0.25</span>), <span class="at">trans =</span> <span class="fu">log10_trans</span>()),</span>
<span id="cb734-6"><a href="árboles-de-decisión.html#cb734-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mtry</span>(<span class="at">range =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">20</span>)),</span>
<span id="cb734-7"><a href="árboles-de-decisión.html#cb734-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">sample_size =</span> <span class="fu">sample_prop</span>(),</span>
<span id="cb734-8"><a href="árboles-de-decisión.html#cb734-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">size =</span> <span class="dv">50</span></span>
<span id="cb734-9"><a href="árboles-de-decisión.html#cb734-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb734-10"><a href="árboles-de-decisión.html#cb734-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb734-11"><a href="árboles-de-decisión.html#cb734-11" aria-hidden="true" tabindex="-1"></a>xgboost_param_grid</span></code></pre></div>
<pre><code>## # A tibble: 50 × 6
##    tree_depth min_n loss_reduction learn_rate  mtry sample_size
##         &lt;int&gt; &lt;int&gt;          &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt;
##  1         15     3       3.25e- 5 0.00378        7       0.779
##  2         17    34       4.81e- 3 0.00128       15       0.495
##  3         24    49       2.80e-10 0.00503       12       0.206
##  4         25    47       3.32e- 7 0.542         13       0.331
##  5         19    49       5.44e- 4 0.00887        3       0.757
##  6         15    39       1.79e+ 0 0.000173       2       0.955
##  7         24    40       1.81e+ 0 0.0519         9       0.571
##  8         14    23       2.11e- 4 0.337          1       0.129
##  9         25    43       4.26e- 1 0.00000650     1       0.670
## 10         30    14       1.61e- 2 0.00233       14       0.636
## # … with 40 more rows</code></pre>
<p><strong>Paso 6: Entrenamiento de modelos con hiperparámetros definidos</strong></p>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="árboles-de-decisión.html#cb736-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(doParallel)</span>
<span id="cb736-2"><a href="árboles-de-decisión.html#cb736-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb736-3"><a href="árboles-de-decisión.html#cb736-3" aria-hidden="true" tabindex="-1"></a>UseCores <span class="ot">&lt;-</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb736-4"><a href="árboles-de-decisión.html#cb736-4" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">makeCluster</span>(UseCores)</span>
<span id="cb736-5"><a href="árboles-de-decisión.html#cb736-5" aria-hidden="true" tabindex="-1"></a><span class="fu">registerDoParallel</span>(cluster)</span>
<span id="cb736-6"><a href="árboles-de-decisión.html#cb736-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb736-7"><a href="árboles-de-decisión.html#cb736-7" aria-hidden="true" tabindex="-1"></a>ctrl_grid <span class="ot">&lt;-</span> <span class="fu">control_grid</span>(<span class="at">save_pred =</span> T, <span class="at">verbose =</span> T)</span>
<span id="cb736-8"><a href="árboles-de-decisión.html#cb736-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb736-9"><a href="árboles-de-decisión.html#cb736-9" aria-hidden="true" tabindex="-1"></a>xgbt1 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>()</span>
<span id="cb736-10"><a href="árboles-de-decisión.html#cb736-10" aria-hidden="true" tabindex="-1"></a>xgboost_tune_result <span class="ot">&lt;-</span> <span class="fu">tune_grid</span>(</span>
<span id="cb736-11"><a href="árboles-de-decisión.html#cb736-11" aria-hidden="true" tabindex="-1"></a>  xgboost_workflow,</span>
<span id="cb736-12"><a href="árboles-de-decisión.html#cb736-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">resamples =</span> telco_folds,</span>
<span id="cb736-13"><a href="árboles-de-decisión.html#cb736-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">grid =</span> xgboost_param_grid,</span>
<span id="cb736-14"><a href="árboles-de-decisión.html#cb736-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">metric_set</span>(roc_auc, pr_auc)</span>
<span id="cb736-15"><a href="árboles-de-decisión.html#cb736-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb736-16"><a href="árboles-de-decisión.html#cb736-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb736-17"><a href="árboles-de-decisión.html#cb736-17" aria-hidden="true" tabindex="-1"></a>xgb2 <span class="ot">&lt;-</span> <span class="fu">Sys.time</span>(); xgb2 <span class="sc">-</span> xgbt1</span>
<span id="cb736-18"><a href="árboles-de-decisión.html#cb736-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb736-19"><a href="árboles-de-decisión.html#cb736-19" aria-hidden="true" tabindex="-1"></a><span class="fu">stopCluster</span>(cluster)</span>
<span id="cb736-20"><a href="árboles-de-decisión.html#cb736-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb736-21"><a href="árboles-de-decisión.html#cb736-21" aria-hidden="true" tabindex="-1"></a>xgboost_tune_result <span class="sc">%&gt;%</span> <span class="fu">saveRDS</span>(<span class="st">&quot;models/xgboost_model_classification.rds&quot;</span>)</span></code></pre></div>
<p><strong>Paso 7: Análisis de métricas de error e hiperparámetros (Vuelve al paso 3, si es necesario)</strong></p>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="árboles-de-decisión.html#cb737-1" aria-hidden="true" tabindex="-1"></a>xgboost_tune_result <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;models/xgboost_model_classification.rds&quot;</span>)</span>
<span id="cb737-2"><a href="árboles-de-decisión.html#cb737-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb737-3"><a href="árboles-de-decisión.html#cb737-3" aria-hidden="true" tabindex="-1"></a><span class="fu">collect_metrics</span>(xgboost_tune_result)</span></code></pre></div>
<pre><code>## # A tibble: 100 × 12
##     mtry min_n tree_depth learn_r…¹ loss_r…² sampl…³ .metric .esti…⁴  mean     n
##    &lt;int&gt; &lt;int&gt;      &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;
##  1     7     3         15   0.00378 3.25e- 5   0.779 pr_auc  binary  0.930    10
##  2     7     3         15   0.00378 3.25e- 5   0.779 roc_auc binary  0.825    10
##  3    15    34         17   0.00128 4.81e- 3   0.495 pr_auc  binary  0.931    10
##  4    15    34         17   0.00128 4.81e- 3   0.495 roc_auc binary  0.831    10
##  5    12    49         24   0.00503 2.80e-10   0.206 pr_auc  binary  0.918    10
##  6    12    49         24   0.00503 2.80e-10   0.206 roc_auc binary  0.810    10
##  7    13    47         25   0.542   3.32e- 7   0.331 pr_auc  binary  0.920    10
##  8    13    47         25   0.542   3.32e- 7   0.331 roc_auc binary  0.815    10
##  9     3    49         19   0.00887 5.44e- 4   0.757 pr_auc  binary  0.935    10
## 10     3    49         19   0.00887 5.44e- 4   0.757 roc_auc binary  0.838    10
## # … with 90 more rows, 2 more variables: std_err &lt;dbl&gt;, .config &lt;chr&gt;, and
## #   abbreviated variable names ¹​learn_rate, ²​loss_reduction, ³​sample_size,
## #   ⁴​.estimator</code></pre>
<p>En la siguiente gráfica observamos las distintas métricas de error asociados a los hiperparámetros elegidos:</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="árboles-de-decisión.html#cb739-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(xgboost_tune_result)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-527-1.png" width="672" /></p>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="árboles-de-decisión.html#cb740-1" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(xgboost_tune_result, <span class="at">n =</span> <span class="dv">10</span>, <span class="at">metric =</span> <span class="st">&quot;roc_auc&quot;</span>) </span></code></pre></div>
<pre><code>## # A tibble: 10 × 12
##     mtry min_n tree_depth learn_rate loss_…¹ sampl…² .metric .esti…³  mean     n
##    &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;
##  1     9    44         18  0.0211    2.21e-7   0.577 roc_auc binary  0.838    10
##  2    18    19         23  0.00585   6.19e+0   0.685 roc_auc binary  0.838    10
##  3     3    49         19  0.00887   5.44e-4   0.757 roc_auc binary  0.838    10
##  4    18    10         26  0.00149   1.92e-9   0.454 roc_auc binary  0.838    10
##  5    15     4         25  0.0638    1.82e+1   0.754 roc_auc binary  0.837    10
##  6    14    14         30  0.00233   1.61e-2   0.636 roc_auc binary  0.837    10
##  7    19     8         19  0.0000372 6.93e-6   0.362 roc_auc binary  0.837    10
##  8     9    40         24  0.0519    1.81e+0   0.571 roc_auc binary  0.836    10
##  9     2     3         23  0.0000608 6.74e-5   0.618 roc_auc binary  0.836    10
## 10     9     7         29  0.00612   2.59e-3   0.551 roc_auc binary  0.836    10
## # … with 2 more variables: std_err &lt;dbl&gt;, .config &lt;chr&gt;, and abbreviated
## #   variable names ¹​loss_reduction, ²​sample_size, ³​.estimator</code></pre>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="árboles-de-decisión.html#cb742-1" aria-hidden="true" tabindex="-1"></a><span class="fu">show_best</span>(xgboost_tune_result, <span class="at">n =</span> <span class="dv">10</span>, <span class="at">metric =</span> <span class="st">&quot;pr_auc&quot;</span>) </span></code></pre></div>
<pre><code>## # A tibble: 10 × 12
##     mtry min_n tree_depth learn_rate loss_…¹ sampl…² .metric .esti…³  mean     n
##    &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;
##  1     9    44         18    0.0211  2.21e-7   0.577 pr_auc  binary  0.935    10
##  2     3    49         19    0.00887 5.44e-4   0.757 pr_auc  binary  0.935    10
##  3    13    46         22    0.0390  1.27e-6   0.866 pr_auc  binary  0.935    10
##  4    16    10         12    0.0133  1.16e-7   0.495 pr_auc  binary  0.934    10
##  5     9    40         24    0.0519  1.81e+0   0.571 pr_auc  binary  0.934    10
##  6    12    13          7    0.0205  7.02e-1   0.561 pr_auc  binary  0.934    10
##  7     5    20         16    0.0399  5.04e-7   0.451 pr_auc  binary  0.934    10
##  8    18    19         23    0.00585 6.19e+0   0.685 pr_auc  binary  0.934    10
##  9     9     7         29    0.00612 2.59e-3   0.551 pr_auc  binary  0.934    10
## 10    14    14         30    0.00233 1.61e-2   0.636 pr_auc  binary  0.934    10
## # … with 2 more variables: std_err &lt;dbl&gt;, .config &lt;chr&gt;, and abbreviated
## #   variable names ¹​loss_reduction, ²​sample_size, ³​.estimator</code></pre>
<p><strong>Paso 8: Selección de modelo a usar</strong></p>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="árboles-de-decisión.html#cb744-1" aria-hidden="true" tabindex="-1"></a>best_xgboost_model <span class="ot">&lt;-</span> <span class="fu">select_best</span>(xgboost_tune_result, <span class="at">metric =</span> <span class="st">&quot;pr_auc&quot;</span>)</span>
<span id="cb744-2"><a href="árboles-de-decisión.html#cb744-2" aria-hidden="true" tabindex="-1"></a>best_xgboost_model</span></code></pre></div>
<pre><code>## # A tibble: 1 × 7
##    mtry min_n tree_depth learn_rate loss_reduction sample_size .config          
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;            
## 1     9    44         18     0.0211    0.000000221       0.577 Preprocessor1_Mo…</code></pre>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="árboles-de-decisión.html#cb746-1" aria-hidden="true" tabindex="-1"></a>best_xgboost_model_1se <span class="ot">&lt;-</span> xgboost_tune_result <span class="sc">%&gt;%</span> </span>
<span id="cb746-2"><a href="árboles-de-decisión.html#cb746-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">select_by_one_std_err</span>(<span class="at">metric =</span> <span class="st">&quot;pr_auc&quot;</span>, <span class="st">&quot;pr_auc&quot;</span>)</span>
<span id="cb746-3"><a href="árboles-de-decisión.html#cb746-3" aria-hidden="true" tabindex="-1"></a>best_xgboost_model_1se</span></code></pre></div>
<pre><code>## # A tibble: 1 × 14
##    mtry min_n tree_depth learn_rate loss_r…¹ sampl…² .metric .esti…³  mean     n
##   &lt;int&gt; &lt;int&gt;      &lt;int&gt;      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   &lt;dbl&gt; &lt;int&gt;
## 1     3    49         19    0.00887 0.000544   0.757 pr_auc  binary  0.935    10
## # … with 4 more variables: std_err &lt;dbl&gt;, .config &lt;chr&gt;, .best &lt;dbl&gt;,
## #   .bound &lt;dbl&gt;, and abbreviated variable names ¹​loss_reduction, ²​sample_size,
## #   ³​.estimator</code></pre>
<p><strong>Paso 9: Ajuste de modelo final con todos los datos (Vuelve al paso 2, si es necesario)</strong></p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="árboles-de-decisión.html#cb748-1" aria-hidden="true" tabindex="-1"></a>final_xgboost_model <span class="ot">&lt;-</span> xgboost_workflow <span class="sc">%&gt;%</span> </span>
<span id="cb748-2"><a href="árboles-de-decisión.html#cb748-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#finalize_workflow(best_xgboost_model) %&gt;% </span></span>
<span id="cb748-3"><a href="árboles-de-decisión.html#cb748-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">finalize_workflow</span>(best_xgboost_model_1se) <span class="sc">%&gt;%</span> </span>
<span id="cb748-4"><a href="árboles-de-decisión.html#cb748-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> telco_test)</span></code></pre></div>
<pre><code>## [23:49:07] WARNING: amalgamation/../src/learner.cc:627: 
## Parameters: { &quot;importance&quot; } might not be used.
## 
##   This could be a false alarm, with some parameters getting used by language bindings but
##   then being mistakenly passed down to XGBoost core, or some parameter actually being used
##   but getting flagged wrongly here. Please open an issue if you find any such cases.</code></pre>
<div class="sourceCode" id="cb750"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb750-1"><a href="árboles-de-decisión.html#cb750-1" aria-hidden="true" tabindex="-1"></a>final_xgboost_model</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ═════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: boost_tree()
## 
## ── Preprocessor ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## • step_mutate()
## • step_impute_median()
## • step_normalize()
## • step_dummy()
## 
## ── Model ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────
## ##### xgb.Booster
## raw: 448.7 Kb 
## call:
##   xgboost::xgb.train(params = list(eta = 0.00887062462674066, max_depth = 19L, 
##     gamma = 0.000544461013295823, colsample_bytree = 1, colsample_bynode = 0.6, 
##     min_child_weight = 49L, subsample = 0.756512506399304), data = x$data, 
##     nrounds = 500, watchlist = x$watchlist, verbose = 0, importance = &quot;impurity&quot;, 
##     nthread = 1, objective = &quot;binary:logistic&quot;)
## params (as set within xgb.train):
##   eta = &quot;0.00887062462674066&quot;, max_depth = &quot;19&quot;, gamma = &quot;0.000544461013295823&quot;, colsample_bytree = &quot;1&quot;, colsample_bynode = &quot;0.6&quot;, min_child_weight = &quot;49&quot;, subsample = &quot;0.756512506399304&quot;, importance = &quot;impurity&quot;, nthread = &quot;1&quot;, objective = &quot;binary:logistic&quot;, validate_parameters = &quot;TRUE&quot;
## xgb.attributes:
##   niter
## callbacks:
##   cb.evaluation.log()
## # of features: 5 
## niter: 500
## nfeatures : 5 
## evaluation_log:
##     iter training_logloss
##        1        0.6895728
##        2        0.6863896
## ---                      
##      499        0.4275463
##      500        0.4275110</code></pre>
<p>Como hemos hablado anteriormente, este último objeto es el modelo final entrenado, el cual contiene toda la información del pre-procesamiento de datos, por lo que en caso de ponerse en producción el modelo, sólo se necesita de este último elemento para poder realizar nuevas predicciones.</p>
<p>Antes de pasar al siguiente paso, es importante validar que hayamos hecho un uso correcto de las variables predictivas. En este momento es posible detectar variables que no estén aportando valor o variables que no debiéramos estar usando debido a que cometeríamos data leakage. Para enfrentar esto, ayuda estimar y ordenar el valor de importancia del modelo.</p>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb752-1"><a href="árboles-de-decisión.html#cb752-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(vip)</span>
<span id="cb752-2"><a href="árboles-de-decisión.html#cb752-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb752-3"><a href="árboles-de-decisión.html#cb752-3" aria-hidden="true" tabindex="-1"></a>final_xgboost_model <span class="sc">%&gt;%</span></span>
<span id="cb752-4"><a href="árboles-de-decisión.html#cb752-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">extract_fit_parsnip</span>() <span class="sc">%&gt;%</span></span>
<span id="cb752-5"><a href="árboles-de-decisión.html#cb752-5" aria-hidden="true" tabindex="-1"></a>  vip<span class="sc">::</span><span class="fu">vip</span>() <span class="sc">+</span> </span>
<span id="cb752-6"><a href="árboles-de-decisión.html#cb752-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Importancia de las variables&quot;</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-532-1.png" width="672" /></p>
<p><strong>Paso 10: Validar poder predictivo con datos de prueba</strong></p>
<p>Imaginemos por un momento que pasa un mes de tiempo desde que hicimos nuestro modelo, es hora de ponerlo a prueba prediciendo valores de nuevos elementos:</p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="árboles-de-decisión.html#cb753-1" aria-hidden="true" tabindex="-1"></a>class_results <span class="ot">&lt;-</span> <span class="fu">predict</span>(final_xgboost_model, telco_test, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb753-2"><a href="árboles-de-decisión.html#cb753-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="at">Churn =</span> telco_test<span class="sc">$</span>Churn) <span class="sc">%&gt;%</span> </span>
<span id="cb753-3"><a href="árboles-de-decisión.html#cb753-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Churn =</span> <span class="fu">factor</span>(Churn, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&#39;Yes&#39;</span>, <span class="st">&#39;No&#39;</span>))) </span>
<span id="cb753-4"><a href="árboles-de-decisión.html#cb753-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb753-5"><a href="árboles-de-decisión.html#cb753-5" aria-hidden="true" tabindex="-1"></a>class_results</span></code></pre></div>
<pre><code>## # A tibble: 2,113 × 3
##    .pred_No .pred_Yes Churn
##       &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;
##  1    0.900    0.100  No   
##  2    0.313    0.687  Yes  
##  3    0.730    0.270  No   
##  4    0.921    0.0788 No   
##  5    0.884    0.116  No   
##  6    0.576    0.424  No   
##  7    0.879    0.121  No   
##  8    0.846    0.154  No   
##  9    0.537    0.463  Yes  
## 10    0.922    0.0779 No   
## # … with 2,103 more rows</code></pre>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb755-1"><a href="árboles-de-decisión.html#cb755-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bind_rows</span>(</span>
<span id="cb755-2"><a href="árboles-de-decisión.html#cb755-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">roc_auc</span>(results_cla, <span class="at">truth =</span> Churn, <span class="at">estimate =</span> .pred_Yes),</span>
<span id="cb755-3"><a href="árboles-de-decisión.html#cb755-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pr_auc</span>(results_cla, <span class="at">truth =</span> Churn, <span class="at">estimate =</span> .pred_Yes)</span>
<span id="cb755-4"><a href="árboles-de-decisión.html#cb755-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.838
## 2 pr_auc  binary         0.644</code></pre>
<p>A continuación, conoceremos el nivel de sensitividad y especificidad para cada punto de corte:</p>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="árboles-de-decisión.html#cb757-1" aria-hidden="true" tabindex="-1"></a>roc_curve_data <span class="ot">&lt;-</span> <span class="fu">roc_curve</span>(</span>
<span id="cb757-2"><a href="árboles-de-decisión.html#cb757-2" aria-hidden="true" tabindex="-1"></a>  class_results, </span>
<span id="cb757-3"><a href="árboles-de-decisión.html#cb757-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> Churn, </span>
<span id="cb757-4"><a href="árboles-de-decisión.html#cb757-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_Yes</span>
<span id="cb757-5"><a href="árboles-de-decisión.html#cb757-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb757-6"><a href="árboles-de-decisión.html#cb757-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb757-7"><a href="árboles-de-decisión.html#cb757-7" aria-hidden="true" tabindex="-1"></a>roc_curve_data</span></code></pre></div>
<pre><code>## # A tibble: 1,376 × 3
##    .threshold specificity sensitivity
##         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
##  1  -Inf          0                 1
##  2     0.0499     0                 1
##  3     0.0499     0.00129           1
##  4     0.0501     0.00194           1
##  5     0.0502     0.00517           1
##  6     0.0504     0.00582           1
##  7     0.0511     0.00646           1
##  8     0.0513     0.00711           1
##  9     0.0515     0.00776           1
## 10     0.0516     0.00840           1
## # … with 1,366 more rows</code></pre>
<p>A través de estas métricas es posible crear la curva ROC:</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="árboles-de-decisión.html#cb759-1" aria-hidden="true" tabindex="-1"></a>roc_curve_plot <span class="ot">&lt;-</span> roc_curve_data <span class="sc">%&gt;%</span> </span>
<span id="cb759-2"><a href="árboles-de-decisión.html#cb759-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">1</span> <span class="sc">-</span> specificity, <span class="at">y =</span> sensitivity)) <span class="sc">+</span></span>
<span id="cb759-3"><a href="árboles-de-decisión.html#cb759-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>, <span class="at">colour =</span> <span class="st">&#39;lightblue&#39;</span>) <span class="sc">+</span></span>
<span id="cb759-4"><a href="árboles-de-decisión.html#cb759-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>() <span class="sc">+</span></span>
<span id="cb759-5"><a href="árboles-de-decisión.html#cb759-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb759-6"><a href="árboles-de-decisión.html#cb759-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;ROC Curve&quot;</span>)<span class="sc">+</span></span>
<span id="cb759-7"><a href="árboles-de-decisión.html#cb759-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb759-8"><a href="árboles-de-decisión.html#cb759-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb759-9"><a href="árboles-de-decisión.html#cb759-9" aria-hidden="true" tabindex="-1"></a>roc_curve_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-536-1.png" width="672" /></p>
<p>De igual manera, podemos calcular la precisión y cobertura para cada punte de corte:</p>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="árboles-de-decisión.html#cb760-1" aria-hidden="true" tabindex="-1"></a>pr_curve_data <span class="ot">&lt;-</span> <span class="fu">pr_curve</span>(</span>
<span id="cb760-2"><a href="árboles-de-decisión.html#cb760-2" aria-hidden="true" tabindex="-1"></a>  class_results, </span>
<span id="cb760-3"><a href="árboles-de-decisión.html#cb760-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> Churn, </span>
<span id="cb760-4"><a href="árboles-de-decisión.html#cb760-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_Yes</span>
<span id="cb760-5"><a href="árboles-de-decisión.html#cb760-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb760-6"><a href="árboles-de-decisión.html#cb760-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb760-7"><a href="árboles-de-decisión.html#cb760-7" aria-hidden="true" tabindex="-1"></a>pr_curve_data</span></code></pre></div>
<pre><code>## # A tibble: 1,375 × 3
##    .threshold  recall precision
##         &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;
##  1    Inf     0           1    
##  2      0.753 0.00177     1    
##  3      0.750 0.00707     1    
##  4      0.749 0.0106      1    
##  5      0.746 0.0124      1    
##  6      0.744 0.0141      1    
##  7      0.740 0.0159      1    
##  8      0.736 0.0194      1    
##  9      0.736 0.0212      1    
## 10      0.736 0.0230      0.929
## # … with 1,365 more rows</code></pre>
<p>Y graficar su respectiva curva:</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="árboles-de-decisión.html#cb762-1" aria-hidden="true" tabindex="-1"></a>pr_curve_plot <span class="ot">&lt;-</span> pr_curve_data <span class="sc">%&gt;%</span> </span>
<span id="cb762-2"><a href="árboles-de-decisión.html#cb762-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> recall, <span class="at">y =</span> precision)) <span class="sc">+</span></span>
<span id="cb762-3"><a href="árboles-de-decisión.html#cb762-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb762-4"><a href="árboles-de-decisión.html#cb762-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">intercept =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb762-5"><a href="árboles-de-decisión.html#cb762-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="at">size =</span> <span class="dv">1</span>, <span class="at">colour =</span> <span class="st">&#39;lightblue&#39;</span>) <span class="sc">+</span></span>
<span id="cb762-6"><a href="árboles-de-decisión.html#cb762-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>() <span class="sc">+</span></span>
<span id="cb762-7"><a href="árboles-de-decisión.html#cb762-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Precision vs Recall&quot;</span>)<span class="sc">+</span></span>
<span id="cb762-8"><a href="árboles-de-decisión.html#cb762-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb762-9"><a href="árboles-de-decisión.html#cb762-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb762-10"><a href="árboles-de-decisión.html#cb762-10" aria-hidden="true" tabindex="-1"></a>pr_curve_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-538-1.png" width="672" /></p>

</div>
</div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="k-nearest-neighbor.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["amt22_aserta_intro2dsml.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
