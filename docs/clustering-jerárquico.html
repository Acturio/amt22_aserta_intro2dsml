<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 17 Clustering Jerárquico | Ciencia de Datos y Machine Learning</title>
  <meta name="description" content="Capítulo 17 Clustering Jerárquico | Ciencia de Datos y Machine Learning" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 17 Clustering Jerárquico | Ciencia de Datos y Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Capítulo 17 Clustering Jerárquico | Ciencia de Datos y Machine Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 17 Clustering Jerárquico | Ciencia de Datos y Machine Learning" />
  
  <meta name="twitter:description" content="Capítulo 17 Clustering Jerárquico | Ciencia de Datos y Machine Learning" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clustering-no-jerárquico.html"/>
<link rel="next" href="actividad-final.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/str_view-0.1.0/str_view.css" rel="stylesheet" />
<script src="libs/str_view-binding-1.4.1/str_view.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><img src="img/aserta-logo.png" width="280"></a></li|
|:-:|  
<center>Ciencia de Datos y Machine Learning</center>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>BIENVENIDA</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#alcances-del-curso"><i class="fa fa-check"></i>Alcances del curso</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#instructores"><i class="fa fa-check"></i>Instructores</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#temario"><i class="fa fa-check"></i>Temario</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-1-introducción-a-r-22-hrs"><i class="fa fa-check"></i>Módulo 1: Introducción a R (22 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-2-introducción-a-ciencia-de-datos-18-hrs"><i class="fa fa-check"></i>Módulo 2: Introducción a Ciencia de Datos (18 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-3-machine-learning-supervisado-38-hrs"><i class="fa fa-check"></i>Módulo 3: Machine Learning: Supervisado (38 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#módulo-4-machine-learning-no-supervisado-12-hrs"><i class="fa fa-check"></i>Módulo 4: Machine Learning: No Supervisado (12 hrs)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#requisitos"><i class="fa fa-check"></i>Requisitos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#duración-y-evaluación-del-curso"><i class="fa fa-check"></i>Duración y evaluación del curso</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recursos-y-dinámica-de-clase"><i class="fa fa-check"></i>Recursos y dinámica de clase</a></li>
</ul></li>
<li class="part"><span><b>Parte 1: Introducción</b></span></li>
<li class="chapter" data-level="1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html"><i class="fa fa-check"></i><b>1</b> Conceptos de Ciencia de Datos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#qué-es-ciencia-de-datos"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es Ciencia de Datos?</a>
<ul>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#definiendo-conceptos"><i class="fa fa-check"></i>Definiendo conceptos:</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#objetivos"><i class="fa fa-check"></i><b>1.2</b> Objetivos</a></li>
<li class="chapter" data-level="1.3" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#requisitos-1"><i class="fa fa-check"></i><b>1.3</b> Requisitos</a></li>
<li class="chapter" data-level="1.4" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aplicaciones"><i class="fa fa-check"></i><b>1.4</b> Aplicaciones</a></li>
<li class="chapter" data-level="1.5" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#tipos-de-algoritmos"><i class="fa fa-check"></i><b>1.5</b> Tipos de algoritmos</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aprendizaje-supervisado"><i class="fa fa-check"></i><b>1.5.1</b> Aprendizaje supervisado</a></li>
<li class="chapter" data-level="1.5.2" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aprendizaje-no-supervisado"><i class="fa fa-check"></i><b>1.5.2</b> Aprendizaje no supervisado</a></li>
<li class="chapter" data-level="1.5.3" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#aprendizaje-por-refuerzo"><i class="fa fa-check"></i><b>1.5.3</b> Aprendizaje por refuerzo</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#perfiles-de-un-equipo"><i class="fa fa-check"></i><b>1.6</b> Perfiles de un equipo</a>
<ul>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ingeniero-de-datos"><i class="fa fa-check"></i>1) Ingeniero de datos</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#decisor"><i class="fa fa-check"></i>2) Decisor</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#analista"><i class="fa fa-check"></i>3) Analista</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#analista-experto"><i class="fa fa-check"></i>4) Analista experto</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#estadístico"><i class="fa fa-check"></i>5) Estadístico</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ingeniero-de-machine-learning"><i class="fa fa-check"></i>6) Ingeniero de Machine Learning</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#científico-de-datos"><i class="fa fa-check"></i>7) Científico de Datos</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#gerente-de-análisis-líder-de-ciencia-de-datos"><i class="fa fa-check"></i>8) Gerente de Análisis / Líder de Ciencia de Datos</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#experto-cualitativo-científico-social"><i class="fa fa-check"></i>9) Experto Cualitativo / Científico Social</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#investigador"><i class="fa fa-check"></i>10) Investigador</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#extra-personal-adicional"><i class="fa fa-check"></i>Extra) Personal Adicional</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#google-data-career-path"><i class="fa fa-check"></i>Google Data Career Path</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#flujo-de-trabajo-en-ml"><i class="fa fa-check"></i><b>1.7</b> Flujo de trabajo en <em>ML</em></a></li>
<li class="chapter" data-level="1.8" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ciclo-de-un-proyecto"><i class="fa fa-check"></i><b>1.8</b> Ciclo de un proyecto</a></li>
<li class="chapter" data-level="1.9" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#taller-de-scoping"><i class="fa fa-check"></i><b>1.9</b> Taller de Scoping</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#data-maturity-framework"><i class="fa fa-check"></i><b>1.9.1</b> Data Maturity Framework</a></li>
<li class="chapter" data-level="1.9.2" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#scoping"><i class="fa fa-check"></i><b>1.9.2</b> Scoping</a></li>
<li class="chapter" data-level="" data-path="conceptos-de-ciencia-de-datos.html"><a href="conceptos-de-ciencia-de-datos.html#ejemplos"><i class="fa fa-check"></i>Ejemplos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducción-a-r.html"><a href="introducción-a-r.html"><i class="fa fa-check"></i><b>2</b> Introducción a R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#cómo-obtener-r"><i class="fa fa-check"></i><b>2.1</b> ¿Cómo obtener <em>R</em>?</a></li>
<li class="chapter" data-level="2.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#qué-es-rstudio"><i class="fa fa-check"></i><b>2.2</b> ¿Qué es RStudio?</a></li>
<li class="chapter" data-level="2.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#r-como-lenguaje-orientado-a-objetos"><i class="fa fa-check"></i><b>2.3</b> <em>R</em> como lenguaje orientado a objetos</a></li>
<li class="chapter" data-level="2.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#estructuras-de-almacenamiento"><i class="fa fa-check"></i><b>2.4</b> Estructuras de almacenamiento</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#operadores-de-asignación"><i class="fa fa-check"></i><b>2.4.1</b> Operadores de asignación</a></li>
<li class="chapter" data-level="2.4.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#variables"><i class="fa fa-check"></i><b>2.4.2</b> Variables</a></li>
<li class="chapter" data-level="2.4.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#vectores"><i class="fa fa-check"></i><b>2.4.3</b> Vectores</a></li>
<li class="chapter" data-level="2.4.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#matrices"><i class="fa fa-check"></i><b>2.4.4</b> Matrices</a></li>
<li class="chapter" data-level="2.4.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#arreglos"><i class="fa fa-check"></i><b>2.4.5</b> Arreglos</a></li>
<li class="chapter" data-level="2.4.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#data-frames"><i class="fa fa-check"></i><b>2.4.6</b> Data Frames</a></li>
<li class="chapter" data-level="2.4.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#listas"><i class="fa fa-check"></i><b>2.4.7</b> Listas</a></li>
<li class="chapter" data-level="2.4.8" data-path="introducción-a-r.html"><a href="introducción-a-r.html#ejercicios"><i class="fa fa-check"></i><b>2.4.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#funbas"><i class="fa fa-check"></i><b>2.5</b> Funciones básicas de R</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#qué-es-una-función-de-r"><i class="fa fa-check"></i><b>2.5.1</b> ¿Qué es una función de R?</a></li>
<li class="chapter" data-level="2.5.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#operaciones-básicas"><i class="fa fa-check"></i><b>2.5.2</b> Operaciones básicas</a></li>
<li class="chapter" data-level="2.5.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#pruebas-lógicas"><i class="fa fa-check"></i><b>2.5.3</b> Pruebas lógicas</a></li>
<li class="chapter" data-level="2.5.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#operadores-lógicos"><i class="fa fa-check"></i><b>2.5.4</b> Operadores lógicos</a></li>
<li class="chapter" data-level="2.5.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#funciones-sobre-vectores"><i class="fa fa-check"></i><b>2.5.5</b> Funciones sobre vectores</a></li>
<li class="chapter" data-level="2.5.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#función-rep"><i class="fa fa-check"></i><b>2.5.6</b> Función <code>rep</code></a></li>
<li class="chapter" data-level="2.5.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#función-seq"><i class="fa fa-check"></i><b>2.5.7</b> Función <code>seq</code></a></li>
<li class="chapter" data-level="2.5.8" data-path="introducción-a-r.html"><a href="introducción-a-r.html#ejercicios-1"><i class="fa fa-check"></i><b>2.5.8</b> EJERCICIOS</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#bucles"><i class="fa fa-check"></i><b>2.6</b> Estructuras de control</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-if"><i class="fa fa-check"></i><b>2.6.1</b> Instrucción <code>if</code></a></li>
<li class="chapter" data-level="2.6.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-if-else"><i class="fa fa-check"></i><b>2.6.2</b> Instrucción <code>if</code> <code>else</code></a></li>
<li class="chapter" data-level="2.6.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-ifelse"><i class="fa fa-check"></i><b>2.6.3</b> Instrucción <code>ifelse</code></a></li>
<li class="chapter" data-level="2.6.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-else-if"><i class="fa fa-check"></i><b>2.6.4</b> Instrucción else if</a></li>
<li class="chapter" data-level="2.6.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-for"><i class="fa fa-check"></i><b>2.6.5</b> Instrucción <code>for</code></a></li>
<li class="chapter" data-level="2.6.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-while"><i class="fa fa-check"></i><b>2.6.6</b> Instrucción <code>while</code></a></li>
<li class="chapter" data-level="2.6.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#instrucción-repeat"><i class="fa fa-check"></i><b>2.6.7</b> Instrucción <code>repeat</code></a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introducción-a-r.html"><a href="introducción-a-r.html#estilo"><i class="fa fa-check"></i><b>2.7</b> Guía de estilo</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introducción-a-r.html"><a href="introducción-a-r.html#nombres-de-los-archivos"><i class="fa fa-check"></i><b>2.7.1</b> Nombres de los archivos</a></li>
<li class="chapter" data-level="2.7.2" data-path="introducción-a-r.html"><a href="introducción-a-r.html#nombres-de-los-objetos"><i class="fa fa-check"></i><b>2.7.2</b> Nombres de los objetos</a></li>
<li class="chapter" data-level="2.7.3" data-path="introducción-a-r.html"><a href="introducción-a-r.html#longitud-de-una-línea-de-código"><i class="fa fa-check"></i><b>2.7.3</b> Longitud de una línea de código</a></li>
<li class="chapter" data-level="2.7.4" data-path="introducción-a-r.html"><a href="introducción-a-r.html#espacios"><i class="fa fa-check"></i><b>2.7.4</b> Espacios</a></li>
<li class="chapter" data-level="2.7.5" data-path="introducción-a-r.html"><a href="introducción-a-r.html#asignación"><i class="fa fa-check"></i><b>2.7.5</b> Asignación</a></li>
<li class="chapter" data-level="2.7.6" data-path="introducción-a-r.html"><a href="introducción-a-r.html#punto-y-coma"><i class="fa fa-check"></i><b>2.7.6</b> Punto y coma</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tidyverse.html"><a href="tidyverse.html"><i class="fa fa-check"></i><b>3</b> Tidyverse</a>
<ul>
<li class="chapter" data-level="3.1" data-path="tidyverse.html"><a href="tidyverse.html#lectura-de-archivos"><i class="fa fa-check"></i><b>3.1</b> Lectura de archivos</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="tidyverse.html"><a href="tidyverse.html#archivos-csv"><i class="fa fa-check"></i><b>3.1.1</b> Archivos <em>csv</em></a></li>
<li class="chapter" data-level="3.1.2" data-path="tidyverse.html"><a href="tidyverse.html#archivos-txt"><i class="fa fa-check"></i><b>3.1.2</b> Archivos txt</a></li>
<li class="chapter" data-level="3.1.3" data-path="tidyverse.html"><a href="tidyverse.html#archivos-xls-y-xlsx"><i class="fa fa-check"></i><b>3.1.3</b> Archivos <em>xls</em> y <em>xlsx</em></a></li>
<li class="chapter" data-level="3.1.4" data-path="tidyverse.html"><a href="tidyverse.html#archivos-json"><i class="fa fa-check"></i><b>3.1.4</b> Archivos json</a></li>
<li class="chapter" data-level="3.1.5" data-path="tidyverse.html"><a href="tidyverse.html#archivos-rds"><i class="fa fa-check"></i><b>3.1.5</b> Archivos rds</a></li>
<li class="chapter" data-level="3.1.6" data-path="tidyverse.html"><a href="tidyverse.html#bases-de-datos"><i class="fa fa-check"></i><b>3.1.6</b> Bases de Datos</a></li>
<li class="chapter" data-level="3.1.7" data-path="tidyverse.html"><a href="tidyverse.html#oracle-database"><i class="fa fa-check"></i><b>3.1.7</b> Oracle Database</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="tidyverse.html"><a href="tidyverse.html#consultas-de-datos"><i class="fa fa-check"></i><b>3.2</b> Consultas de datos</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="tidyverse.html"><a href="tidyverse.html#seleccionar-columnas"><i class="fa fa-check"></i><b>3.2.1</b> Seleccionar columnas</a></li>
<li class="chapter" data-level="3.2.2" data-path="tidyverse.html"><a href="tidyverse.html#filtrar-observaciones"><i class="fa fa-check"></i><b>3.2.2</b> Filtrar observaciones</a></li>
<li class="chapter" data-level="3.2.3" data-path="tidyverse.html"><a href="tidyverse.html#ordenar-registros"><i class="fa fa-check"></i><b>3.2.3</b> Ordenar registros</a></li>
<li class="chapter" data-level="3.2.4" data-path="tidyverse.html"><a href="tidyverse.html#agregar-modificar"><i class="fa fa-check"></i><b>3.2.4</b> Agregar / Modificar</a></li>
<li class="chapter" data-level="3.2.5" data-path="tidyverse.html"><a href="tidyverse.html#resumen-estadístico"><i class="fa fa-check"></i><b>3.2.5</b> Resumen estadístico</a></li>
<li class="chapter" data-level="3.2.6" data-path="tidyverse.html"><a href="tidyverse.html#agrupamiento"><i class="fa fa-check"></i><b>3.2.6</b> Agrupamiento</a></li>
<li class="chapter" data-level="3.2.7" data-path="tidyverse.html"><a href="tidyverse.html#cruces-de-tablas"><i class="fa fa-check"></i><b>3.2.7</b> Cruces de tablas</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="tidyverse.html"><a href="tidyverse.html#orden-y-estructura"><i class="fa fa-check"></i><b>3.3</b> Orden y estructura</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="tidyverse.html"><a href="tidyverse.html#pivote-horizontal"><i class="fa fa-check"></i><b>3.3.1</b> Pivote horizontal</a></li>
<li class="chapter" data-level="3.3.2" data-path="tidyverse.html"><a href="tidyverse.html#pivote-vertical"><i class="fa fa-check"></i><b>3.3.2</b> Pivote vertical</a></li>
<li class="chapter" data-level="3.3.3" data-path="tidyverse.html"><a href="tidyverse.html#unión-de-columnas"><i class="fa fa-check"></i><b>3.3.3</b> Unión de columnas</a></li>
<li class="chapter" data-level="3.3.4" data-path="tidyverse.html"><a href="tidyverse.html#separador-de-columnas"><i class="fa fa-check"></i><b>3.3.4</b> Separador de columnas</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tidyverse.html"><a href="tidyverse.html#manipulación-de-texto"><i class="fa fa-check"></i><b>3.4</b> Manipulación de texto</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="tidyverse.html"><a href="tidyverse.html#caracteres-especiales"><i class="fa fa-check"></i><b>3.4.1</b> Caracteres especiales</a></li>
<li class="chapter" data-level="3.4.2" data-path="tidyverse.html"><a href="tidyverse.html#tamaño-de-cadena"><i class="fa fa-check"></i><b>3.4.2</b> Tamaño de cadena</a></li>
<li class="chapter" data-level="3.4.3" data-path="tidyverse.html"><a href="tidyverse.html#concatenar"><i class="fa fa-check"></i><b>3.4.3</b> Concatenar</a></li>
<li class="chapter" data-level="3.4.4" data-path="tidyverse.html"><a href="tidyverse.html#extraer-y-reemplazar"><i class="fa fa-check"></i><b>3.4.4</b> Extraer y reemplazar</a></li>
<li class="chapter" data-level="3.4.5" data-path="tidyverse.html"><a href="tidyverse.html#expresiones-regulares"><i class="fa fa-check"></i><b>3.4.5</b> Expresiones regulares</a></li>
<li class="chapter" data-level="3.4.6" data-path="tidyverse.html"><a href="tidyverse.html#detectar-coincidencias"><i class="fa fa-check"></i><b>3.4.6</b> Detectar coincidencias</a></li>
<li class="chapter" data-level="3.4.7" data-path="tidyverse.html"><a href="tidyverse.html#contabilizar-coincidencias"><i class="fa fa-check"></i><b>3.4.7</b> Contabilizar coincidencias</a></li>
<li class="chapter" data-level="3.4.8" data-path="tidyverse.html"><a href="tidyverse.html#extraer-coincidencias"><i class="fa fa-check"></i><b>3.4.8</b> Extraer coincidencias</a></li>
<li class="chapter" data-level="3.4.9" data-path="tidyverse.html"><a href="tidyverse.html#reemplazar-coincidencias"><i class="fa fa-check"></i><b>3.4.9</b> Reemplazar coincidencias</a></li>
<li class="chapter" data-level="3.4.10" data-path="tidyverse.html"><a href="tidyverse.html#divisiones-mediante-patrones"><i class="fa fa-check"></i><b>3.4.10</b> Divisiones mediante patrones</a></li>
<li class="chapter" data-level="3.4.11" data-path="tidyverse.html"><a href="tidyverse.html#localización-de-coincidencias"><i class="fa fa-check"></i><b>3.4.11</b> Localización de coincidencias</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="tidyverse.html"><a href="tidyverse.html#manipulación-de-tiempo"><i class="fa fa-check"></i><b>3.5</b> Manipulación de tiempo</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="tidyverse.html"><a href="tidyverse.html#lectura-y-creación-de-datos-temporales"><i class="fa fa-check"></i><b>3.5.1</b> Lectura y creación de datos temporales</a></li>
<li class="chapter" data-level="3.5.2" data-path="tidyverse.html"><a href="tidyverse.html#extracción-de-datos-temporales"><i class="fa fa-check"></i><b>3.5.2</b> Extracción de datos temporales</a></li>
<li class="chapter" data-level="3.5.3" data-path="tidyverse.html"><a href="tidyverse.html#operaciones-temporales"><i class="fa fa-check"></i><b>3.5.3</b> Operaciones temporales</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="tidyverse.html"><a href="tidyverse.html#iteraciones"><i class="fa fa-check"></i><b>3.6</b> Iteraciones</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="tidyverse.html"><a href="tidyverse.html#bucles-1"><i class="fa fa-check"></i><b>3.6.1</b> Bucles</a></li>
<li class="chapter" data-level="3.6.2" data-path="tidyverse.html"><a href="tidyverse.html#bucles-dobles"><i class="fa fa-check"></i><b>3.6.2</b> Bucles dobles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="visualización.html"><a href="visualización.html"><i class="fa fa-check"></i><b>4</b> Visualización</a>
<ul>
<li class="chapter" data-level="4.1" data-path="visualización.html"><a href="visualización.html#eda-análisis-exploratorio-de-datos"><i class="fa fa-check"></i><b>4.1</b> EDA: Análisis Exploratorio de Datos</a></li>
<li class="chapter" data-level="4.2" data-path="visualización.html"><a href="visualización.html#geda-análisis-exploratorio-de-datos-gráficos"><i class="fa fa-check"></i><b>4.2</b> GEDA: Análisis Exploratorio de Datos Gráficos</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="visualización.html"><a href="visualización.html#lo-que-no-se-debe-hacer"><i class="fa fa-check"></i><b>4.2.1</b> Lo que no se debe hacer…</a></li>
<li class="chapter" data-level="4.2.2" data-path="visualización.html"><a href="visualización.html#principios-de-visualización"><i class="fa fa-check"></i><b>4.2.2</b> Principios de visualización</a></li>
<li class="chapter" data-level="4.2.3" data-path="visualización.html"><a href="visualización.html#principios-generales-del-diseño-analítico"><i class="fa fa-check"></i><b>4.2.3</b> Principios generales del diseño analítico:</a></li>
<li class="chapter" data-level="4.2.4" data-path="visualización.html"><a href="visualización.html#técnicas-de-visualización"><i class="fa fa-check"></i><b>4.2.4</b> Técnicas de visualización:</a></li>
<li class="chapter" data-level="4.2.5" data-path="visualización.html"><a href="visualización.html#indicadores-de-calidad-gráfica"><i class="fa fa-check"></i><b>4.2.5</b> Indicadores de calidad gráfica:</a></li>
<li class="chapter" data-level="4.2.6" data-path="visualización.html"><a href="visualización.html#gráficos-univariados"><i class="fa fa-check"></i><b>4.2.6</b> Gráficos univariados:</a></li>
<li class="chapter" data-level="4.2.7" data-path="visualización.html"><a href="visualización.html#gráficos-multivariados"><i class="fa fa-check"></i><b>4.2.7</b> Gráficos multivariados</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="visualización.html"><a href="visualización.html#creación-de-gráficos"><i class="fa fa-check"></i><b>4.3</b> Creación de gráficos</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="visualización.html"><a href="visualización.html#estéticas"><i class="fa fa-check"></i><b>4.3.1</b> Estéticas</a></li>
<li class="chapter" data-level="4.3.2" data-path="visualización.html"><a href="visualización.html#objetos-geométricos-o-capas"><i class="fa fa-check"></i><b>4.3.2</b> Objetos geométricos o capas</a></li>
<li class="chapter" data-level="4.3.3" data-path="visualización.html"><a href="visualización.html#facetas"><i class="fa fa-check"></i><b>4.3.3</b> Facetas</a></li>
<li class="chapter" data-level="4.3.4" data-path="visualización.html"><a href="visualización.html#más-sobre-estéticas"><i class="fa fa-check"></i><b>4.3.4</b> Más sobre estéticas</a></li>
<li class="chapter" data-level="4.3.5" data-path="visualización.html"><a href="visualización.html#quick-view"><i class="fa fa-check"></i><b>4.3.5</b> Quick View</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="visualización.html"><a href="visualización.html#análisis-univariado"><i class="fa fa-check"></i><b>4.4</b> Análisis univariado</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="visualización.html"><a href="visualización.html#variables-numéricas"><i class="fa fa-check"></i><b>4.4.1</b> Variables numéricas</a></li>
<li class="chapter" data-level="4.4.2" data-path="visualización.html"><a href="visualización.html#variables-nominalescategóricas"><i class="fa fa-check"></i><b>4.4.2</b> Variables nominales/categóricas</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="visualización.html"><a href="visualización.html#análisis-multivariado"><i class="fa fa-check"></i><b>4.5</b> Análisis multivariado</a></li>
<li class="chapter" data-level="4.6" data-path="visualización.html"><a href="visualización.html#visualización-interactiva"><i class="fa fa-check"></i><b>4.6</b> Visualización interactiva</a>
<ul>
<li class="chapter" data-level="" data-path="visualización.html"><a href="visualización.html#warning"><i class="fa fa-check"></i>¡ Warning !</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="visualización.html"><a href="visualización.html#reporte-interactivos"><i class="fa fa-check"></i><b>4.7</b> Reporte interactivos</a></li>
</ul></li>
<li class="part"><span><b>Parte 2: Machine Learning</b></span></li>
<li class="chapter" data-level="5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html"><i class="fa fa-check"></i><b>5</b> Introducción a Machine Learning</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#análisis-supervisado-vs-no-supervisado"><i class="fa fa-check"></i><b>5.1</b> Análisis Supervisado vs No supervisado</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#regresión-vs-clasificación"><i class="fa fa-check"></i><b>5.1.1</b> Regresión vs clasificación</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#sesgo-vs-varianza"><i class="fa fa-check"></i><b>5.2</b> Sesgo vs varianza</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#errores-reducibles"><i class="fa fa-check"></i><b>5.2.1</b> Errores reducibles</a></li>
<li class="chapter" data-level="5.2.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#error-irreducible"><i class="fa fa-check"></i><b>5.2.2</b> Error irreducible</a></li>
<li class="chapter" data-level="5.2.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#balance-entre-sesgo-y-varianza-o-trade-off"><i class="fa fa-check"></i><b>5.2.3</b> Balance entre sesgo y varianza o Trade-off</a></li>
<li class="chapter" data-level="5.2.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#error-total"><i class="fa fa-check"></i><b>5.2.4</b> Error total</a></li>
<li class="chapter" data-level="5.2.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#overfitting"><i class="fa fa-check"></i><b>5.2.5</b> Overfitting</a></li>
<li class="chapter" data-level="5.2.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#underfitting"><i class="fa fa-check"></i><b>5.2.6</b> Underfitting</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#orden-y-estructura-de-proyecto"><i class="fa fa-check"></i><b>5.3</b> Orden y estructura de proyecto</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#plantilla-de-estructura-proyecto"><i class="fa fa-check"></i><b>5.3.1</b> Plantilla de estructura proyecto</a></li>
<li class="chapter" data-level="5.3.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#reproducibilidad"><i class="fa fa-check"></i><b>5.3.2</b> Reproducibilidad</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#partición-de-datos"><i class="fa fa-check"></i><b>5.4</b> Partición de datos</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#métodos-comunes-para-particionar-datos"><i class="fa fa-check"></i><b>5.4.1</b> Métodos comunes para particionar datos</a></li>
<li class="chapter" data-level="5.4.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#conjunto-de-validación"><i class="fa fa-check"></i><b>5.4.2</b> Conjunto de validación</a></li>
<li class="chapter" data-level="5.4.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#leave-one-out-cross-validation"><i class="fa fa-check"></i><b>5.4.3</b> Leave-one-out cross-validation</a></li>
<li class="chapter" data-level="5.4.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#v-fold-cross-validation"><i class="fa fa-check"></i><b>5.4.4</b> V Fold Cross Validation</a></li>
<li class="chapter" data-level="5.4.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#medidas-de-ajuste"><i class="fa fa-check"></i><b>5.4.5</b> Medidas de ajuste</a></li>
<li class="chapter" data-level="5.4.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#validación-cruzada-para-series-de-tiempo"><i class="fa fa-check"></i><b>5.4.6</b> Validación cruzada para series de tiempo</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#pre-procesamiento-de-datos"><i class="fa fa-check"></i><b>5.5</b> Pre-procesamiento de datos</a></li>
<li class="chapter" data-level="5.6" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#ingeniería-de-datos"><i class="fa fa-check"></i><b>5.6</b> Ingeniería de datos</a></li>
<li class="chapter" data-level="5.7" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#recetas"><i class="fa fa-check"></i><b>5.7</b> Recetas</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#pasos-y-estructura-de-recetas"><i class="fa fa-check"></i><b>5.7.1</b> Pasos y estructura de recetas</a></li>
<li class="chapter" data-level="5.7.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#imputaciones"><i class="fa fa-check"></i><b>5.7.2</b> Imputaciones</a></li>
<li class="chapter" data-level="5.7.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#agregar-o-modificar-columnas"><i class="fa fa-check"></i><b>5.7.3</b> Agregar o modificar columnas</a></li>
<li class="chapter" data-level="5.7.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#interacciones"><i class="fa fa-check"></i><b>5.7.4</b> Interacciones</a></li>
<li class="chapter" data-level="5.7.5" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#transformaciones-generales"><i class="fa fa-check"></i><b>5.7.5</b> Transformaciones generales</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#datos-y-tipos-de-modelos"><i class="fa fa-check"></i><b>5.8</b> Datos y tipos de modelos</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#separación-de-los-datos"><i class="fa fa-check"></i><b>5.8.1</b> Separación de los datos</a></li>
<li class="chapter" data-level="5.8.2" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#definición-de-la-receta"><i class="fa fa-check"></i><b>5.8.2</b> Definición de la receta</a></li>
<li class="chapter" data-level="5.8.3" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#separación-de-los-datos-1"><i class="fa fa-check"></i><b>5.8.3</b> Separación de los datos</a></li>
<li class="chapter" data-level="5.8.4" data-path="introducción-a-machine-learning.html"><a href="introducción-a-machine-learning.html#definición-de-la-receta-1"><i class="fa fa-check"></i><b>5.8.4</b> Definición de la receta</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regresión-lineal.html"><a href="regresión-lineal.html"><i class="fa fa-check"></i><b>6</b> Regresión Lineal</a>
<ul>
<li class="chapter" data-level="6.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#ajuste-de-modelo"><i class="fa fa-check"></i><b>6.1</b> Ajuste de modelo</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-de-parámetros-regresión-lineal-simple"><i class="fa fa-check"></i><b>6.1.1</b> Estimación de parámetros: Regresión lineal simple</a></li>
<li class="chapter" data-level="6.1.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#estimación-de-parámetros-regresión-lineal-múltiple"><i class="fa fa-check"></i><b>6.1.2</b> Estimación de parámetros: Regresión lineal múltiple</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#residuos-del-modelo"><i class="fa fa-check"></i><b>6.2</b> Residuos del modelo</a>
<ul>
<li class="chapter" data-level="" data-path="regresión-lineal.html"><a href="regresión-lineal.html#condiciones-para-el-ajuste-de-una-regresión-lineal"><i class="fa fa-check"></i>Condiciones para el ajuste de una regresión lineal:</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#métricas-de-desempeño"><i class="fa fa-check"></i><b>6.3</b> Métricas de desempeño</a></li>
<li class="chapter" data-level="6.4" data-path="regresión-lineal.html"><a href="regresión-lineal.html#implementación-en-r"><i class="fa fa-check"></i><b>6.4</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#coeficientes-del-modelo"><i class="fa fa-check"></i><b>6.4.1</b> Coeficientes del modelo</a></li>
<li class="chapter" data-level="6.4.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#métricas-de-desempeño-1"><i class="fa fa-check"></i><b>6.4.2</b> Métricas de desempeño</a></li>
<li class="chapter" data-level="6.4.3" data-path="regresión-lineal.html"><a href="regresión-lineal.html#gráfica-de-ajuste"><i class="fa fa-check"></i><b>6.4.3</b> Gráfica de ajuste</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="regresión-lineal.html"><a href="regresión-lineal.html#métodos-se-selección-de-variables"><i class="fa fa-check"></i><b>6.5</b> Métodos se selección de variables</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="regresión-lineal.html"><a href="regresión-lineal.html#forward-selection-selección-hacia-adelante"><i class="fa fa-check"></i><b>6.5.1</b> Forward selection (selección hacia adelante)</a></li>
<li class="chapter" data-level="6.5.2" data-path="regresión-lineal.html"><a href="regresión-lineal.html#backward-selection-selección-hacia-atrás"><i class="fa fa-check"></i><b>6.5.2</b> Backward selection (selección hacia atrás)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regresión-logística.html"><a href="regresión-logística.html"><i class="fa fa-check"></i><b>7</b> Regresión Logística</a>
<ul>
<li class="chapter" data-level="7.1" data-path="regresión-logística.html"><a href="regresión-logística.html#función-sigmoide"><i class="fa fa-check"></i><b>7.1</b> Función sigmoide</a></li>
<li class="chapter" data-level="7.2" data-path="regresión-logística.html"><a href="regresión-logística.html#ajuste-del-modelo"><i class="fa fa-check"></i><b>7.2</b> Ajuste del modelo</a></li>
<li class="chapter" data-level="7.3" data-path="regresión-logística.html"><a href="regresión-logística.html#clasificación-2"><i class="fa fa-check"></i><b>7.3</b> Clasificación</a></li>
<li class="chapter" data-level="7.4" data-path="regresión-logística.html"><a href="regresión-logística.html#métricas-de-desempeño-2"><i class="fa fa-check"></i><b>7.4</b> Métricas de desempeño</a></li>
<li class="chapter" data-level="7.5" data-path="regresión-logística.html"><a href="regresión-logística.html#implementación-en-r-1"><i class="fa fa-check"></i><b>7.5</b> Implementación en R</a></li>
<li class="chapter" data-level="7.6" data-path="regresión-logística.html"><a href="regresión-logística.html#matriz-de-confusión"><i class="fa fa-check"></i><b>7.6</b> Matriz de Confusión</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html"><i class="fa fa-check"></i><b>8</b> K-Nearest-Neighbor</a>
<ul>
<li class="chapter" data-level="8.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#clasificación-3"><i class="fa fa-check"></i><b>8.1</b> Clasificación</a></li>
<li class="chapter" data-level="8.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#regresión-2"><i class="fa fa-check"></i><b>8.2</b> Regresión</a></li>
<li class="chapter" data-level="8.3" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#ajuste-del-modelo-1"><i class="fa fa-check"></i><b>8.3</b> Ajuste del modelo</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#selección-de-hiper-parámetro-k"><i class="fa fa-check"></i><b>8.3.1</b> Selección de Hiper-parámetro K</a></li>
<li class="chapter" data-level="8.3.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#métodos-de-cálculo-de-la-distancia-entre-observaciones"><i class="fa fa-check"></i><b>8.3.2</b> Métodos de cálculo de la distancia entre observaciones</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#implementación-en-r-2"><i class="fa fa-check"></i><b>8.4</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#regresión-3"><i class="fa fa-check"></i><b>8.4.1</b> Regresión</a></li>
<li class="chapter" data-level="8.4.2" data-path="k-nearest-neighbor.html"><a href="k-nearest-neighbor.html#clasificación-4"><i class="fa fa-check"></i><b>8.4.2</b> Clasificación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html"><i class="fa fa-check"></i><b>9</b> Árboles de decisión</a>
<ul>
<li class="chapter" data-level="9.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#ajuste-del-modelo-2"><i class="fa fa-check"></i><b>9.1</b> Ajuste del modelo</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#attribute-selective-measure-asm"><i class="fa fa-check"></i><b>9.1.1</b> Attribute Selective Measure (ASM)</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#regularización-de-árboles"><i class="fa fa-check"></i><b>9.2</b> Regularización de árboles</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#nivel-de-profundidad-de-árbol"><i class="fa fa-check"></i><b>9.2.1</b> Nivel de profundidad de árbol</a></li>
<li class="chapter" data-level="9.2.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#poda-de-árbol"><i class="fa fa-check"></i><b>9.2.2</b> Poda de árbol</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#aprendizaje-conjunto"><i class="fa fa-check"></i><b>9.3</b> Aprendizaje conjunto</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging-vs.-boosting"><i class="fa fa-check"></i><b>9.3.1</b> Bagging vs. boosting</a></li>
<li class="chapter" data-level="9.3.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#error-out-of-bag"><i class="fa fa-check"></i><b>9.3.2</b> Error Out-Of-Bag</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#bagging"><i class="fa fa-check"></i><b>9.4</b> Bagging</a></li>
<li class="chapter" data-level="9.5" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#random-forest"><i class="fa fa-check"></i><b>9.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#qué-es"><i class="fa fa-check"></i><b>9.5.1</b> ¿Qué es?</a></li>
<li class="chapter" data-level="9.5.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#características-de-los-bosques-aleatorios"><i class="fa fa-check"></i><b>9.5.2</b> Características de los bosques aleatorios</a></li>
<li class="chapter" data-level="9.5.3" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#aplicar-árboles-de-decisión-en-un-bosque-aleatorio"><i class="fa fa-check"></i><b>9.5.3</b> Aplicar árboles de decisión en un bosque aleatorio</a></li>
<li class="chapter" data-level="9.5.4" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#ventajas-y-desventjas-de-bosques-aleatorios"><i class="fa fa-check"></i><b>9.5.4</b> Ventajas y desventjas de bosques aleatorios</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#implementación-de-rf-en-r"><i class="fa fa-check"></i><b>9.6</b> Implementación de RF en R</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#regresión-4"><i class="fa fa-check"></i><b>9.6.1</b> Regresión</a></li>
<li class="chapter" data-level="9.6.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#clasificación-5"><i class="fa fa-check"></i><b>9.6.2</b> Clasificación</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#boosting"><i class="fa fa-check"></i><b>9.7</b> Boosting</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#predicciones-boosting"><i class="fa fa-check"></i><b>9.7.1</b> Predicciones <em>Boosting</em></a></li>
<li class="chapter" data-level="9.7.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#modelos-boosting"><i class="fa fa-check"></i><b>9.7.2</b> Modelos <em>Boosting</em></a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#implementación-de-xgb-en-r"><i class="fa fa-check"></i><b>9.8</b> Implementación de XGB en R</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#xgboost-para-regresión"><i class="fa fa-check"></i><b>9.8.1</b> XGBoost para regresión</a></li>
<li class="chapter" data-level="9.8.2" data-path="árboles-de-decisión.html"><a href="árboles-de-decisión.html#xgboost-para-clasificación"><i class="fa fa-check"></i><b>9.8.2</b> XGBoost para clasificación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html"><i class="fa fa-check"></i><b>10</b> Regularización Elasticnet</a>
<ul>
<li class="chapter" data-level="10.1" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html#regularización-ridge"><i class="fa fa-check"></i><b>10.1</b> Regularización Ridge</a></li>
<li class="chapter" data-level="10.2" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html#regularización-lasso"><i class="fa fa-check"></i><b>10.2</b> Regularización Lasso</a></li>
<li class="chapter" data-level="10.3" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html#comparación-entre-ridge-y-lasso"><i class="fa fa-check"></i><b>10.3</b> Comparación entre Ridge y Lasso</a></li>
<li class="chapter" data-level="10.4" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html#elasticnet"><i class="fa fa-check"></i><b>10.4</b> ElasticNet</a></li>
<li class="chapter" data-level="10.5" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html#implementación-en-r-3"><i class="fa fa-check"></i><b>10.5</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html#regresión-5"><i class="fa fa-check"></i><b>10.5.1</b> Regresión</a></li>
<li class="chapter" data-level="10.5.2" data-path="regularización-elasticnet.html"><a href="regularización-elasticnet.html#clasificación-6"><i class="fa fa-check"></i><b>10.5.2</b> Clasificación</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html"><i class="fa fa-check"></i><b>11</b> Workflowsets &amp; Stacking</a>
<ul>
<li class="chapter" data-level="11.1" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#múltiples-recetas"><i class="fa fa-check"></i><b>11.1</b> Múltiples recetas</a></li>
<li class="chapter" data-level="11.2" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#múltiples-modelos"><i class="fa fa-check"></i><b>11.2</b> Múltiples modelos</a></li>
<li class="chapter" data-level="11.3" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#creación-de-workflowset"><i class="fa fa-check"></i><b>11.3</b> Creación de workflowset</a></li>
<li class="chapter" data-level="11.4" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#ajuste-y-evaluación-de-modelos"><i class="fa fa-check"></i><b>11.4</b> Ajuste y evaluación de modelos</a></li>
<li class="chapter" data-level="11.5" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#extracción-de-modelos"><i class="fa fa-check"></i><b>11.5</b> Extracción de modelos</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#selección-de-modelo"><i class="fa fa-check"></i><b>11.5.1</b> Selección de modelo</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#stacking"><i class="fa fa-check"></i><b>11.6</b> Stacking</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#elección-de-modelos"><i class="fa fa-check"></i><b>11.6.1</b> Elección de modelos</a></li>
<li class="chapter" data-level="11.6.2" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#ajuste-final"><i class="fa fa-check"></i><b>11.6.2</b> Ajuste final</a></li>
<li class="chapter" data-level="11.6.3" data-path="workflowsets-stacking.html"><a href="workflowsets-stacking.html#comparación-de-métricas"><i class="fa fa-check"></i><b>11.6.3</b> Comparación de métricas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html"><i class="fa fa-check"></i><b>12</b> Sesgo e Inequidad</a>
<ul>
<li class="chapter" data-level="12.1" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#propósito-vs-error"><i class="fa fa-check"></i><b>12.1</b> Propósito Vs Error</a></li>
<li class="chapter" data-level="12.2" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#métricas"><i class="fa fa-check"></i><b>12.2</b> Métricas</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#equal-parity-or-demographic-or-statistical-parity"><i class="fa fa-check"></i><b>12.2.1</b> Equal Parity or Demographic or Statistical Parity</a></li>
<li class="chapter" data-level="12.2.2" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#proportional-parity-o-impact-parity-o-minimizing-disparate-impact"><i class="fa fa-check"></i><b>12.2.2</b> Proportional Parity o Impact Parity o Minimizing Disparate Impact</a></li>
<li class="chapter" data-level="12.2.3" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#equalized-odds"><i class="fa fa-check"></i><b>12.2.3</b> Equalized odds</a></li>
<li class="chapter" data-level="12.2.4" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#predictive-rate-parity"><i class="fa fa-check"></i><b>12.2.4</b> Predictive rate parity</a></li>
<li class="chapter" data-level="12.2.5" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#accuracy-parity"><i class="fa fa-check"></i><b>12.2.5</b> Accuracy parity</a></li>
<li class="chapter" data-level="12.2.6" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#false-negative-parity-o-equal-oppportunity"><i class="fa fa-check"></i><b>12.2.6</b> False Negative Parity o Equal Oppportunity</a></li>
<li class="chapter" data-level="12.2.7" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#false-positive-parity"><i class="fa fa-check"></i><b>12.2.7</b> False Positive Parity</a></li>
<li class="chapter" data-level="12.2.8" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#negative-predictive-value-parity"><i class="fa fa-check"></i><b>12.2.8</b> Negative predictive value parity</a></li>
<li class="chapter" data-level="12.2.9" data-path="sesgo-e-inequidad.html"><a href="sesgo-e-inequidad.html#specificity-parity"><i class="fa fa-check"></i><b>12.2.9</b> Specificity parity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html"><i class="fa fa-check"></i><b>13</b> Interpretabilidad local</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html#interpretabilidad-lime"><i class="fa fa-check"></i><b>13.1</b> Interpretabilidad LIME</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html#proceso"><i class="fa fa-check"></i><b>13.1.1</b> Proceso</a></li>
<li class="chapter" data-level="13.1.2" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html#características-principales"><i class="fa fa-check"></i><b>13.1.2</b> Características principales</a></li>
<li class="chapter" data-level="13.1.3" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html#implementación-con-r"><i class="fa fa-check"></i><b>13.1.3</b> Implementación con <em>R</em></a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html#interpretabilidad-dalextra"><i class="fa fa-check"></i><b>13.2</b> Interpretabilidad DALEXtra</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html#otros-métodos"><i class="fa fa-check"></i><b>13.2.1</b> Otros métodos</a></li>
<li class="chapter" data-level="13.2.2" data-path="interpretabilidad-local.html"><a href="interpretabilidad-local.html#consejos"><i class="fa fa-check"></i><b>13.2.2</b> Consejos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="a-b---testing.html"><a href="a-b---testing.html"><i class="fa fa-check"></i><b>14</b> A / B - testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="a-b---testing.html"><a href="a-b---testing.html#elementos-en-riesgo"><i class="fa fa-check"></i><b>14.1</b> Elementos en riesgo</a></li>
<li class="chapter" data-level="14.2" data-path="a-b---testing.html"><a href="a-b---testing.html#costo-de-retención"><i class="fa fa-check"></i><b>14.2</b> Costo de retención</a></li>
<li class="chapter" data-level="14.3" data-path="a-b---testing.html"><a href="a-b---testing.html#diseño-experimental"><i class="fa fa-check"></i><b>14.3</b> Diseño experimental</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="a-b---testing.html"><a href="a-b---testing.html#qué-es-y-para-qué-sirve-muestreo"><i class="fa fa-check"></i><b>14.3.1</b> ¿Qué es y para qué sirve muestreo?</a></li>
<li class="chapter" data-level="14.3.2" data-path="a-b---testing.html"><a href="a-b---testing.html#muestreo-estratificado"><i class="fa fa-check"></i><b>14.3.2</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="14.3.3" data-path="a-b---testing.html"><a href="a-b---testing.html#marco-de-muestreo"><i class="fa fa-check"></i><b>14.3.3</b> Marco de muestreo</a></li>
<li class="chapter" data-level="14.3.4" data-path="a-b---testing.html"><a href="a-b---testing.html#tamaño-de-muestra"><i class="fa fa-check"></i><b>14.3.4</b> Tamaño de muestra</a></li>
<li class="chapter" data-level="14.3.5" data-path="a-b---testing.html"><a href="a-b---testing.html#distribución-muestral"><i class="fa fa-check"></i><b>14.3.5</b> Distribución muestral</a></li>
<li class="chapter" data-level="14.3.6" data-path="a-b---testing.html"><a href="a-b---testing.html#probabilidades-y-factores"><i class="fa fa-check"></i><b>14.3.6</b> Probabilidades y Factores</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="a-b---testing.html"><a href="a-b---testing.html#extracción-de-muestra"><i class="fa fa-check"></i><b>14.4</b> Extracción de muestra</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="a-b---testing.html"><a href="a-b---testing.html#muestreo-estratificado-1"><i class="fa fa-check"></i><b>14.4.1</b> Muestreo estratificado</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="a-b---testing.html"><a href="a-b---testing.html#estimación-muestral"><i class="fa fa-check"></i><b>14.5</b> Estimación muestral</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="a-b---testing.html"><a href="a-b---testing.html#implementación-de-diseño-muestral"><i class="fa fa-check"></i><b>14.5.1</b> Implementación de diseño muestral</a></li>
<li class="chapter" data-level="14.5.2" data-path="a-b---testing.html"><a href="a-b---testing.html#estimación-de-resultados"><i class="fa fa-check"></i><b>14.5.2</b> Estimación de resultados</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html"><i class="fa fa-check"></i><b>15</b> Análisis de Componentes Principales</a>
<ul>
<li class="chapter" data-level="15.1" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#construcción-matemática"><i class="fa fa-check"></i><b>15.1</b> Construcción matemática</a></li>
<li class="chapter" data-level="15.2" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#implementación-en-r-6"><i class="fa fa-check"></i><b>15.2</b> Implementación en R</a></li>
<li class="chapter" data-level="15.3" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#reducción-de-dimensión"><i class="fa fa-check"></i><b>15.3</b> Reducción de dimensión</a></li>
<li class="chapter" data-level="15.4" data-path="análisis-de-componentes-principales.html"><a href="análisis-de-componentes-principales.html#representación-gráfica"><i class="fa fa-check"></i><b>15.4</b> Representación gráfica</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html"><i class="fa fa-check"></i><b>16</b> Clustering No Jerárquico</a>
<ul>
<li class="chapter" data-level="16.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#cálculo-de-distancia"><i class="fa fa-check"></i><b>16.1</b> Cálculo de distancia</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#distancias-homogéneas"><i class="fa fa-check"></i><b>16.1.1</b> Distancias homogéneas</a></li>
<li class="chapter" data-level="16.1.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#distancias-mixtas"><i class="fa fa-check"></i><b>16.1.2</b> Distancias mixtas</a></li>
<li class="chapter" data-level="16.1.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#visualización-de-distancias"><i class="fa fa-check"></i><b>16.1.3</b> Visualización de distancias</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#k---means"><i class="fa fa-check"></i><b>16.2</b> K - means</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#ajuste-de-modelo-cómo-funciona-el-algortimo"><i class="fa fa-check"></i><b>16.2.1</b> Ajuste de modelo: ¿Cómo funciona el algortimo?</a></li>
<li class="chapter" data-level="16.2.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#calidad-de-ajuste"><i class="fa fa-check"></i><b>16.2.2</b> Calidad de ajuste</a></li>
<li class="chapter" data-level="16.2.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#cómo-seleccionamos-k"><i class="fa fa-check"></i><b>16.2.3</b> ¿Cómo seleccionamos K?</a></li>
<li class="chapter" data-level="16.2.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-7"><i class="fa fa-check"></i><b>16.2.4</b> Implementación en R</a></li>
<li class="chapter" data-level="16.2.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#warnings"><i class="fa fa-check"></i><b>16.2.5</b> Warnings</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#partitioning-around-medoids-pam"><i class="fa fa-check"></i><b>16.3</b> Partitioning Around Medoids (PAM)</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#algoritmo-pam"><i class="fa fa-check"></i><b>16.3.1</b> Algoritmo PAM</a></li>
<li class="chapter" data-level="16.3.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-8"><i class="fa fa-check"></i><b>16.3.2</b> Implementación en R</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#dbscan"><i class="fa fa-check"></i><b>16.4</b> DBSCAN</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#algoritmo"><i class="fa fa-check"></i><b>16.4.1</b> Algoritmo</a></li>
<li class="chapter" data-level="16.4.2" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#estimación-de-parámetros"><i class="fa fa-check"></i><b>16.4.2</b> Estimación de parámetros</a></li>
<li class="chapter" data-level="16.4.3" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#implementación-en-r-9"><i class="fa fa-check"></i><b>16.4.3</b> Implementación en R</a></li>
<li class="chapter" data-level="16.4.4" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#ventajas-de-dbscan"><i class="fa fa-check"></i><b>16.4.4</b> Ventajas de DBSCAN</a></li>
<li class="chapter" data-level="16.4.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#aplicación-dbscan"><i class="fa fa-check"></i><b>16.4.5</b> Aplicación DBSCAN</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="clustering-no-jerárquico.html"><a href="clustering-no-jerárquico.html#comparación-de-algoritmos"><i class="fa fa-check"></i><b>16.5</b> Comparación de algoritmos</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html"><i class="fa fa-check"></i><b>17</b> Clustering Jerárquico</a>
<ul>
<li class="chapter" data-level="17.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#agglomerative-divise-clustering"><i class="fa fa-check"></i><b>17.1</b> Agglomerative &amp; Divise Clustering</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#algoritmo-1"><i class="fa fa-check"></i><b>17.1.1</b> Algoritmo</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#implementación-en-r-10"><i class="fa fa-check"></i><b>17.2</b> Implementación en R</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#preparación-y-estructuración-de-datos"><i class="fa fa-check"></i><b>17.2.1</b> Preparación y estructuración de datos</a></li>
<li class="chapter" data-level="17.2.2" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#medidas-de-disimilaridad"><i class="fa fa-check"></i><b>17.2.2</b> Medidas de (di)similaridad</a></li>
<li class="chapter" data-level="17.2.3" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#función-liga"><i class="fa fa-check"></i><b>17.2.3</b> Función Liga</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#dendogramas"><i class="fa fa-check"></i><b>17.3</b> Dendogramas</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#selección-de-grupos"><i class="fa fa-check"></i><b>17.3.1</b> Selección de grupos</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#heatmaps"><i class="fa fa-check"></i><b>17.4</b> Heatmaps</a></li>
<li class="chapter" data-level="17.5" data-path="clustering-jerárquico.html"><a href="clustering-jerárquico.html#tendencia-de-factibilidad"><i class="fa fa-check"></i><b>17.5</b> Tendencia de factibilidad</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="actividad-final.html"><a href="actividad-final.html"><i class="fa fa-check"></i><b>18</b> ¡Actividad FINAL!</a></li>
<li class="divider"></li>
<li><a href="./"><img src="img/amat-logo.png" width="280"></a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Ciencia de Datos y Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="clustering-jerárquico" class="section level1 hasAnchor" number="17">
<h1><span class="header-section-number">Capítulo 17</span> Clustering Jerárquico<a href="clustering-jerárquico.html#clustering-jerárquico" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En esta sección se analizarán diferentes metodologías que tienen como propósito realizar segmentaciones de unidades de manera jerárquica, es decir, a partir de un único grupo se van agrupando o separando los individuos dependiendo de qué tan lejanos o cercanos se encuentran unos de otros. A diferencia del clustering por partición (no jerárquico), este no requiere de la pre-especificación del número de clusters a producir.</p>
<p>El clustering jerárquico se divide en dos tipos:</p>
<p><strong>1) Clustering aglomerativo.</strong></p>
<p><strong>2) Clustering divisivo.</strong></p>
<p>Las principales metodologías a revisar serán:</p>
<ul>
<li><p>Liga simple o vecino más cercano</p></li>
<li><p>Liga compleja o vecino más lejano</p></li>
<li><p>Liga promedio</p></li>
<li><p>Liga centroide</p></li>
<li><p>Varianza mínima de Ward</p></li>
</ul>
<p><img src="img/17-hclus/01-clusters.jpeg" width="350pt" /><img src="img/17-hclus/02-clusters.jpeg" width="350pt" /><img src="img/17-hclus/03-clusters.jpeg" width="350pt" /><img src="img/17-hclus/04-clusters.jpeg" width="350pt" /></p>
<p>A partir del concepto de distancia entre puntos en un espacio de <em>N</em> dimensiones (variables), se realiza la agrupación de elementos para posteriormente calcular cuántos <strong>grupos</strong> es conveniente usar. Este proceso puede ser graficado de múltiples formas, sin embargo, la visualización más usada corresponde al <strong>dendograma</strong>, el cual es un gráfico como el presentado a continuación:</p>
<p><img src="img/17-hclus/06-Hierarchical-Clustering.webp" width="400pt" style="display: block; margin: auto;" /></p>
<ul>
<li><p>El eje horizontal representa los <strong>puntos de datos</strong>.</p></li>
<li><p>La altura a lo largo del eje vertical representa la <strong>distancia entre los grupos</strong>.</p></li>
<li><p>Las líneas verticales en el gráfico representan grupos.</p></li>
<li><p>La altura de estas líneas representa la distancia desde el grupo más cercano.</p></li>
</ul>
<p>Podemos encontrar el número de conglomerados que mejor representan los grupos en los datos usando el dendrograma.</p>
<p><img src="img/17-hclus/07-Hierarchical-Clustering-1.webp" width="400pt" style="display: block; margin: auto;" /></p>
<p>Las líneas verticales con las mayores distancias entre ellas, es decir, la mayor altura en el mismo nivel, dan el número de grupos que mejor representan los datos.</p>
<div id="agglomerative-divise-clustering" class="section level2 hasAnchor" number="17.1">
<h2><span class="header-section-number">17.1</span> Agglomerative &amp; Divise Clustering<a href="clustering-jerárquico.html#agglomerative-divise-clustering" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El cluster aglomerativo es el tipo de clustering jerárquico más comúnmente usado para agrupar objetos en clusters basados en su similitud. También es conocido como <strong>AGNES</strong> (Agglomerative Nesting). El inverso del agrupamiento aglomerativo es el agrupamiento divisivo, en cual es conocido también como <strong>DIANA</strong> (<em>Divise Analysis</em>).</p>
<p><img src="img/17-hclus/08-agnes_diana_clustering.png" width="600pt" style="display: block; margin: auto;" /></p>
<div id="algoritmo-1" class="section level3 hasAnchor" number="17.1.1">
<h3><span class="header-section-number">17.1.1</span> Algoritmo<a href="clustering-jerárquico.html#algoritmo-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este algoritmo AGNES funciona de la manera <strong>“bottom-up”</strong>. Esto es:</p>
<ol style="list-style-type: decimal">
<li><p>cada objeto es <strong>inicialmente considerado como un cluster de único elemento</strong> (hoja).</p></li>
<li><p>En cada paso del algoritmo, los 2 clusters que son más <strong>similares</strong> son combinados en uno nuevo más grande.</p></li>
<li><p>El paso anterior es repetido hasta que todos los puntos son miembros de un <strong>único</strong> y gran cluster.</p></li>
</ol>
<p>Mientras que el algoritmo DIANA es del tipo <strong>top-down</strong>, funcionando de la siguiente manera:</p>
<ol style="list-style-type: decimal">
<li><p>Comienza con una raíz, en la que todos los elementos están incluidos en el mismo grupo.</p></li>
<li><p>En cada paso del algoritmo, los 2 clusters que son más <strong>disimilares</strong> son divididos en dos nuevos grupos.</p></li>
<li><p>El paso anterior es repetido hasta que todos los puntos son un cluster de elemento único en sí mismos.</p></li>
</ol>
<div class="infobox quicktip">
<p><strong>¡¡ TIP !!</strong></p>
<ul>
<li><p>Clustering aglomerativo es bueno en identificar pequeños clusters</p></li>
<li><p>Clustering divisivo es bueno para detectar los clusters grandes.</p></li>
</ul>
</div>
</div>
</div>
<div id="implementación-en-r-10" class="section level2 hasAnchor" number="17.2">
<h2><span class="header-section-number">17.2</span> Implementación en R<a href="clustering-jerárquico.html#implementación-en-r-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En esta sección se revisan las librerías y funciones que hacen posible estos algoritmos. Como metodología general, tenemos los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li><p>Preparación de datos</p></li>
<li><p>Cálculo de (di)similitudes entre pares de objetos en el conjunto de datos</p></li>
<li><p>Uso de <strong>función liga</strong> para agrupar los objetos en un árbol jerárquico basado en la distancia generada en los pasos anteriores.</p></li>
<li><p>Determinar el umbral de corte del árbol jerárquico para la creación de grupos.</p></li>
</ol>
<div id="preparación-y-estructuración-de-datos" class="section level3 hasAnchor" number="17.2.1">
<h3><span class="header-section-number">17.2.1</span> Preparación y estructuración de datos<a href="clustering-jerárquico.html#preparación-y-estructuración-de-datos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los datos deben ser presentados en un formato matricial, en donde los renglones representan a las observaciones y las columnas a las variables.</p>
<div class="sourceCode" id="cb1033"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1033-1"><a href="clustering-jerárquico.html#cb1033-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;USArrests&quot;</span>)</span>
<span id="cb1033-2"><a href="clustering-jerárquico.html#cb1033-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1033-3"><a href="clustering-jerárquico.html#cb1033-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">scale</span>(USArrests)</span>
<span id="cb1033-4"><a href="clustering-jerárquico.html#cb1033-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1033-5"><a href="clustering-jerárquico.html#cb1033-5" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df)</span></code></pre></div>
<pre><code>##                Murder   Assault   UrbanPop         Rape
## Alabama    1.24256408 0.7828393 -0.5209066 -0.003416473
## Alaska     0.50786248 1.1068225 -1.2117642  2.484202941
## Arizona    0.07163341 1.4788032  0.9989801  1.042878388
## Arkansas   0.23234938 0.2308680 -1.0735927 -0.184916602
## California 0.27826823 1.2628144  1.7589234  2.067820292
## Colorado   0.02571456 0.3988593  0.8608085  1.864967207</code></pre>
</div>
<div id="medidas-de-disimilaridad" class="section level3 hasAnchor" number="17.2.2">
<h3><span class="header-section-number">17.2.2</span> Medidas de (di)similaridad<a href="clustering-jerárquico.html#medidas-de-disimilaridad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Con el fin de decidir qué elementos deben ser combinados o divididos, se requieren métodos para medir la similaridad entre objetos. Existen muchos métodos para calcular la (di)similaridad de la información. Estas métricas ya se han considerados en capítulos anteriores.</p>
<p>En <em>R</em>, se puede usar la función <em>dist()</em> para calcular la distancia entre cada par de objetos en un conjunto de datos. El resultado de este cálculo es conocido como <strong>matriz de distancia de similitud</strong>.</p>
<div class="sourceCode" id="cb1035"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1035-1"><a href="clustering-jerárquico.html#cb1035-1" aria-hidden="true" tabindex="-1"></a>res_dist <span class="ot">&lt;-</span> <span class="fu">dist</span>(df, <span class="at">method =</span> <span class="st">&quot;euclidian&quot;</span>)</span>
<span id="cb1035-2"><a href="clustering-jerárquico.html#cb1035-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(res_dist)[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span></code></pre></div>
<pre><code>##             Alabama   Alaska  Arizona Arkansas California Colorado
## Alabama    0.000000 2.703754 2.293520 1.289810   3.263110 2.651067
## Alaska     2.703754 0.000000 2.700643 2.826039   3.012541 2.326519
## Arizona    2.293520 2.700643 0.000000 2.717758   1.310484 1.365031
## Arkansas   1.289810 2.826039 2.717758 0.000000   3.763641 2.831051
## California 3.263110 3.012541 1.310484 3.763641   0.000000 1.287619
## Colorado   2.651067 2.326519 1.365031 2.831051   1.287619 0.000000</code></pre>
<p>Esta función usa los métodos de distancia:</p>
<ul>
<li><p>Euclidiana</p></li>
<li><p>Máxima</p></li>
<li><p>Manhattan</p></li>
<li><p>Canberra</p></li>
<li><p>Binaria</p></li>
<li><p>Minkowski</p></li>
</ul>
<p>Es importante mencionar que existen otras distancias como la geodésica que pueden implementarse a partir de otras librerías. Para distancias cortas y en general, la distancia euclidiana funciona muy bien.</p>
</div>
<div id="función-liga" class="section level3 hasAnchor" number="17.2.3">
<h3><span class="header-section-number">17.2.3</span> Función Liga<a href="clustering-jerárquico.html#función-liga" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La función liga toma la información de la distancia que regresa de la función <em>dist()</em> y agrupa pares de objetos en clusters basados en su similaridad. Posteriormente, estos clusters nuevos son ligados a otros para crear clusters más grandes. Este proceso es iterativo hasta que todos los objetos en el conjunto original de datos son ligados juntos en un árbol jerárquico. Este proceso se lleva a cabo con la función: <em>hclust()</em>.</p>
<div class="sourceCode" id="cb1037"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1037-1"><a href="clustering-jerárquico.html#cb1037-1" aria-hidden="true" tabindex="-1"></a>res_hc <span class="ot">&lt;-</span> <span class="fu">hclust</span>(<span class="at">d =</span> res_dist, <span class="at">method =</span> <span class="st">&quot;complete&quot;</span>)</span>
<span id="cb1037-2"><a href="clustering-jerárquico.html#cb1037-2" aria-hidden="true" tabindex="-1"></a>res_hc</span></code></pre></div>
<pre><code>## 
## Call:
## hclust(d = res_dist, method = &quot;complete&quot;)
## 
## Cluster method   : complete 
## Distance         : euclidean 
## Number of objects: 50</code></pre>
<p><strong>Donde:</strong></p>
<blockquote>
<p><strong>d:</strong> Es la estructura de disimilaridad producida por la función <em>dist()</em></p>
<p><strong>method:</strong> El método de liga de aglomeración a ser usado para el cálculo de distancia entre clusters. Los siguientes valores están permitidos: “single”, “complete”, “average”, “median”, “centroid”, “ward.D”, “ward.D2”.</p>
</blockquote>
<p>Existen múltiples métodos de aglomeración (i.e. métodos liga). Los más comunes se describen a continuación:</p>
<ul>
<li><strong>Liga máxima o completa:</strong> La distancia entre dos clusters es definida como el valor máximo de todos los pares de distancia entre los elementos dentro del cluster 1 y los elementos en el cluster 2. Tiende a producir clusters compactos.</li>
</ul>
<p><img src="img/17-hclus/09-complete_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Liga mínima o simple:</strong> La distancia entre dos clusters es definida como el valor mínimo de todas las parejas de distancias entre los elementos en el cluster 1 y los elementos en el cluster 2. Tiende a producir clusters largos o pobres.</li>
</ul>
<p><img src="img/17-hclus/10-single_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Liga promedio o media:</strong> La distancia entre dos clusters es definida como la distancia promedio entre los elementos en el cluster 1 y los elementos en el cluster 2.</li>
</ul>
<p><span class="math display">\[Dist(C_1, C_2)= \frac{1}{n_1+n_2}\sum_{i=1}^{n_1}{\sum_{j=1}^{n_2}{D(i,j)}}\]</span></p>
<p><img src="img/17-hclus/11-average_linkage2.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Liga centroide:</strong> La distancia entre dos clusters está definida como la distancia del centroide del cluster 1 (un vector de medias con tamaño de <em>p</em> variables) y el centroide del cluster 2.</li>
</ul>
<p><img src="img/17-hclus/12-centroid_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Método de varianza mínima de Ward:</strong> Este método en vez de analizar la distancia entre grupos, analiza la varianza, por lo que se encarga de minimizar el total de la varianza intra-cluster (inercia). En cada paso, el par de clusters con distancia mínima entre clusters son unidos. Este método dice que <strong>la distancia entre dos clusters A y B, es qué tanto la varianza respecto del centroide incrementará cuando sean unidos.</strong></li>
</ul>
<p><img src="img/17-hclus/13-wards_linkage.png" width="600pt" style="display: block; margin: auto;" /></p>
<p>Sin importar el método usado, en cada etapa del proceso de clustering, los 2 elementos con la distancia liga más corta son unidos en un solo cluster.</p>
<div class="infobox quicktip">
<p><strong>¡¡ TIP !!</strong></p>
<p>Las ligas: completa y Ward´s son preferidas generalmente</p>
</div>
</div>
</div>
<div id="dendogramas" class="section level2 hasAnchor" number="17.3">
<h2><span class="header-section-number">17.3</span> Dendogramas<a href="clustering-jerárquico.html#dendogramas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La manera gráfica de representar el proceso de clustering jerárquico es mediante un dendograma. Los dendogramas pueden ser creados en <em>R</em> a partir de la función genérica <em>plot()</em>, sin embargo, se mostrarán otras funciones más novedosas para crear gráficos de mayor calidad.</p>
<div class="sourceCode" id="cb1039"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1039-1"><a href="clustering-jerárquico.html#cb1039-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb1039-2"><a href="clustering-jerárquico.html#cb1039-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1039-3"><a href="clustering-jerárquico.html#cb1039-3" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(res_hc, <span class="at">cex =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-759-1.png" width="672" /></p>
<p>En el dendograma superior cada hoja corresponde a un objeto. En la medida en que nos movemos hacia arriba en el árbol, los objetos que son similar a otros están combinados en ramas, las cuales se fusionan a mayor altura.</p>
<p>La altura de la fusión, proveída en el eje vertical, indica la (di)similaridad/distancia entre dos objetos/clusters. Entre más alta sea la altura de la fusión, menos similares son los objetos/clusters. Esta altura es conocida como <strong>la distancia de cophenetic</strong> entre dos objetos.</p>
<p>A fin de identificar sub-grupos, se puede cortar el dendograma en cierta altura, como se describe en las siguientes secciones.</p>
<p>Para validar que las distancias en la altura reflejen las distancias originales de manera precisa, se hace uso de la correlación entre las distancias originales y la distancia de cophenetic:</p>
<div class="sourceCode" id="cb1040"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1040-1"><a href="clustering-jerárquico.html#cb1040-1" aria-hidden="true" tabindex="-1"></a>res_coph <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(res_hc)</span>
<span id="cb1040-2"><a href="clustering-jerárquico.html#cb1040-2" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(res_coph)[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span></code></pre></div>
<pre><code>##             Alabama   Alaska  Arizona Arkansas California Colorado
## Alabama    0.000000 3.255433 4.420074 6.076642   4.420074 4.420074
## Alaska     3.255433 0.000000 4.420074 6.076642   4.420074 4.420074
## Arizona    4.420074 4.420074 0.000000 6.076642   2.445860 2.445860
## Arkansas   6.076642 6.076642 6.076642 0.000000   6.076642 6.076642
## California 4.420074 4.420074 2.445860 6.076642   0.000000 1.398859
## Colorado   4.420074 4.420074 2.445860 6.076642   1.398859 0.000000</code></pre>
<div class="sourceCode" id="cb1042"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1042-1"><a href="clustering-jerárquico.html#cb1042-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(res_coph, res_dist)</span></code></pre></div>
<pre><code>## [1] 0.6979437</code></pre>
<p><strong>Ejercicio</strong></p>
<ul>
<li>Usar las distintas ligas y determinar cuál de ellas funciona mejor (<em>Hint:</em> La que muestre correlación más alta entre las distancias originales y la distancia cophenetica)</li>
</ul>
<div id="selección-de-grupos" class="section level3 hasAnchor" number="17.3.1">
<h3><span class="header-section-number">17.3.1</span> Selección de grupos<a href="clustering-jerárquico.html#selección-de-grupos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Uno de los problemas del clustering jerárquico es que, NO dice cuántos clusters hay o dónde cortar el dendograma para formar los clusters.</p>
<p>Es posible cortar el árbol jerárquico a una altura dada con el fin de particionar los datos en clusters. La función <em>cutree()</em> puede ser usada para cortar el árbol en varios grupos al especificar ya el número deseado de grupos o la altura a cortar. Esta función regresa un vector que contiene el número de cluster de cada observación.</p>
<div class="sourceCode" id="cb1044"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1044-1"><a href="clustering-jerárquico.html#cb1044-1" aria-hidden="true" tabindex="-1"></a>groups_1 <span class="ot">&lt;-</span> <span class="fu">cutree</span>(res_hc, <span class="at">k =</span> <span class="dv">4</span>)</span>
<span id="cb1044-2"><a href="clustering-jerárquico.html#cb1044-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(groups_1)</span></code></pre></div>
<pre><code>##    Alabama     Alaska    Arizona   Arkansas California   Colorado 
##          1          1          2          3          2          2</code></pre>
<div class="sourceCode" id="cb1046"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1046-1"><a href="clustering-jerárquico.html#cb1046-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(groups_1)</span></code></pre></div>
<pre><code>## groups_1
##  1  2  3  4 
##  8 11 21 10</code></pre>
<div class="sourceCode" id="cb1048"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1048-1"><a href="clustering-jerárquico.html#cb1048-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb1048-2"><a href="clustering-jerárquico.html#cb1048-2" aria-hidden="true" tabindex="-1"></a> res_hc,</span>
<span id="cb1048-3"><a href="clustering-jerárquico.html#cb1048-3" aria-hidden="true" tabindex="-1"></a> <span class="at">k =</span> <span class="dv">4</span>,</span>
<span id="cb1048-4"><a href="clustering-jerárquico.html#cb1048-4" aria-hidden="true" tabindex="-1"></a> <span class="at">cex =</span> <span class="fl">0.5</span>,</span>
<span id="cb1048-5"><a href="clustering-jerárquico.html#cb1048-5" aria-hidden="true" tabindex="-1"></a> <span class="at">k_colors =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;purple&quot;</span>),</span>
<span id="cb1048-6"><a href="clustering-jerárquico.html#cb1048-6" aria-hidden="true" tabindex="-1"></a> <span class="at">color_labels_by_k =</span> <span class="cn">TRUE</span>,</span>
<span id="cb1048-7"><a href="clustering-jerárquico.html#cb1048-7" aria-hidden="true" tabindex="-1"></a> <span class="at">rect =</span> <span class="cn">TRUE</span></span>
<span id="cb1048-8"><a href="clustering-jerárquico.html#cb1048-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-762-1.png" width="672" /></p>
<p>Algunas variaciones estéticas sobre un dendograma se pueden realizar al cambiar determinados parámetros. Por ejemplo:</p>
<div class="sourceCode" id="cb1049"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1049-1"><a href="clustering-jerárquico.html#cb1049-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb1049-2"><a href="clustering-jerárquico.html#cb1049-2" aria-hidden="true" tabindex="-1"></a> res_hc,</span>
<span id="cb1049-3"><a href="clustering-jerárquico.html#cb1049-3" aria-hidden="true" tabindex="-1"></a> <span class="at">k =</span> <span class="dv">4</span>,</span>
<span id="cb1049-4"><a href="clustering-jerárquico.html#cb1049-4" aria-hidden="true" tabindex="-1"></a> <span class="at">cex =</span> <span class="fl">0.5</span>,</span>
<span id="cb1049-5"><a href="clustering-jerárquico.html#cb1049-5" aria-hidden="true" tabindex="-1"></a> <span class="at">k_colors =</span> <span class="st">&quot;jco&quot;</span>,</span>
<span id="cb1049-6"><a href="clustering-jerárquico.html#cb1049-6" aria-hidden="true" tabindex="-1"></a> <span class="at">type =</span> <span class="st">&quot;circular&quot;</span>,</span>
<span id="cb1049-7"><a href="clustering-jerárquico.html#cb1049-7" aria-hidden="true" tabindex="-1"></a> <span class="at">show_labels =</span> <span class="cn">TRUE</span></span>
<span id="cb1049-8"><a href="clustering-jerárquico.html#cb1049-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-763-1.png" width="672" /></p>
<div class="sourceCode" id="cb1050"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1050-1"><a href="clustering-jerárquico.html#cb1050-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb1050-2"><a href="clustering-jerárquico.html#cb1050-2" aria-hidden="true" tabindex="-1"></a> res_hc,</span>
<span id="cb1050-3"><a href="clustering-jerárquico.html#cb1050-3" aria-hidden="true" tabindex="-1"></a> <span class="at">k =</span> <span class="dv">4</span>,</span>
<span id="cb1050-4"><a href="clustering-jerárquico.html#cb1050-4" aria-hidden="true" tabindex="-1"></a> <span class="at">cex =</span> <span class="fl">0.5</span>,</span>
<span id="cb1050-5"><a href="clustering-jerárquico.html#cb1050-5" aria-hidden="true" tabindex="-1"></a> <span class="at">k_colors =</span> <span class="st">&quot;jco&quot;</span>,</span>
<span id="cb1050-6"><a href="clustering-jerárquico.html#cb1050-6" aria-hidden="true" tabindex="-1"></a> <span class="at">type =</span> <span class="st">&quot;phylogenic&quot;</span>,</span>
<span id="cb1050-7"><a href="clustering-jerárquico.html#cb1050-7" aria-hidden="true" tabindex="-1"></a> <span class="at">phylo_layout =</span> <span class="st">&quot;layout.gem&quot;</span>,</span>
<span id="cb1050-8"><a href="clustering-jerárquico.html#cb1050-8" aria-hidden="true" tabindex="-1"></a> <span class="at">repel =</span> T,</span>
<span id="cb1050-9"><a href="clustering-jerárquico.html#cb1050-9" aria-hidden="true" tabindex="-1"></a> <span class="at">show_labels =</span> <span class="cn">TRUE</span></span>
<span id="cb1050-10"><a href="clustering-jerárquico.html#cb1050-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-764-1.png" width="672" /></p>
<p>Usando la función <em>f_viz_cluster()</em> también es posible visualizar los clusters a través de un gráfico de dispersión. Las observaciones son presentadas en puntos usando el análisis de componentes principales.</p>
<div class="sourceCode" id="cb1051"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1051-1"><a href="clustering-jerárquico.html#cb1051-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_cluster</span>(</span>
<span id="cb1051-2"><a href="clustering-jerárquico.html#cb1051-2" aria-hidden="true" tabindex="-1"></a> <span class="fu">list</span>(<span class="at">data =</span> df, <span class="at">cluster =</span> groups_1),</span>
<span id="cb1051-3"><a href="clustering-jerárquico.html#cb1051-3" aria-hidden="true" tabindex="-1"></a> <span class="at">palette =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;purple&quot;</span>),</span>
<span id="cb1051-4"><a href="clustering-jerárquico.html#cb1051-4" aria-hidden="true" tabindex="-1"></a> <span class="at">ellipse.type =</span> <span class="st">&quot;convex&quot;</span>,</span>
<span id="cb1051-5"><a href="clustering-jerárquico.html#cb1051-5" aria-hidden="true" tabindex="-1"></a> <span class="at">repel =</span> T,</span>
<span id="cb1051-6"><a href="clustering-jerárquico.html#cb1051-6" aria-hidden="true" tabindex="-1"></a> <span class="at">show.clust.cent =</span> F</span>
<span id="cb1051-7"><a href="clustering-jerárquico.html#cb1051-7" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-765-1.png" width="672" /></p>
<p>Finalmente, es importante mencionar que la librería <em>cluster</em> ofrece un par de funciones que resumen todo el proceso anterior (scale, dist y hclus). Las funciones se usan de la siguiente forma:</p>
<div class="sourceCode" id="cb1052"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1052-1"><a href="clustering-jerárquico.html#cb1052-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb1052-2"><a href="clustering-jerárquico.html#cb1052-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1052-3"><a href="clustering-jerárquico.html#cb1052-3" aria-hidden="true" tabindex="-1"></a>res_agnes <span class="ot">&lt;-</span> <span class="fu">agnes</span>(</span>
<span id="cb1052-4"><a href="clustering-jerárquico.html#cb1052-4" aria-hidden="true" tabindex="-1"></a> <span class="at">x =</span> USArrests,</span>
<span id="cb1052-5"><a href="clustering-jerárquico.html#cb1052-5" aria-hidden="true" tabindex="-1"></a> <span class="at">stand =</span> T,</span>
<span id="cb1052-6"><a href="clustering-jerárquico.html#cb1052-6" aria-hidden="true" tabindex="-1"></a> <span class="at">metric =</span> <span class="st">&quot;euclidian&quot;</span>,</span>
<span id="cb1052-7"><a href="clustering-jerárquico.html#cb1052-7" aria-hidden="true" tabindex="-1"></a> <span class="at">method =</span> <span class="st">&quot;ward&quot;</span></span>
<span id="cb1052-8"><a href="clustering-jerárquico.html#cb1052-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1052-9"><a href="clustering-jerárquico.html#cb1052-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1052-10"><a href="clustering-jerárquico.html#cb1052-10" aria-hidden="true" tabindex="-1"></a>res_diana <span class="ot">&lt;-</span> <span class="fu">diana</span>(</span>
<span id="cb1052-11"><a href="clustering-jerárquico.html#cb1052-11" aria-hidden="true" tabindex="-1"></a> <span class="at">x =</span> USArrests,</span>
<span id="cb1052-12"><a href="clustering-jerárquico.html#cb1052-12" aria-hidden="true" tabindex="-1"></a> <span class="at">stand =</span> T,</span>
<span id="cb1052-13"><a href="clustering-jerárquico.html#cb1052-13" aria-hidden="true" tabindex="-1"></a> <span class="at">metric =</span> <span class="st">&quot;euclidian&quot;</span></span>
<span id="cb1052-14"><a href="clustering-jerárquico.html#cb1052-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1052-15"><a href="clustering-jerárquico.html#cb1052-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1052-16"><a href="clustering-jerárquico.html#cb1052-16" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb1052-17"><a href="clustering-jerárquico.html#cb1052-17" aria-hidden="true" tabindex="-1"></a> res_diana, </span>
<span id="cb1052-18"><a href="clustering-jerárquico.html#cb1052-18" aria-hidden="true" tabindex="-1"></a> <span class="at">cex =</span> <span class="fl">0.6</span>, </span>
<span id="cb1052-19"><a href="clustering-jerárquico.html#cb1052-19" aria-hidden="true" tabindex="-1"></a> <span class="at">k =</span> <span class="dv">4</span>,</span>
<span id="cb1052-20"><a href="clustering-jerárquico.html#cb1052-20" aria-hidden="true" tabindex="-1"></a> <span class="at">color_labels_by_k =</span> <span class="cn">TRUE</span>,</span>
<span id="cb1052-21"><a href="clustering-jerárquico.html#cb1052-21" aria-hidden="true" tabindex="-1"></a> <span class="at">rect =</span> <span class="cn">TRUE</span></span>
<span id="cb1052-22"><a href="clustering-jerárquico.html#cb1052-22" aria-hidden="true" tabindex="-1"></a> )</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-766-1.png" width="672" /></p>
</div>
</div>
<div id="heatmaps" class="section level2 hasAnchor" number="17.4">
<h2><span class="header-section-number">17.4</span> Heatmaps<a href="clustering-jerárquico.html#heatmaps" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Otro modo de visualizar el clustering jerárquico es a través de los mapas de color. Existen diversas alternativas para mostrar estas aglomeraciones. Los heatmaps, permiten visualizar clusters de individuos y de características.</p>
<p>En las siguientes secciones se mostrarán diversas visualizaciones de clusters, las cuales podrán ser por individuos, por características o ambas. Como primer paso, se comienza con la preparación de datos.</p>
<div class="sourceCode" id="cb1053"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1053-1"><a href="clustering-jerárquico.html#cb1053-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb1053-2"><a href="clustering-jerárquico.html#cb1053-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb1053-3"><a href="clustering-jerárquico.html#cb1053-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gplots)</span>
<span id="cb1053-4"><a href="clustering-jerárquico.html#cb1053-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sf)</span>
<span id="cb1053-5"><a href="clustering-jerárquico.html#cb1053-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1053-6"><a href="clustering-jerárquico.html#cb1053-6" aria-hidden="true" tabindex="-1"></a>indice_marg <span class="ot">&lt;-</span> <span class="fu">st_read</span>(<span class="st">&#39;data/IMEF_2010.dbf&#39;</span>, <span class="at">quiet =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1053-7"><a href="clustering-jerárquico.html#cb1053-7" aria-hidden="true" tabindex="-1"></a>indice_marg <span class="sc">%&gt;%</span> <span class="fu">glimpse</span>()</span></code></pre></div>
<pre><code>## Rows: 32
## Columns: 16
## $ CVE_ENT &lt;chr&gt; &quot;01&quot;, &quot;02&quot;, &quot;03&quot;, &quot;04&quot;, &quot;05&quot;, &quot;06&quot;, &quot;07&quot;, &quot;08&quot;, &quot;09&quot;, &quot;10&quot;, &quot;1…
## $ AÑO     &lt;int&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 20…
## $ POB_TOT &lt;int&gt; 1184996, 3155070, 637026, 822441, 2748391, 650555, 4796580, 34…
## $ ANALF   &lt;dbl&gt; 3.274040, 2.600783, 3.234464, 8.370643, 2.645050, 5.157943, 17…
## $ SPRIM   &lt;dbl&gt; 14.754823, 12.987567, 14.273833, 22.541207, 12.168029, 18.4761…
## $ OVSDE   &lt;dbl&gt; 1.0649743, 0.4322072, 0.9436751, 6.4196750, 1.0916308, 0.68577…
## $ OVSEE   &lt;dbl&gt; 0.62347891, 0.94517891, 2.84464884, 2.59080046, 0.53707721, 0.…
## $ OVSAE   &lt;dbl&gt; 0.9854257, 3.5616214, 7.0865085, 9.7378176, 1.3908497, 1.17060…
## $ VHAC    &lt;dbl&gt; 30.33066, 29.05839, 31.73806, 45.96720, 30.26891, 31.32052, 53…
## $ OVPT    &lt;dbl&gt; 1.761813, 3.398537, 5.814081, 4.500699, 1.423701, 4.691477, 15…
## $ PL_5000 &lt;dbl&gt; 25.1626166, 10.3491523, 15.6188287, 30.8755279, 12.1486353, 14…
## $ PO2SM   &lt;dbl&gt; 33.64880, 21.86970, 23.29986, 45.51076, 30.04270, 32.04402, 69…
## $ IM      &lt;dbl&gt; -0.91086057, -1.14014880, -0.68128749, 0.43357139, -1.14000448…
## $ GM      &lt;chr&gt; &quot;Bajo&quot;, &quot;Muy bajo&quot;, &quot;Bajo&quot;, &quot;Alto&quot;, &quot;Muy bajo&quot;, &quot;Bajo&quot;, &quot;Muy a…
## $ LUGAR   &lt;int&gt; 28, 30, 23, 10, 29, 26, 2, 21, 32, 15, 14, 1, 6, 27, 22, 8, 19…
## $ NOM_ENT &lt;chr&gt; &quot;Aguascalientes&quot;, &quot;Baja California&quot;, &quot;Baja California Sur&quot;, &quot;C…</code></pre>
<div class="sourceCode" id="cb1055"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1055-1"><a href="clustering-jerárquico.html#cb1055-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> indice_marg <span class="sc">%&gt;%</span> </span>
<span id="cb1055-2"><a href="clustering-jerárquico.html#cb1055-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(ANALF<span class="sc">:</span>PO2SM) <span class="sc">%&gt;%</span> </span>
<span id="cb1055-3"><a href="clustering-jerárquico.html#cb1055-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale</span>(<span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1055-4"><a href="clustering-jerárquico.html#cb1055-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1055-5"><a href="clustering-jerárquico.html#cb1055-5" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(df) <span class="ot">&lt;-</span> indice_marg<span class="sc">$</span>NOM_ENT</span>
<span id="cb1055-6"><a href="clustering-jerárquico.html#cb1055-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1055-7"><a href="clustering-jerárquico.html#cb1055-7" aria-hidden="true" tabindex="-1"></a><span class="fu">heatmap.2</span>(</span>
<span id="cb1055-8"><a href="clustering-jerárquico.html#cb1055-8" aria-hidden="true" tabindex="-1"></a>  df,</span>
<span id="cb1055-9"><a href="clustering-jerárquico.html#cb1055-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">scale =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb1055-10"><a href="clustering-jerárquico.html#cb1055-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">cexCol =</span> <span class="fl">0.7</span>,</span>
<span id="cb1055-11"><a href="clustering-jerárquico.html#cb1055-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">cexRow =</span> <span class="fl">0.5</span>,</span>
<span id="cb1055-12"><a href="clustering-jerárquico.html#cb1055-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Heatmap - Marginación&quot;</span>,</span>
<span id="cb1055-13"><a href="clustering-jerárquico.html#cb1055-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="fu">bluered</span>(<span class="dv">32</span>),</span>
<span id="cb1055-14"><a href="clustering-jerárquico.html#cb1055-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">trace =</span> <span class="st">&quot;none&quot;</span>,</span>
<span id="cb1055-15"><a href="clustering-jerárquico.html#cb1055-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">density.info =</span> <span class="st">&quot;none&quot;</span></span>
<span id="cb1055-16"><a href="clustering-jerárquico.html#cb1055-16" aria-hidden="true" tabindex="-1"></a> )</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-767-1.png" width="672" /></p>
<p>El dendograma anterior tiene la ventaja de ser simple y limpio. Los parámetros son sencillos.</p>
<div class="sourceCode" id="cb1056"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1056-1"><a href="clustering-jerárquico.html#cb1056-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pheatmap)</span>
<span id="cb1056-2"><a href="clustering-jerárquico.html#cb1056-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1056-3"><a href="clustering-jerárquico.html#cb1056-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pheatmap</span>(</span>
<span id="cb1056-4"><a href="clustering-jerárquico.html#cb1056-4" aria-hidden="true" tabindex="-1"></a>  df,</span>
<span id="cb1056-5"><a href="clustering-jerárquico.html#cb1056-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">cutree_rows =</span> <span class="dv">5</span>,</span>
<span id="cb1056-6"><a href="clustering-jerárquico.html#cb1056-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">cutree_cols =</span> <span class="dv">2</span>,</span>
<span id="cb1056-7"><a href="clustering-jerárquico.html#cb1056-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">clustering_distance_rows =</span> <span class="st">&quot;euclidean&quot;</span>,</span>
<span id="cb1056-8"><a href="clustering-jerárquico.html#cb1056-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">clustering_distance_cols =</span> <span class="st">&quot;euclidean&quot;</span>,</span>
<span id="cb1056-9"><a href="clustering-jerárquico.html#cb1056-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">clustering_method =</span> <span class="st">&quot;ward.D&quot;</span>,</span>
<span id="cb1056-10"><a href="clustering-jerárquico.html#cb1056-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Heatmap - Ward´s Clustering&quot;</span></span>
<span id="cb1056-11"><a href="clustering-jerárquico.html#cb1056-11" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-768-1.png" width="672" /></p>
<p>Este segundo dendograma es uno de los más limpios y completos que hay. Se segmentan tanto renglones como columnas de acuerdo con la metodología especificada de clustering.</p>
<div class="sourceCode" id="cb1057"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1057-1"><a href="clustering-jerárquico.html#cb1057-1" aria-hidden="true" tabindex="-1"></a><span class="co"># devtools::install_github(&quot;jokergoo/ComplexHeatmap&quot;)</span></span>
<span id="cb1057-2"><a href="clustering-jerárquico.html#cb1057-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1057-3"><a href="clustering-jerárquico.html#cb1057-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ComplexHeatmap)</span>
<span id="cb1057-4"><a href="clustering-jerárquico.html#cb1057-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1057-5"><a href="clustering-jerárquico.html#cb1057-5" aria-hidden="true" tabindex="-1"></a><span class="fu">Heatmap</span>(</span>
<span id="cb1057-6"><a href="clustering-jerárquico.html#cb1057-6" aria-hidden="true" tabindex="-1"></a>  df,</span>
<span id="cb1057-7"><a href="clustering-jerárquico.html#cb1057-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">split =</span> indice_marg <span class="sc">%&gt;%</span> </span>
<span id="cb1057-8"><a href="clustering-jerárquico.html#cb1057-8" aria-hidden="true" tabindex="-1"></a>     <span class="fu">mutate</span>(<span class="at">GM =</span> <span class="fu">case_when</span>(</span>
<span id="cb1057-9"><a href="clustering-jerárquico.html#cb1057-9" aria-hidden="true" tabindex="-1"></a>        GM <span class="sc">==</span> <span class="st">&quot;Muy bajo&quot;</span> <span class="sc">~</span> <span class="st">&quot;MB&quot;</span>,</span>
<span id="cb1057-10"><a href="clustering-jerárquico.html#cb1057-10" aria-hidden="true" tabindex="-1"></a>        GM <span class="sc">==</span> <span class="st">&quot;Bajo&quot;</span> <span class="sc">~</span> <span class="st">&quot;B&quot;</span>,</span>
<span id="cb1057-11"><a href="clustering-jerárquico.html#cb1057-11" aria-hidden="true" tabindex="-1"></a>        GM <span class="sc">==</span> <span class="st">&quot;Medio&quot;</span> <span class="sc">~</span> <span class="st">&quot;M&quot;</span>,</span>
<span id="cb1057-12"><a href="clustering-jerárquico.html#cb1057-12" aria-hidden="true" tabindex="-1"></a>        GM <span class="sc">==</span> <span class="st">&quot;Alto&quot;</span> <span class="sc">~</span> <span class="st">&quot;A&quot;</span>,</span>
<span id="cb1057-13"><a href="clustering-jerárquico.html#cb1057-13" aria-hidden="true" tabindex="-1"></a>        GM <span class="sc">==</span> <span class="st">&quot;Muy alto&quot;</span> <span class="sc">~</span> <span class="st">&quot;MA&quot;</span></span>
<span id="cb1057-14"><a href="clustering-jerárquico.html#cb1057-14" aria-hidden="true" tabindex="-1"></a>     )) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(GM),</span>
<span id="cb1057-15"><a href="clustering-jerárquico.html#cb1057-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">name =</span> <span class="st">&quot;Scale&quot;</span>,</span>
<span id="cb1057-16"><a href="clustering-jerárquico.html#cb1057-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">clustering_distance_rows =</span> <span class="st">&quot;euclidean&quot;</span>,</span>
<span id="cb1057-17"><a href="clustering-jerárquico.html#cb1057-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">clustering_method_rows =</span> <span class="st">&quot;ward.D&quot;</span>,</span>
<span id="cb1057-18"><a href="clustering-jerárquico.html#cb1057-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">column_title =</span> <span class="st">&quot;Variables&quot;</span>,</span>
<span id="cb1057-19"><a href="clustering-jerárquico.html#cb1057-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">row_title_gp =</span> <span class="fu">gpar</span>(<span class="at">fontsize =</span> <span class="dv">12</span>),</span>
<span id="cb1057-20"><a href="clustering-jerárquico.html#cb1057-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">column_title_gp =</span> <span class="fu">gpar</span>(<span class="at">fontsize =</span> <span class="dv">12</span>),</span>
<span id="cb1057-21"><a href="clustering-jerárquico.html#cb1057-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">row_names_gp =</span> <span class="fu">gpar</span>(<span class="at">fontsize =</span> <span class="dv">8</span>)</span>
<span id="cb1057-22"><a href="clustering-jerárquico.html#cb1057-22" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-769-1.png" width="672" /></p>
<p>El último de los dendogramas presentados permite separar los renglones o columnas de acuerdo con alguna variable auxiliar especificada, lo cual puede servir para otro tipo de análisis cruzados.</p>
<p>Será responsabilidad de cada usuario determinar cuál es el dendograma que aporta más valor al análisis o reporte que está siendo presentado.</p>
</div>
<div id="tendencia-de-factibilidad" class="section level2 hasAnchor" number="17.5">
<h2><span class="header-section-number">17.5</span> Tendencia de factibilidad<a href="clustering-jerárquico.html#tendencia-de-factibilidad" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este análisis es considerado como la evaluación de factibilidad de implementar análisis de clustering. Antes de aplicar cualquier técnica de clustering vale la pena <strong>evaluar si el conjunto de datos contiene clusters naturales significativos</strong> (i.e. estructuras no aleatorias) o no. En caso de que sí existan estructuras conglomeradas naturales, se deberá proceder a identificar el número de clusters a extraer.</p>
<p><img src="img/17-hclus/14-blindly_analysis.jpg" width="600pt" style="display: block; margin: auto;" /></p>
<p>A diferencia de otros tipos de análisis, una desventaja que tiene el análisis de clustering es que en todo momento regresarán clusters incluso cuando los datos no contengan tal estructura, por lo que si <strong>ciegamente</strong> se implementa un método de clustering, este dividirá los datos en clusters debido a que es lo esperado a realizar. las librerías usadas en <em>R</em> serán <em>factoextra</em> y <em>hopkins</em>.</p>
<div class="sourceCode" id="cb1058"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1058-1"><a href="clustering-jerárquico.html#cb1058-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(iris, <span class="dv">5</span>)</span></code></pre></div>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
## 1          5.1         3.5          1.4         0.2  setosa
## 2          4.9         3.0          1.4         0.2  setosa
## 3          4.7         3.2          1.3         0.2  setosa
## 4          4.6         3.1          1.5         0.2  setosa
## 5          5.0         3.6          1.4         0.2  setosa</code></pre>
<div class="sourceCode" id="cb1060"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1060-1"><a href="clustering-jerárquico.html#cb1060-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> iris <span class="sc">%&gt;%</span> <span class="fu">select_if</span>(is.numeric)</span>
<span id="cb1060-2"><a href="clustering-jerárquico.html#cb1060-2" aria-hidden="true" tabindex="-1"></a>random_df <span class="ot">&lt;-</span> df <span class="sc">%&gt;%</span> </span>
<span id="cb1060-3"><a href="clustering-jerárquico.html#cb1060-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">apply</span>(<span class="dv">2</span>, <span class="cf">function</span>(x){<span class="fu">runif</span>(<span class="fu">length</span>(x), <span class="fu">min</span>(x), <span class="fu">max</span>(x))}) <span class="sc">%&gt;%</span> </span>
<span id="cb1060-4"><a href="clustering-jerárquico.html#cb1060-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as_tibble</span>()</span>
<span id="cb1060-5"><a href="clustering-jerárquico.html#cb1060-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1060-6"><a href="clustering-jerárquico.html#cb1060-6" aria-hidden="true" tabindex="-1"></a>df_scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(df)</span>
<span id="cb1060-7"><a href="clustering-jerárquico.html#cb1060-7" aria-hidden="true" tabindex="-1"></a>random_df_scaled <span class="ot">&lt;-</span> <span class="fu">scale</span>(random_df)</span></code></pre></div>
<p>Se comienza con una evaluación visual sobre los datos para evaluar la significancia de los clusters. Debido a que los más probable es que los datos tengan más de dos dimensiones, se aprovecha el análisis de componentes principales para representar los datos en un espacio de dimensión menor.</p>
<div class="sourceCode" id="cb1061"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1061-1"><a href="clustering-jerárquico.html#cb1061-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb1061-2"><a href="clustering-jerárquico.html#cb1061-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1061-3"><a href="clustering-jerárquico.html#cb1061-3" aria-hidden="true" tabindex="-1"></a>iris_plot <span class="ot">&lt;-</span> <span class="fu">fviz_pca_ind</span>(</span>
<span id="cb1061-4"><a href="clustering-jerárquico.html#cb1061-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prcomp</span>(df_scaled), <span class="at">title =</span> <span class="st">&quot;PCA - Iris data&quot;</span>,</span>
<span id="cb1061-5"><a href="clustering-jerárquico.html#cb1061-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">ggtheme =</span> <span class="fu">theme_classic</span>(),</span>
<span id="cb1061-6"><a href="clustering-jerárquico.html#cb1061-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend =</span> <span class="st">&quot;bottom&quot;</span></span>
<span id="cb1061-7"><a href="clustering-jerárquico.html#cb1061-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1061-8"><a href="clustering-jerárquico.html#cb1061-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1061-9"><a href="clustering-jerárquico.html#cb1061-9" aria-hidden="true" tabindex="-1"></a>random_plot <span class="ot">&lt;-</span> <span class="fu">fviz_pca_ind</span>(</span>
<span id="cb1061-10"><a href="clustering-jerárquico.html#cb1061-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">prcomp</span>(random_df_scaled), <span class="at">title =</span> <span class="st">&quot;PCA - Random data&quot;</span>,</span>
<span id="cb1061-11"><a href="clustering-jerárquico.html#cb1061-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">ggtheme =</span> <span class="fu">theme_classic</span>(),</span>
<span id="cb1061-12"><a href="clustering-jerárquico.html#cb1061-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">legend =</span> <span class="st">&quot;bottom&quot;</span></span>
<span id="cb1061-13"><a href="clustering-jerárquico.html#cb1061-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1061-14"><a href="clustering-jerárquico.html#cb1061-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1061-15"><a href="clustering-jerárquico.html#cb1061-15" aria-hidden="true" tabindex="-1"></a>iris_plot <span class="sc">+</span> random_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-772-1.png" width="672" /></p>
<p>Puede observarse en el primer gráfico que, al menos existen 2 clusters significativos, con posibilidad de que sean 3. A diferencia del gráfico de la derecha que no muestra una tendencia en la estructura conglomerativa.</p>
<p>Es sumamente importante realizar esta evaluación porque</p>
<div class="sourceCode" id="cb1062"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1062-1"><a href="clustering-jerárquico.html#cb1062-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12853</span>)</span>
<span id="cb1062-2"><a href="clustering-jerárquico.html#cb1062-2" aria-hidden="true" tabindex="-1"></a>km_res2 <span class="ot">&lt;-</span> <span class="fu">kmeans</span>(random_df_scaled, <span class="dv">3</span>)</span>
<span id="cb1062-3"><a href="clustering-jerárquico.html#cb1062-3" aria-hidden="true" tabindex="-1"></a>cluster_plot <span class="ot">&lt;-</span> <span class="fu">fviz_cluster</span>(</span>
<span id="cb1062-4"><a href="clustering-jerárquico.html#cb1062-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">data =</span> random_df_scaled, <span class="at">cluster =</span> km_res2<span class="sc">$</span>cluster),</span>
<span id="cb1062-5"><a href="clustering-jerárquico.html#cb1062-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">ellipse.type =</span> <span class="st">&quot;convex&quot;</span>, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">stand =</span> F,</span>
<span id="cb1062-6"><a href="clustering-jerárquico.html#cb1062-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">palette =</span> <span class="st">&quot;jco&quot;</span>, <span class="at">ggtheme =</span> <span class="fu">theme_classic</span>()</span>
<span id="cb1062-7"><a href="clustering-jerárquico.html#cb1062-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1062-8"><a href="clustering-jerárquico.html#cb1062-8" aria-hidden="true" tabindex="-1"></a>cluster_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-773-1.png" width="672" /></p>
<div class="sourceCode" id="cb1063"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1063-1"><a href="clustering-jerárquico.html#cb1063-1" aria-hidden="true" tabindex="-1"></a>den_plot <span class="ot">&lt;-</span> <span class="fu">fviz_dend</span>(</span>
<span id="cb1063-2"><a href="clustering-jerárquico.html#cb1063-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hclust</span>(<span class="fu">dist</span>(random_df_scaled), <span class="at">method =</span> <span class="st">&quot;ward.D&quot;</span>), <span class="at">k =</span> <span class="dv">3</span>, <span class="at">k_colors =</span> <span class="st">&quot;jco&quot;</span>,</span>
<span id="cb1063-3"><a href="clustering-jerárquico.html#cb1063-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">as.gplot =</span> T, <span class="at">show_labels =</span> F</span>
<span id="cb1063-4"><a href="clustering-jerárquico.html#cb1063-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1063-5"><a href="clustering-jerárquico.html#cb1063-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1063-6"><a href="clustering-jerárquico.html#cb1063-6" aria-hidden="true" tabindex="-1"></a>cluster_plot <span class="sc">+</span> den_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-773-2.png" width="672" /></p>
<p>Puede observarse que ambos métodos imponen una segmentación a los datos que son <strong>uniformemente aleatorios</strong> y que no contienen ninguna segmentación natural. Por esta razón, <strong>siempre</strong> deberá realizarse este análisis previamente y elegir si se desea proceder con el análisis.</p>
<p>El método anterior fue totalmente gráfico. Se procede a continuación a mostrar una metodología estadística para determinar la factibilidad de implementar análisis de clustering.</p>
<p><strong>El estadístico Hopkins</strong> es usado para evaluar la tendencia de clustering en un conjunto de datos. Mide la probabilidad de que un conjunto de datos dado sea generado por una distribución uniforme. En otras palabras, <strong>prueba la aleatoriedad espacial de los datos</strong>. Por ejemplo, Sea <em>D</em> un conjunto de datos real, el estadístico de Hopkins puede ser calculado de la siguiente forma:</p>
<div class="infobox note">
<p><strong>Proceso:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Muestrear aleatoriamente <em>n</em> puntos <span class="math inline">\((p_1, p_2, p_3, ..., p_n)\)</span> de D</p></li>
<li><p>Para cada punto <span class="math inline">\(p_i \in D\)</span>, encontrar su vecino más cercano <span class="math inline">\(p_j\)</span>; luego calcular la distancia entre <span class="math inline">\(p_i\)</span> y <span class="math inline">\(p_j\)</span> y denotarla como <span class="math inline">\(x_i = dist(p_i, p_j)\)</span></p></li>
<li><p>Generar un conjunto de datos simulado <span class="math inline">\((random_D)\)</span> tomado de una distribución uniformemente aleatoria con <em>n</em> puntos <span class="math inline">\((q_1, q_2, q_3, ..., q_n)\)</span> y de la misma variación que la original del conjunto <em>D</em>.</p></li>
<li><p>Para cada punto <span class="math inline">\(q_i \in random_D\)</span>, encontrar su vecino más cercano <span class="math inline">\(q_j\)</span> en <em>D</em>; posteriormente, calcular la distancia entre <span class="math inline">\(q_i\)</span> y <span class="math inline">\(q_j\)</span> y denotarla como <span class="math inline">\(y_i=dist(q_i, q_j)\)</span>.</p></li>
<li><p>Calcular el <strong>estadístico de Hopkins</strong> como la distancia media más cercana de vecinos en los datos aleatorios y dividirlos por la suma de las distancias medias de vecinos más cercanos de los datos reales y aleatorios:</p></li>
</ol>
<p><span class="math display">\[H=\frac{\sum_{i=1}^{n}{y_i}}{\sum_{i=1}^{n}{x_i} + \sum_{i=1}^{n}{y_i}}\]</span></p>
</div>
<p>Un valor cercano a 0.5 significa que <span class="math inline">\(\sum_{i=1}^{n}{y_i}\)</span> y <span class="math inline">\(\sum_{i=1}^{n}{x_i}\)</span> son similares uno del otro y por lo tanto, <em>D</em> es distribuida aleatoriamente.</p>
<p>Por lo tanto, las hipótesis nula y alternativa son definidas como sigue:</p>
<blockquote>
<ul>
<li><p>Hipótesis Nula: El conjunto de datos <em>D</em> es uniformemente distribuido (sin clusters significativos).</p></li>
<li><p>Hipótesis Alternativa: El conjunto de datos <em>D</em> no es distribuido uniformemente (contiene clusters significativos).</p></li>
</ul>
</blockquote>
<p><strong>Cuando el estadístico de Hopkins tiene valores cercanos a cero, entonces puede rechazarse la hipótesis nula y concluir que el conjunto de datos <em>D</em> tiene datos conglomerables significativos.</strong></p>
<div class="sourceCode" id="cb1064"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1064-1"><a href="clustering-jerárquico.html#cb1064-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(hopkins)</span>
<span id="cb1064-2"><a href="clustering-jerárquico.html#cb1064-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1064-3"><a href="clustering-jerárquico.html#cb1064-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">19735</span>)</span>
<span id="cb1064-4"><a href="clustering-jerárquico.html#cb1064-4" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> hopkins<span class="sc">::</span><span class="fu">hopkins</span>(df_scaled, <span class="fu">nrow</span>(df_scaled)<span class="sc">-</span><span class="dv">1</span>, <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## [1] 0.005107394</code></pre>
<p><strong>Este valor sugiere rechazar la hipótesis nula en favor de la alternativa.</strong></p>
<p>Por último, se compararán otros 2 gráficos con la disimilitud de los dos conjuntos de datos. La metodología de este gráfico lleva por nombre “Visual Assessment of Cluster Tendency” (VAT). Este método consiste de 3 pasos:</p>
<ol style="list-style-type: decimal">
<li><p>Calcula la matriz de disimilaridad (DM) entre objetos usando la distancia Euclidiana.</p></li>
<li><p>Re-ordena la DM de forma que los elementos similares estén cercanos unos de otros. Este proceso crea una Matriz de Di-similaridad Ordenada (ODM).</p></li>
<li><p>La ODM es mostrada como una imagen de disimilaridad ordenada, la cual es la salida visual de VAT.</p></li>
</ol>
<div class="sourceCode" id="cb1066"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1066-1"><a href="clustering-jerárquico.html#cb1066-1" aria-hidden="true" tabindex="-1"></a>dis_irirs_plot <span class="ot">&lt;-</span> <span class="fu">fviz_dist</span>(</span>
<span id="cb1066-2"><a href="clustering-jerárquico.html#cb1066-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dist</span>(df_scaled),</span>
<span id="cb1066-3"><a href="clustering-jerárquico.html#cb1066-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">show_labels =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb1066-4"><a href="clustering-jerárquico.html#cb1066-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Iris data&quot;</span>)</span>
<span id="cb1066-5"><a href="clustering-jerárquico.html#cb1066-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1066-6"><a href="clustering-jerárquico.html#cb1066-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1066-7"><a href="clustering-jerárquico.html#cb1066-7" aria-hidden="true" tabindex="-1"></a>dis_random_plot <span class="ot">&lt;-</span> <span class="fu">fviz_dist</span>(</span>
<span id="cb1066-8"><a href="clustering-jerárquico.html#cb1066-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dist</span>(random_df_scaled),</span>
<span id="cb1066-9"><a href="clustering-jerárquico.html#cb1066-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">show_labels =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb1066-10"><a href="clustering-jerárquico.html#cb1066-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Random data&quot;</span>)</span>
<span id="cb1066-11"><a href="clustering-jerárquico.html#cb1066-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1066-12"><a href="clustering-jerárquico.html#cb1066-12" aria-hidden="true" tabindex="-1"></a>dis_irirs_plot <span class="sc">+</span> dis_random_plot</span></code></pre></div>
<p><img src="amt22_aserta_intro2dsml_files/figure-html/unnamed-chunk-775-1.png" width="672" /></p>
<p><strong>Donde:</strong></p>
<ul>
<li><p>Rojo: Alta similaridad</p></li>
<li><p>Azul: Baja similaridad</p></li>
</ul>
<p>La matriz de disimilaridad anterior confirma que existe una estructura de cluster en el conjunto de datos Iris, pero no en el aleatorio.</p>
<p>La técnica <em>VAT</em> detecta la tendencia de clustering de forma visual al contar el número de bloques cuadradas sobre la diagonal en la imagen VAT.</p>
<p><strong>Ejercicio</strong></p>
<ul>
<li><p>Realizar una evaluación de tendencia de conglomeración con los datos de clientes</p></li>
<li><p>Realizar una evaluación de tendencia de conglomeración con los datos de entidades</p></li>
</ul>

<div class="watermark">
<img src="img/header.png" width="400">
</div>
</div>
</div>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script>

$('.pipehover_incremental tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).prevAll().addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});


$('.pipehover_select_one_row tr').hover(function() {
  $(this).removeClass()
  $(this).prevAll().removeClass()
  $(this).nextAll().removeClass()
  $(this).addClass('hover');
  $(this).closest('div').next().find('img').attr("src", $(this).attr("link"));
});

</script>
            </section>

          </div>
        </div>
      </div>
<a href="clustering-no-jerárquico.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="actividad-final.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["amt22_aserta_intro2dsml.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
