<div class="watermark"><img src="img/header.png" width="400"></div>

# Introducción a Ciencia de Datos

## ¿Qué es Ciencia de Datos?

```{r echo=FALSE,fig.align='center', out.width='500pt', out.height='500pt'}
knitr::include_graphics("img/01-intro2ds/12_data-science-applications.jpeg")
```

### Definiendo conceptos: {-}

**Estadistica** Disciplina que recolecta, organiza, analiza e interpreta datos. Lo hace a través de una población muestral generando estadística descriptiva y estadística inferencial.

  * La [estadística descriptiva](), como su nombre lo indica, se encarga de describir datos y obtener conclusiones. Se utilizan números (media, mediana, moda, mínimo, máximo, etc) para analizar datos y llegar a conclusiones de acuerdo a ellos.
  
  * La [estadística inferencial]() argumenta o infiere sus resultados a partir de las muestras de una población. Se intenta conseguir información al utilizar un procedimiento ordenado en el manejo de los datos de la muestra.
  
  * La [estadística predictiva]() busca estimar valores y escenarios futuros más probables de ocurrir a partir de referencias históricas previas. Se suelen ocupar como apoyo características y factores áltamente asociados al fenómeno que se desea predecir.
  

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds/01_muestra.jpg")
```


**Business Intelligence**: BI aprovecha el software y los servicios para transformar los datos en conocimientos prácticos que informan las decisiones empresariales estratégicas y tácticas de una organización. Las herramientas de BI acceden y analizan conjuntos de datos y presentan hallazgos analíticos en informes, resúmenes, tableros, gráficos, cuadros, -indicadores- o KPI's y mapas para proporcionar a los usuarios **inteligencia detallada sobre el estado del negocio**. BI esta enfocado en analizar la historia pasada para tomar decisiones hacia el futuro.

¿Qué característicastiene un KPI?

* Específicos
* Continuos y periódicos
* Objetivos
* Cuantificables
* Medibles
* Realistas
* Concisos
* Coherentes
* Relevantes  


```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds/04_bi.png")
```



**Machine Learning**: Machine learning --aprendizaje de máquina-- es una **rama de la inteligencia artificial** que permite que las máquinas aprendan de los patrones existentes en los datos. Se usan métodos computacionales para aprender de datos con el fin de producir reglas para mejorar el desempeño en alguna tarea o toma de decisión. (Está enfocado en la programación de máquinas para aprender de los patrones existentes en datos principalmente estructurados y anticiparse al futuro)

```{r echo=FALSE,fig.align='center', out.width='600pt'}
knitr::include_graphics("img/01-intro2ds/02_ml.png")
```

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds/03_supervisado_robo.png")
```

**Deep Learning**: El aprendizaje profundo es un subcampo del aprendizaje automático que se ocupa de los algoritmos **inspirados en la estructura y función del cerebro llamados redes neuronales artificiales.**

En *Deep Learning*, un modelo de computadora aprende a realizar tareas de clasificación directamente a partir de imágenes, texto o sonido. Los modelos de aprendizaje profundo pueden lograr una precisión de vanguardia, a veces superando el rendimiento a nivel humano. Los modelos se entrenan mediante el uso de un gran conjunto de datos etiquetados y arquitecturas de redes neuronales que contienen muchas capas. (Está enfocado en la programación de máquinas para el reconocimiento de imagenes y audio (datos no estructurados))

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds/05_reconocimiento.png")
```

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds/06_ml1.png")
```

**Big data** se refiere a los grandes y diversos conjuntos de información que crecen a un ritmo cada vez mayor. Abarca el volumen de información, la velocidad a la que se crea y recopila, y la variedad o alcance de los puntos de datos que se cubren. Los macrodatos a menudo provienen de la minería de datos y llegan en múltiples formatos.

```{r echo=FALSE,fig.align='center', out.width='600pt'}
knitr::include_graphics("img/01-intro2ds/07_big-data-8vs.jpg")
```


Es comun que se confunda los conceptos de *Big Data* y *Big Compute*, como habiamos mencionado *Big Data* se refiere a el procesamiento de conjuntos de datos que son más voluminosos y complejos que los tradicionales y *Big Compute* a herramientas y enfoques que utilizan una gran cantidad de recursos de CPU y memoria de forma coordinada para resolver problemas que usan algoritmos muy complejos.

```{r echo=FALSE,fig.align='center', out.width='600pt'}
knitr::include_graphics("img/01-intro2ds/07_bigdata.jpg")
```

Curiosidad: [Servidores en líquido para ser enfriados](https://www.xatakawindows.com/actualidad-en-redmond/servidores-liquido-hirviendo-esta-idea-microsoft-para-evitar-calentamiento-sus-equipos#:~:text=Con%20este%20sistema%2C%20el%20dispositivo,fr%C3%ADo%2C%20emplea%20uno%20en%20ebullici%C3%B3n.)

Curiosidad 2: [Centro de datos en el océano](https://www.bbc.com/mundo/noticias/2016/02/160202_microsoft_centro_datos_debajo_agua_mar_subamino_all)

</br> **Entonces, ¿qué NO es ciencia de datos?**

-   No es una tecnología
-   No es una herramienta
-   No es desarrollo de software
-   No es Business Intelligence\*
-   No es Big Data\*
-   No es Inteligencia Artificial\*
-   No es (solo) machine learning
-   No es (solo) deep learning
-   No es (solo) visualización
-   No es (solo) hacer modelos

## Objetivo de la Ciencia de Datos

- Los científicos de datos analizan qué preguntas necesitan respuesta y dónde encontrar los datos relacionados. Tienen conocimiento de negocio y habilidades analíticas, así como la capacidad de extraer, limpiar y presentar datos. Las empresas utilizan científicos de datos para obtener, administrar y analizar grandes cantidades de datos no estructurados. Luego, los resultados se sintetizan y comunican a las partes interesadas clave para impulsar la toma de decisiones estratégicas en la organización.

```{r echo=FALSE,fig.align='center', out.height='500pt', out.width='600pt'}
knitr::include_graphics("img/01-intro2ds/08_data_science_vd.png")
```

Fuente: [Blog post de Drew Conway](http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram)

Más sobre Conway: [Forbes 2016](https://www.forbes.com/sites/joshwolfe/2016/03/03/using-data-science-for-the-physical-world/?sh=614ac5b0150e)

## ¿Qué se requiere para hacer Ciencia de Datos?

- **Background científico:** Conocimientos generales de probabilidad, estadística, álgebra lineal, cálculo, geometría análitica, programación, conocimientos computacionales... etc

- **Datos relevantes y suficientes:** Es indispensable saber si los datos con los que se trabajará son relevantes y suficientes, debemos evaluar qué preguntas podemos responder con los datos con los que contamos.

  - **Suficiencia:** Los datos con los que trabajamos tienen que ser representativos de la población en general, necesitamos que las características representadas en la información sean suficientes para aproximar a la población objetivo.

  - **Relevancia:** De igual manera los datos tienen que tener relevancia para la tarea que queremos resolver, por ejemplo, es probable que información sobre gusto en alimentos sea irrelevante para predecir número de hijos.

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds/09_relevancia_suficiencia.png")
```

- **Etiquetas:** Se necesita la intervención humana para etiquetar, clasificar e introducir los datos en el algoritmo.

```{r echo=FALSE,fig.align='center', out.height='400pt', out.width='600pt'}
knitr::include_graphics("img/01-intro2ds/10_etiquetas.png")
```

- **Software:** Existen distintos lenguajes de programación para realizar ciencia de datos:

```{r echo=FALSE,fig.align='center', out.height='300pt', out.width='600pt'}
knitr::include_graphics("img/01-intro2ds/11_lenguajes.png")
```

## Aplicaciones de Ciencia de Datos

Dependiendo de la industria en la que se quiera aplicar Machine Learning, podemos pensar en distintos enfoques, en la siguiente imagen se muestran algunos ejemplos:

```{r echo=FALSE, fig.align='center', out.height='350pt', out.width='600pt'}
knitr::include_graphics("img/01-intro2ds/12_applications-finances.png")
```

Podemos pensar en una infinidad de aplicaciones comerciales basadas en el análisis de datos. Con la intención de estructurar las posibles aplicaciones, se ofrece a contiuación una categorización que, aunque no es suficiente para englobar todos los posibles casos de uso, sí es sorprendente la cantidad de aplicaciones que abarca.

**1. Aplicaciones centradas en los clientes**

-   Incrementar beneficio al mejorar recomendaciones de productos
-   Upselling
-   Cross-selling
-   Reducir tasas de cancelación y mejorar tasas de retención
-   Personalizar experiencia de usuario
-   Mejorar el marketing dirigido
-   Análisis de sentimientos
-   Personalización de productos o servicios

**2. Optimización de problemas**

-   Optimización de precios
-   Ubicación de nuevas sucursales
-   Maximización de ganancias mediante producción de materias primas
-   Construcción de portafolios de inversión

**3. Predicción de demanda**

-   Número futuro de clientes
-   Número esperado de viajes en avión / camión / bicis
-   Número de contagios por un virus (demanda médica / medicamentos / etc)
-   Predicción de uso de recursos (luz / agua / gas)

**4. Análisis de detección de fraudes**

-   Detección de robo de identidad
-   Detección de transacciones ilícitas
-   Detección de servicios fraudulentos
-   Detección de zonas geográficas con actividades ilícitas

## Tipos de aprendizaje

Los algoritmos de Machine Learning se dividen en tres categorías, siendo las dos primeras las más comunes:

```{r, fig.align='center', echo=F, out.height='500pt', out.width='750pt'}
knitr::include_graphics("img/01-intro2ds/13_tipo_aprendizaje.png")
```

La diferencia entre el análisis supervisado y el no supervisado es la etiqueta, es decir, en el análisis supervisado tenemos una etiqueta "correcta" y el objetivo de los algoritmos es predecir esta etiqueta.

### Aprendizaje supervisado

En el aprendizaje supervisado, la idea principal es **aprender bajo supervisión**, donde la señal de supervisión se nombra como valor objetivo o etiqueta. Estos algoritmos cuentan con un aprendizaje previo basado en un **sistema de etiquetas** asociadas a unos datos que les permiten tomar decisiones o hacer predicciones. 

- Conocemos la respuesta correcta de antemano.

- Esta respuesta correcta fue "etiquetada" por un humano (la mayoría de las veces, en algunas circunstancias puede ser generada por otro algoritmo).

- Debido a que conocemos la respuesta correcta, existen muchas métricas de desempeño del modelo para verificar que nuestro algoritmo está haciendo las cosas "bien".

Algunos ejemplos son:

    - Un detector de spam que etiqueta un e-mail como spam o no.
    
    - Predecir precios de casas
    
    - Clasificación de imagenes
    
    - Predecir el clima
    
    - ¿Quiénes son los clientes descontentos?


#### Tipos de aprendizaje supervisado (Regresión vs clasificación) {-}

Existen dos tipos principales de aprendizaje supervisado, esto depende del tipo de la variable respuesta:

#### Clasificación {-}
En el aprendizaje supervisado, los algoritmos de clasificación se usan cuando el resultado es una **etiqueta discreta.** Esto quiere decir que se utilizan cuando la respuesta se fundamenta en conjunto finito de resultados.

#### Regresión {-} 
El análisis de regresión es un subcampo del aprendizaje automático supervisado cuyo objetivo es **establecer un método para la relación entre un cierto número de características y una variable objetivo continua.**

<br/>

```{r echo=FALSE,fig.align='center', out.height='450pt', out.width='700pt'}
knitr::include_graphics("img/01-intro2ds/13_regresion_clasificacion.png")
```

### Aprendizaje no supervisado

En el aprendizaje no supervisado, **carecemos de etiquetas**. Por lo tanto, necesitamos encontrar nuestro camino sin ninguna supervisión ni guía. Esto simplemente significa que necesitamos descubrir ¿qué es qué? por nosotros mismos.

- Aquí no tenemos la respuesta correcta de antemano ¿cómo podemos saber que el algoritmo está bien o mal?

- Estadísticamente podemos verificar que el algoritmo está bien

- Siempre tenemos que verificar con el cliente si los resultados que estamos obteniendo tienen sentido de negocio. Por ejemplo, número de grupos y características

```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds/14_nosupervisado_robo.png")
```

Algunos ejemplos son:

    - Encontrar segmentos de clientes.
    
    - Reducir la complejidad de un problema
    
    - Selección de variables
    
    - Encontrar grupos

    - Reducción de dimensionalidad


### Aprendizaje por refuerzo

Su objetivo es que un algoritmo aprenda a partir de la propia experiencia. Esto es, que sea capaz de tomar la mejor decisión ante diferentes situaciones de acuerdo a un proceso de prueba y error en el que se recompensan las decisiones correctas.

```{r echo=FALSE,fig.align='center', out.height='350pt', out.width='500pt'}
knitr::include_graphics("img/01-intro2ds/14_reinforcement_robot.png")
```


Algunos ejemplos son:

    - Optimización de campañas de marketing
    
    - Reconocimiento facial
    
    - Diagnósticos médicos

    - Clasificar secuencias de ADN








## Ciclo de un proyecto


```{r, fig.align='center', out.height='600pt', out.width='800pt', echo=F}
knitr::include_graphics("img/01-intro2ds-ciclo/01-etapas.png")
```

1. **Identificación del problema**

    - Debemos conocer si el problema es significativo, si el problema se puede resolver con ciencia de datos, y si habrá un compromiso real del lado de cliente/usuario/partner para implementar la solución con todas sus implicaciones: recursos físicos y humanos.
    
    
```{r echo=FALSE,fig.align='center', out.width='200pt', out.height='200pt'}
knitr::include_graphics("img/01-intro2ds-ciclo/02-identificacion.jpg")
```

2. **Scoping**

    - El objetivo es definir el alcance del proyecto y por lo tanto definir claramente los objetivos.

    - Conocer las acciones que se llevarán a cabo para cada objetivo. Estas definirán las soluciones analíticas a hacer.

    - Queremos saber si los datos con los que contamos son relevantes y suficientes.

    - Hacer visible los posibles conflictos éticos que se pueden tener en esta fase.

    - Debemos definir el cómo evaluaremos que el análisis de esos datos será balanceada entre eficiencia, efectividad y equidad.


```{r echo=FALSE,fig.align='center', out.width='200pt', out.height='200pt'}
knitr::include_graphics("img/01-intro2ds-ciclo/03-alcance.png")
```

3. **Adquisición de datos**

    - Adquisición, almacenamiento, entendimiento y preparación de los datos para después poder hacer analítica sober ellos.

    - Asegurar que en la transferencia estamos cumpliendo con el manejo adecuado de datos sensibles y privados.
    
    
```{r echo=FALSE,fig.align='center', out.width='200pt', out.height='300pt'}
knitr::include_graphics("img/01-intro2ds-ciclo/04-data-adquisition.webp")
```

4. **EDA**

    - El objetivo en esta fase es conocer los datos con los que contamos y contexto de negocio explicado a través de los mismos.

    - Identificamos datos faltantes, sugerimos cómo imputarlos.

    - Altamente apoyado de visualización y procesos de adquisición y limpieza de datos.


```{r echo=FALSE,fig.align='center', out.width='600pt', out.height='350pt'}
knitr::include_graphics("img/01-intro2ds-ciclo/05-eda.jpg")
```

5. **Formulación analítica**

    - Esta fase incluye empezar a formular nuestro problema como uno de ciencia de datos, el conocimiento adquirido en la fase de exploración nos permite conocer a mayor detalle del problema y por lo tanto de la solución adecuada.
    
```{r echo=FALSE,fig.align='center', out.width='450pt', out.height='300pt'}
knitr::include_graphics("img/01-intro2ds-ciclo/05-analytical-thinking.jpg")
```    
    

6. **Modelado**

    - Proceso iterativo para desarrollar diferentes "experimentos".

        - Mismo algoritmo/método diferentes hiperparámetros (grid search).
        - Diferentes algortimos.

    - Selección de un muy pequeño conjunto de modelos tomando en cuenta un balance entre interpretabilidad, complejidad, desempeño, fairness.

    - Correcta interpretación de los resultados de desempeño de cada modelo.
    
    
```{r echo=FALSE,fig.align='center'}
knitr::include_graphics("img/01-intro2ds-ciclo/06-formulacion.jpg")
```

7. **Validación**

    - Es muy importante poner a prueba el/los modelo/modelos seleccionados en la fase anterior. Esta prueba es en campo con datos reales, le llamamos prueba piloto.

    - Debemos medir el impacto causal que nuestro modelo tuvo en un ambiente real.
    
    
```{r echo=FALSE,fig.align='center', out.width='200pt', out.height='200pt'}
knitr::include_graphics("img/01-intro2ds-ciclo/07-validacion.jpg")
```

8. **Acciones a realizar**

    - Finalmente esta etapa corresponde a compartir con los tomadores de decisiones/stakeholders/creadores de política pública los resultados obtenidos y la recomendación de acciones a llevar a cabo -menú de opciones-.

    - Las implicaciones éticas de esta fase consisten en hacer conciente el impacto social de nuestro trabajo.


```{r echo=FALSE,fig.align='center', out.width='200pt', out.height='200pt'}
knitr::include_graphics("img/01-intro2ds-ciclo/08-action.jpg")
```



## Taller de Scoping

El **scoping** es uno de los pasos más importante en los proyectos de ciencia de datos, es ideal realizarlo con ayuda del cliente, tiene como objetivo **definir el alcance del proyecto**, definir los objetivos, conocer las acciones que se llevaran acabo, conocer si los datos son relevantes y suficientes, proponer soluciones analíticas, entre otros puntos que se tocaran a continuación.

```{r, fig.align='center', out.height='300pt', out.width='300pt',echo=F}
knitr::include_graphics("img/01-intro2ds-ciclo/09-objetivo.jpg")
```

### Data Maturity Framework

Antes de iniciar con el *scoping*, queremos conocer si los interesados **están listos para realizar un proyecto de ciencia de datos**. Para ello, una opción es usar el [*Data Maturity Framework*](http://www.datasciencepublicpolicy.org/wp-content/uploads/2018/05/Data_Maturity_Framework_4.28.16.pdf) desarrollado en la Universidad de Chicago.

El *Data Maturity Framework* nos sirve para ver dónde se encuentra la organización en el marco de madurez de datos y cómo mejorar su organización, tecnología y preparación de datos.

Tiene tres áreas de contenido:

- Definición del problema

- Disponibilidad de datos y tecnología

- Preparación organizacional

Esta dividido en tres partes:

- Un cuestionario y una encuesta para evaluar la preparación de la organización.

```{r, fig.align='center', out.height='800pt', out.width='750pt', echo=F}
knitr::include_graphics("img/01-intro2ds-ciclo/10-dmf1.png")
```

- Matriz de preparación de datos y tecnología

```{r, fig.align='center',  echo=F}
knitr::include_graphics("img/01-intro2ds-ciclo/11-dmf2.png")
```

- Matriz de preparación organizacional

```{r, fig.align='center', echo=F}
knitr::include_graphics("img/01-intro2ds-ciclo/12-dmf3.png")
```










### Scoping

Para realizar el scoping podemos apoyarnos del siguiente [documento](https://docs.google.com/spreadsheets/d/1hCRt00nYyZvbkfi9yOMRSR0R30lPRtKzaNKKlgAE78M/edit?usp=sharing).

Ya que sabemos que la organización esta preparada para realizar un proyecto de ciencia de datos, podemos inicar el *scoping*. El proceso a seguir es el siguiente:

#### Definir objetivo(s) {-}

Considerado **el paso más importante del proceso**, los *stakeholders* iniciaran con un planteamiento del problema de manera muy general, nuestra responsabilidad será ir aterrizando ideas y **definir el problema de manera más concreta**, esta parte del *scoping* puede ocurrir en distintas iteraciones.

Necesitamos hacer que el objetivo sea **concreto, medible y optimizable**. Cuando se van refinando objetivos, es común que se vaya priorizando por lo que tendremos *tradeoffs* que irán ligados a las acciones y al contexto del negocio.

#### ¿Qué acciones o intervenciones existen que serán mejoradas a través de este proyecto? {-}

Debemos **definir acciones concretas**, si esto no ocurre es muy probable que la solución no sea implementada por lo que el proyecto no tendrá uso y no estaráamos haciendo ciencia de datos.

La implementación del proyecto debería ayudar a tener mejor información para llevar acabo estas acciones, es decir, el proyecto mejorará la toma de decisiones basadas en la evidencia de los datos.

Hacer una lista con las acciones ayuda a que el proyecto sea accionable, es posible que estas acciones no existan aún en la organización, por lo que el proyecto puede ayudar a **generar nuevas acciones**.

Es muy común que la acción definida por el *stakeholder* sea de muy alto nivel, en ese caso podemos tomar 2 caminos en el *scoping*:

- Proponer en el *scoping* que el proyecto informe a esa acción general.

- Generar a partir de esa acción general acciones más pequeñas. 

#### ¿Qué datos tenemos y cuáles necesitamos?  {-}

Primero observemos que no se habia hablado de los datos hasta este punto, lo anterior porque debemos primero pensar en el problema, entenderlo y luego ver con qué datos contamos para resolverlo. Si hacemos esto primero seguramente acabaremos desarrollando productos de datos "muertos" y no accionables.

En este paso se le dara uso al *Data Maturity Framework*, queremos conocer cómo se guardan los datos, con qué frecuencia, en qué formato, en qué estructura, qué granularidad tiene, desde cuándo tenemos historia de estos datos, si existe un sesgo en su recolección, con qué frencuencia recolectan nueva información, sobreescribe la ya existente?

Uno de los objetivos consiste en **identificar si la granularidad, frecuencia y horizonte de tiempo en los datos corresponde a la granularidad, frecuencia y horizonte de tiempo de las acciones**.

Otro punto importante es saber si los datos con los que se cuenta son **relevantes y suficientes** para desarrollar el proyecto, se pueden considerar fuentes de datos externa.


#### ¿Cuál es el análisis que necesitamos hacer? {-}

En esta seccion del *scoping* queremos definir qué tipo de análisis necesitamos hacer con los datos con los que contamos para cumplir con los objetivos definidos y generar las acciones identificadas.

El análisis puede incluir métodos y herramientas de diferentes disciplinas: ciencias computacionales, ciencia de datos, machine learning, estadística, ciencias sociales.

Existen distintos tipops de análisis, los 4 más comunes son:

- **Descripción**: Centrado en entender eventos y comportamientos del pasado. Aunque puede confundirse con business intelligence, debido a que ya definimos objetivos y acciones vamos a desarrollar un producto de datos. Para este tipo de análisis podemos ocupar métodos de aprendizaje no supervisado: clustering.

- **Detección**: Más concentrado en los eventos que están sucediendo. Detección de anomalías.

- **Predicción**: Concentrado en el futuro, prediciendo futuros eventos o comportamientos.

- **Cambio en comportamiento**: Concentrado en entender las causas de cambios en comportamientos de personas eventos, organizaciones, vecindarios, etc.

```{r, fig.align='center', out.height='400pt', out.width='500pt',echo=F}
knitr::include_graphics("img/01-intro2ds-ciclo/15-elegir.jpg")
```


En esta fase tenemos que responder las siguientes preguntas:

- ¿Qué tipo de análisis neceistaremos? Puede ser más de uno.

- ¿Cómo vamos a validar el análisis? ¿Qué validaciones se pueden hacer con los datos existentes? ¿Cómo podemos diseñar una prueba en campo para validar el análisis antes de que pongamos el producto en producción.

- Identificar qué acciones se cubren con cada análisis, debemos tener todas las acciones cubiertas.

### Ejemplos {-}

Los siguientes ejemplos forman parte del trabajo de [DSSG](http://www.datasciencepublicpolicy.org/home/resources/data-science-project-*scoping*-guide/), en cada uno de estos planteamientos intentaremos responder las siguientes preguntas:

- ¿Cuál es el objetivo?
- ¿Cómo se mide el objetivo?
- ¿Qué se optimiza?
- ¿Se puede optimizar?
- ¿Cuáles son los tradeoffs?
- ¿Que implicaciones éticas identificas?

1) **Envenenamiento por plomo**: Hace unos años, comenzamos a trabajar con el Departamento de Salud Pública de Chicago para prevenir el envenenamiento por plomo. El objetivo inicial era aumentar la eficacia de sus inspecciones de peligro de plomo. Una forma de lograr ese objetivo sería concentrarse en los hogares que tienen peligros de plomo. Aunque fue útil, este enfoque no lograría su objetivo real, que era evitar que los niños se intoxicaran con plomo. Encontrar un hogar con peligros de plomo y repararlo solo es beneficioso si existe una alta probabilidad de que un niño presente (actualmente o en el futuro) se exponga al plomo. La siguiente iteración del objetivo fue maximizar la cantidad de inspecciones que detectan peligros de plomo en hogares donde hay un niño en riesgo (antes de que el niño se exponga al plomo). Finalmente, llegamos al objetivo final: identificar qué niños corren un alto riesgo de intoxicación por plomo en el futuro y luego dirigir las intervenciones a los hogares de esos niños..

2) **High School Graduation**: Uno de los mayores desafíos que enfrentan las escuelas hoy en día es ayudar a sus estudiantes a graduarse (a tiempo). Las tasas de graduación en los EE. UU. Son ~65%. Todos están interesados en identificar a los estudiantes que corren el riesgo de no graduarse a tiempo. Al hablar inicialmente con la mayoría de los distritos escolares, comienzan con un objetivo muy limitado de predecir qué niños es poco probable que se gradúen a tiempo. El primer paso es volver al objetivo de aumentar las tasas de graduación y preguntar si hay un subconjunto específico de estudiantes en riesgo que quieran identificar. ¿Qué pasaría si pudiéramos identificar a los estudiantes que tienen solo un 5% de probabilidades de estar en riesgo frente a los estudiantes que tienen un 95% de probabilidades de no graduarse a tiempo sin apoyo adicional? Si el objetivo es simplemente aumentar las tasas de graduación, es (probablemente) más fácil intervenir e influir en el primer grupo, mientras que el segundo grupo puede ser más desafiante debido a los recursos que necesita. ¿El objetivo es maximizar la probabilidad promedio/media/mediana de graduarse para una clase/escuela o es el objetivo enfocarse en los niños con mayor riesgo y maximizar la probabilidad de graduación del 10% inferior de los estudiantes? ¿O el objetivo es crear más equidad y disminuir la diferencia en la probabilidad de graduación a tiempo entre el cuartil superior y el cuartil inferior? Todos estos son objetivos razonables, pero las escuelas deben comprender, evaluar y decidir qué objetivos les interesan. Esta conversación a menudo los hace pensar más en definir analíticamente cuáles son sus objetivos organizacionales, así como las compensaciones..

3) **Inspecciones**: Hemos trabajado en varios proyectos que involucraron inspecciones, como con la EPA (Agencia de Protección Ambiental) y el Departamento de Conservación Ambiental del Estado de Nueva York para ayudarlos a priorizar qué instalaciones inspeccionar para detectar infracciones de eliminación de desechos, con la ciudad de Cincinnati para ayudar a identificar las propiedades en riesgo de violaciones del código para prevenir el deterioro -el proceso a través del cual una ciudad que funcionaba anteriormente, o parte de ella, cae en deterioro y decrepitud-, y con el Grupo del Banco Mundial para ayudarlos a priorizar qué denuncias de fraude y colusión investigar. En la mayoría de los problemas de inspección/investigación, hay muchas más entidades (viviendas, edificios, instalaciones, negocios, contratos) para inspeccionar que los recursos disponibles necesarios para realizar esas inspecciones. El objetivo con el que comienzan la mayoría de estas organizaciones es dirigir sus inspecciones a las entidades que tienen más probabilidades de violar las regulaciones existentes. Ese es un buen comienzo, pero la mayoría de estas organizaciones nunca pueden inspeccionar todas las instalaciones/hogares que pueden no cumplir con las normas, por lo que el objetivo que realmente buscan es la disuasión: reducir la cantidad total de instalaciones que estarán en violación. Un proceso de inspección ideal resultaría entonces en la reducción del número real de violaciones (encontradas o no), lo cual puede no ser lo mismo que un proceso de inspección que tiene como objetivo ser eficiente y aumentar la tasa de aciertos (% de inspección que resulta en violaciones).

4) **Programación de la recolección de residuos**: Recientemente comenzamos a trabajar con Sanergy, una empresa social con sede en Kenia. Implementan inodoros portátiles en asentamientos urbanos informales y uno de sus mayores costos es contratar personas para vaciar los inodoros. Hoy en día, todos los inodoros se vacían todos los días, aunque existe una variación en cuánto se usan y cuánto se llenan. Para que puedan crecer y mantener bajos los costos, necesitan un enfoque más adaptable que pueda optimizar el cronograma de vaciado de los inodoros. El objetivo en este caso es asegurarse de no vaciar demasiado el inodoro cuando no está lleno, pero tampoco dejar que permanezca lleno porque entonces no se puede usar. Esto se traduce en una formulación que presiona para vaciar el inodoro lo más cerca posible de estar lleno al 100% sin llegar al 100%.












